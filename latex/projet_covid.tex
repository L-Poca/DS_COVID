\textbf{
}\includegraphics[width=4.9375in,height=1.21875in]{media/image1.png}

Analyse de Radiographies pulmonaires Covid-19

\includegraphics[width=4.39583in,height=2.92708in]{media/image2.png}

Présenté par : Encadré par :

\begin{itemize}
\tightlist
\item
  Cirine Bouamrane Nicolas Mormiche
\item
  Léna Bacot
\item
  Steven Moire
\item
  Rafael Cepa
\end{itemize}

\begin{quote}
Sommaire :
\end{quote}

\begin{quote}
\end{quote}

\section[Introduction
:]{\texorpdfstring{\protect\hypertarget{anchor}{}{}\protect\hypertarget{anchor-1}{}{}\protect\hypertarget{anchor-2}{}{}Introduction
:}{Introduction :}}\label{introduction}

Afin d'identifier plus facilement les cas positifs de Covid-19,
l'analyse automatisée des radiographies pulmonaires apparaît comme une
alternative précieuse, notamment lorsque les tests conventionnels ne
sont pas disponibles. L'utilisation du deep learning appliqué à ces
images a déjà montré des résultats prometteurs pour détecter les
infections à Covid-19, parfois avec une précision supérieure à celle de
radiologues expérimentés.

L'objectif de notre projet est donc de concevoir un système de
classification binaire permettant de distinguer entre patients atteints
et non atteints du Covid-19 à partir de radiographies thoraciques.

\section[Etape 1 : Exploration des données et
DataViz']{\texorpdfstring{\protect\hypertarget{anchor-3}{}{}\protect\hypertarget{anchor-4}{}{}\protect\hypertarget{anchor-5}{}{}Etape
1 : Exploration des données et
DataViz'}{Etape 1 : Exploration des données et DataViz'}}\label{etape-1-exploration-des-donnuxe9es-et-dataviz}

\subsection[Base de données
:]{\texorpdfstring{\protect\hypertarget{anchor-6}{}{}\protect\hypertarget{anchor-7}{}{}\protect\hypertarget{anchor-8}{}{}Base
de données :}{Base de données :}}\label{base-de-donnuxe9es}

La base de données utilisée pour ce projet est la COVID-19 Radiography
Database accessible sur Kaggle. Cette base de données regroupe
différentes catégories d\textquotesingle images radiographiques
pulmonaires permettant la détection et la classification des infections,
notamment du Covid-19. Elle inclut :

\begin{itemize}
\tightlist
\item
  Des radiographies thoraciques de patients confirmés positifs au
  Covid-19.
\item
  Des images de cas jugés normaux (sans infection pulmonaire détectée).
\item
  Des radiographies de pneumonies virales autres que Covid-19.
\item
  Des images présentant des opacités pulmonaires (infections pulmonaires
  non-COVID de type "Lung Opacity").
\end{itemize}

Les tailles des sous-ensembles composant la base de données sont
représentées dans le tableau suivant~:

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Classes & Images & Masks \\
Covid & 3616 & 3616 \\
Normal & 10192 & 10192 \\
Viral\_pneumonia & 1345 & 1345 \\
Lung\_opacity & 6012 & 6012 \\
\end{longtable}

Ces images proviennent de multiples sources publiques, publications
spécialisées et collaborations avec des hôpitaux.

Un exemple d'une image de la classe normale et son mask sont
représentées dans la figure ci-dessous (Figure01).

\includegraphics[width=2.78001in,height=3.21864in]{media/image3.png}\includegraphics[width=3.0836in,height=3.18361in]{media/image4.png}

\begin{quote}
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\textbf{ }
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\textbf{Figure 01 : }Exemple d'une image de la base de données et son
mask (classe nomal)
\end{quote}

\subsection[Dataviz'
:]{\texorpdfstring{\protect\hypertarget{anchor-9}{}{}\protect\hypertarget{anchor-10}{}{}\protect\hypertarget{anchor-11}{}{}Dataviz'
:}{Dataviz' :}}\label{dataviz}

Histogramme de la luminosité et du contraste :

\begin{quote}
\end{quote}

\begin{itemize}
\tightlist
\item
  \textbf{Luminosité~:}\\
  Il s'agit de l'intensité lumineuse globale d'une image, c'est-à-dire
  du niveau moyen de clarté ou d'obscurité perçu sur l'ensemble de
  l'image. Mathématiquement, c'est simplement la moyenne des valeurs des
  canaux de chaque pixel. Pour une image en couleurs (RGB), on utilise
  la pondération de la norme ITU-R BT.601, correspondant à la
  sensibilité de l'œil humain (0.299 pour R, 0.587 pour G, 0.114 pour
  B).
\item
  \textbf{Contraste~:}\\
  Le contraste représente la différence de luminosité entre les zones
  claires et sombres d'une image. Mathématiquement, c'est l'écart-type
  (std) de la valeur des pixels. Un contraste élevé signifie que la
  différence entre les parties les plus sombres et les plus claires est
  importante~; à l'inverse, un faible contraste indique que les valeurs
  de gris sont proches les unes des autres, rendant les détails moins
  visibles.
\end{itemize}

Un histogramme de luminosité et de contraste fournit des informations
essentielles sur la répartition des tons et la qualité d'exposition
d'une image, l'histogramme permet de juger de la bonne exposition, du
niveau de contraste, de repérer d'éventuelles pertes d'information, et
de guider les ajustements à apporter pour optimiser une image.

Il indique comment les pixels de l'image sont répartis des tons les plus
foncés (gauche) aux plus clairs (droite)~:

\begin{itemize}
\tightlist
\item
  À gauche~: pixels sombres (ombres, noirs)
\item
  Au centre~: tons moyens (gris)
\item
  À droite~: pixels clairs (hautes lumières, blancs)
\end{itemize}

Il permet d'identifier~:

\begin{itemize}
\tightlist
\item
  Une sous-exposition (pic vers la gauche~: image trop sombre)
\item
  Une surexposition (pic vers la droite~: image trop claire)
\item
  Un bon contraste (répartition étalée de la gauche à la droite~:
  l'image contient à la fois des zones sombres et claires, donc beaucoup
  de détails)
\item
  Un faible contraste (histogramme ramené vers le centre, l'image paraît
  ``plate'' avec surtout des tons moyens)
\end{itemize}

L'histogramme aide aussi à~:

\begin{itemize}
\tightlist
\item
  Éviter l'écrêtage~: apparition de barres hautes à l'extrême gauche ou
  droite, signalant une perte d'information dans les ombres ou les
  hautes lumières.
\item
  Ajuster la correction de la luminosité et du contraste pour améliorer
  la lisibilité ou la qualité technique de l'image.
\end{itemize}

Nous avons généré les histogrammes de luminosité pour chaque catégorie
d'images (normal, Covid, pneumonie et lung). Les résultats
correspondants sont illustrés dans les figures suivantes :

\begin{quote}
\includegraphics[width=5.63542in,height=2.25in]{media/image5.png}
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\end{quote}

\includegraphics[width=5.65625in,height=2.19792in]{media/image6.png}

\includegraphics[width=5.70833in,height=2.48958in]{media/image7.png}

\includegraphics[width=5.79167in,height=2.34375in]{media/image8.png}

\textbf{Figure 02 : }Histogramme de la luminosité et du contraste des
différentes images de la dataset

\subsection[Interprétation
:]{\texorpdfstring{\protect\hypertarget{anchor-12}{}{}Interprétation
:}{Interprétation :}}\label{interpruxe9tation}

A savoir :

\begin{itemize}
\tightlist
\item
  \textbf{Axe horizontal~:} les\textbf{ }valeurs de gris, de 0 (noir) à
  255 (blanc).
\item
  \textbf{Axe vertical~: }nombre d'images.
\end{itemize}

\begin{longtable}[]{@{}lll@{}}
\toprule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
& Histogramme luminosité & Histogramme contraste \\
Image normale & Ton vers le clair & Faible contraste \\
Image covid & Ton vers le clair & Bon contraste \\
Image Pneumo & Ton moyen (gris équilibré) & Bon contraste \\
Image lung & Ton vers le clair & Bon contraste \\
\end{longtable}

\subsection{\texorpdfstring{Luminosité Globale :
}{Luminosité Globale : }}\label{luminosituxe9-globale}

Exprime la répartition de la luminosité des images, pour chaque
catégorie.

\includegraphics[width=6.26042in,height=1.67708in]{media/image9.png}

\textbf{Figure 03 :} Distribution Luminosité Globale

\subsection{Contraste Globale :}\label{contraste-globale}

Exprime la répartition du contraste des images, pour chaque catégorie.

\includegraphics[width=6.26042in,height=1.67708in]{media/image10.png}\textbf{Figure
04 :} Distribution du contraste Globale

\section[Steven Visualization
:]{\texorpdfstring{\protect\hypertarget{anchor-13}{}{}\protect\hypertarget{anchor-14}{}{}\protect\hypertarget{anchor-15}{}{}Steven
Visualization :}{Steven Visualization :}}\label{steven-visualization}

\includegraphics[width=6.26042in,height=2.84375in]{media/image11.png}

\textbf{Figure 03 :} Visualisation des images en L et en RGB de la
classe Viral Pneumonia

⚠️ 140 images RGB détectées (hors norme) sur un total de 1345 images
provenant de Viral Pneumonia.

Après analyse, nous avons conclu qu'il s'agit en fait de `faux RGB',
c'est à dire des images encodées en 3 canaux, mais représentant en
réalité une image L. En effet, quand on a essayé d'afficher quelques
intrus, nous avions l'impression de voir des niveaux de gris. Pour
chaque intrus `img', convertie en np.array, nous avons :

img\_array{[}:,:,0{]} == img\_array{[}:,:,1{]} == img\_array{[}:,:,2{]}

\includegraphics[width=6.07395in,height=2.86011in]{media/image12.png}

\textbf{Figure 04 :} exemple d'images en RGB de la classe Viral
Pneumonia

Ces 140 images sont bien codées en 3 canaux RGB, mais on a, à chaque
fois, la même valeur pour les trois canaux, c'est donc une redondance
d'informations, et la conversion en L sera alors encore plus simple.
Pour rappel, une image RGB est convertie en L selon la norme ITU-R
BT.601 (citée plus haut), grâce à la formule :

L = 0.299R + 0.587G + 0.114B.

Où :

\begin{itemize}
\tightlist
\item
  L : valeur du pixel en nuance de gris résultante de la conversion
\item
  R, G, B : valeurs du pixel en RGB que l'on veut convertir
\end{itemize}

Il est donc évident ici, qu'avec R = G = B :

L = 0.299R + 0.587R + 0.114R L = R = G = B

Autrement dit, le pixel converti en L n'est autre que la même valeur
commune aux trois channels, on peut donc simplement choisir le premier
canal (R, i.e. img\_array{[}:,:,0{]}) pour `convertir' l'image en L.

Nous avons remarqué qu'en réalité, ce problème est exactement le même
pour les masks, qui sont tous des ``faux RGB''. Pour la suite de notre
projet, nous avons décidé d'utiliser les fonctions de conversion des
packages reconnus (PIL, cv2 ...), même si utiliser le premier canal (par
exemple) suffirait. En effet, nous voulons tester différentes approches,
et essayer de comprendre ce qu'apportent ces fonctions. Il nous semblait
cependant important de montrer notre réflexion face à ce
problème.\protect\phantomsection\label{anchor-16}{}\protect\phantomsection\label{anchor-17}{}\protect\phantomsection\label{anchor-18}{}🧠
\textbf{Analyse métier}

\begin{itemize}
\tightlist
\item
  Les radiographies doivent être en niveau de gris (L), car les
  informations pertinentes ne sont pas dans les couleurs.
\item
  La présence de plusieurs images en RGB est donc anormale.
\item
  Cela peut indiquer des erreurs de traitement ou
  d\textquotesingle export depuis un outil d\textquotesingle annotation.
\end{itemize}

\subsection[🛠️ \textbf{Recommandations
techniques}]{\texorpdfstring{\protect\hypertarget{anchor-19}{}{}\protect\hypertarget{anchor-20}{}{}\protect\hypertarget{anchor-21}{}{}🛠️
\textbf{Recommandations
techniques}}{🛠️ Recommandations techniques}}\label{recommandations-techniques}

\begin{itemize}
\item
  Identifier les images en RGB et les vérifier visuellement.
\item
  Si ce sont bien des radios, les convertir en L via img.convert("L")
  pour :

  \begin{itemize}
  \tightlist
  \item
    Homogénéiser les données
  \item
    Réduire la taille mémoire
  \end{itemize}
\item
  Ces anomalies sont visibles dans le rapport template d'exploration
  automatique généré (voir lien juste après).
\end{itemize}

\subsection[Steven Template
:]{\texorpdfstring{\protect\hypertarget{anchor-22}{}{}\protect\hypertarget{anchor-23}{}{}\protect\hypertarget{anchor-24}{}{}Steven
Template :}{Steven Template :}}\label{steven-template}

\href{https://1drv.ms/x/c/9e322a9006fb4eb1/ERjCTdYjnJBFhoRxyeNj00EBlyoYCRADMprJFlOrgObT0Q?e=idyaqO}{\textbf{https://1drv.ms/x/c/9e322a9006fb4eb1/ERjCTdYjnJBFhoRxyeNj00EBlyoYCRADMprJFlOrgObT0Q?e=idyaqO}}

\section[\textbf{Stream lit
Graph}]{\texorpdfstring{\protect\hypertarget{anchor-25}{}{}\protect\hypertarget{anchor-26}{}{}\protect\hypertarget{anchor-27}{}{}\textbf{Stream
lit Graph}}{Stream lit Graph}}\label{stream-lit-graph}

\subsection[Introduction :
]{\texorpdfstring{\protect\hypertarget{anchor-28}{}{}\protect\hypertarget{anchor-29}{}{}Introduction
: }{Introduction : }}\label{introduction-1}

La bibliothèque StreamLit sur python, nous permet de créer des Dashboard
interactifs.

Ceux-ci ont été conçus afin de nous permettre de créer des outils afin
de faciliter notre collaboration.

Le Stream Lit peut appeler les fonctions en backend pour effectuer
certaines taches dans notre data-workflow et nous présenter des
visualisations d'analyses que l'on a effectué.\\
\strut \\
A la suite, vous trouverez un aperçu de ces fonctionnalités et un cas
d'application pratique sur notre problématique.

\subsection[\textbf{Outils Collaboratifs :
}]{\texorpdfstring{\protect\hypertarget{anchor-30}{}{}\protect\hypertarget{anchor-31}{}{}\textbf{Outils
Collaboratifs : }}{Outils Collaboratifs : }}\label{outils-collaboratifs}

\subsubsection[Inspection des Fichiers Features :
]{\texorpdfstring{\protect\hypertarget{anchor-32}{}{}\protect\hypertarget{anchor-33}{}{}Inspection
des Fichiers Features :
}{Inspection des Fichiers Features : }}\label{inspection-des-fichiers-features}

Voici un aperçu de la fenêtre d'inspection des fichiers.

\includegraphics[width=6.26042in,height=2.54167in]{media/image13.png}

\textbf{ Figure 05 :} Inspection Fichiers Python Backend

Cet affichage nous permet de voir l'évolution des fichiers de fonctions
backend d'un simple coup d'œil !

On peut donc voir le nombre de lignes et la validation PEP8, nous
permettant de revoir les fichiers adéquats et donc de gagner en
organisation.

\subsubsection[Inspection détaillée des fonctions dans Features
:]{\texorpdfstring{\protect\hypertarget{anchor-34}{}{}\protect\hypertarget{anchor-35}{}{}Inspection
détaillée des fonctions dans Features
:}{Inspection détaillée des fonctions dans Features :}}\label{inspection-duxe9tailluxe9e-des-fonctions-dans-features}

Pour chacun des fichiers détectés précédemment, on vient scanner toutes
les fonctions (à l'aide de la librairie Inspect) afin de les afficher.

Ceci sert pour le travail collaboratif afin de rester informé de
l'existence des fonctions crée ou mises à jour par nos équipes.

\includegraphics[width=6.26042in,height=2.72917in]{media/image14.png}

\textbf{ Figure 06:} Inspection Fonctions Python Backend

Il est ensuite possible d'afficher un panel détaillé avec toutes les
informations essentielles de la fonction !

Ceci incluant le nom de la fonction, la doc string, le nombre de lignes,
les arguments et la valeur de return.

\includegraphics[width=6.26042in,height=2.90625in]{media/image15.png}
\textbf{Figure 07 :} Détail Fonctions Python Backend

\subsection[Analyse Complète (Déséquilibrée)
:]{\texorpdfstring{\protect\hypertarget{anchor-36}{}{}\protect\hypertarget{anchor-37}{}{}\protect\hypertarget{anchor-38}{}{}Analyse
Complète (Déséquilibrée)
:}{Analyse Complète (Déséquilibrée) :}}\label{analyse-compluxe8te-duxe9suxe9quilibruxe9e}

Nous allons utiliser les fonctionnalités de l'interface afin de traiter
et analyser nos données d'images.

\includegraphics[width=6.26042in,height=3.375in]{media/image16.png}\textbf{Figure
08 :} Menu Principal, sélection des données

On lance une analyse sur l'ensemble des images.

\includegraphics[width=6.26042in,height=1.98958in]{media/image17.png}\textbf{Figure
09 :} Radar Chart, Données/Métriques par Catégories

On peut déjà noter visuellement des domaines différents pour chaque
catégorie.

\textbf{Luminosité~/ Intensité :} Moyenne des valeurs de pixels, reflète
la clarté globale de l'image.

\textbf{Contraste~:} Écart-type des valeurs de pixels, mesure la
variation autour de la moyenne.

\textbf{Netteté~:} Quantifie la présence de détails et de contours, via
la fonction Laplacien.

\textbf{Entropie~:} Mesure la diversité des intensités, indique la
richesse
d'information.\includegraphics[width=6.26042in,height=1.52083in]{media/image18.png}\textbf{Figure
10 :} Test Anova, différence entre Catégories

Et l'on confirme ce résultat par un test ANOVA.

\includegraphics[width=6.26042in,height=4.02083in]{media/image19.png}\textbf{Figure
11 :} Taille des fichiers par
catégorie\includegraphics[width=6.26042in,height=3.23047in]{media/image20.png}\textbf{Figure
12 :} Intensité par Catégorie

\includegraphics[width=6.26042in,height=1.98958in]{media/image21.png}\textbf{Figure
13 :} Corrélation des métriques

\includegraphics[width=6.26042in,height=1.98958in]{media/image22.png}\textbf{Figure
14 :} Répartition des données dans un espace 3D

\includegraphics[width=6.26042in,height=2.53125in]{media/image23.png}\textbf{Figure
15 :} Recommandations Automatiques

\subsection[Analyse Equilibrée
:]{\texorpdfstring{\protect\hypertarget{anchor-39}{}{}\protect\hypertarget{anchor-40}{}{}\protect\hypertarget{anchor-41}{}{}Analyse
Equilibrée :}{Analyse Equilibrée :}}\label{analyse-equilibruxe9e}

Suite à cette analyse, on se rend compte que les données ne sont pas
équilibrées, on va donc retenter l'analyse avec un échantillon de 1000
pour chacune des catégories et voir les différences sur nos indicateurs.

\includegraphics[width=6.26042in,height=3.38542in]{media/image24.png}\textbf{Figure
16 :} Menu Principal, sélection des données
(équilibrés)\includegraphics[width=6.26042in,height=1.79167in]{media/image25.png}\textbf{Figure
17 :} Menu Principal, Aperçu des données (équilibrés)

\includegraphics[width=6.26042in,height=1.72917in]{media/image26.png}\textbf{Figure
18 :} Menu Principal, sélection des données (équilibrés)

On peut noter sur cet ensemble plus équilibré que la représentation des
domaines est différente par rapport à l'analyse précédente.

\includegraphics[width=6.26042in,height=1.23958in]{media/image27.png}\textbf{Figure
19 :} Test Anova, Différences Catégories (équilibrés)

Les différences sont toujours significatives.

\includegraphics[width=6.26042in,height=3.48958in]{media/image28.png}\textbf{Figure
20 :} Intensité par Catégories (équilibrés)

\includegraphics[width=6.26042in,height=3.48958in]{media/image29.png}\textbf{Figure
21 :} Taille de fichiers par catégorie (équilibrés)

\includegraphics[width=6.26042in,height=1.72917in]{media/image30.png}\textbf{Figure
22 :} Corrélation des métriques (équilibrés)

\includegraphics[width=6.26042in,height=2in]{media/image31.png}\textbf{Figure
23 :} Recommandations Automatiques (équilibrés)

\includegraphics[width=6.26042in,height=1.78086in]{media/image32.png}\textbf{Figure
24 :} Représentation des données dans un espace 3D (équilibrés)

\section[Génération images masquées + Statistiques :
]{\texorpdfstring{\protect\hypertarget{anchor-42}{}{}\protect\hypertarget{anchor-43}{}{}\protect\hypertarget{anchor-44}{}{}Génération
images masquées + Statistiques :
}{Génération images masquées + Statistiques : }}\label{guxe9nuxe9ration-images-masquuxe9es-statistiques}

Cette fonctionnalité appelée par un notebook, permet de générer des
images masquées à l'aide d'images et de masques (nos datas).

Pendant cette opération, des statistiques sont également évalués et
représentées.

Voici les statistiques du masquage sur l'ensemble des données, avec un
paramètre :

dsize = (256x256), ce qui correspond à une image de 256x256 pixels.

\subsection[Exemple Génération Image Masqué :
]{\texorpdfstring{\protect\hypertarget{anchor-45}{}{}Exemple Génération
Image Masqué :
}{Exemple Génération Image Masqué : }}\label{exemple-guxe9nuxe9ration-image-masquuxe9}

La fonction permet en lui donnant une image et un masque, de l'appliquer
pour générer une image masquée, avec une possibilité de
redimensionnement de l'image.

\includegraphics[width=1.76399in,height=1.76399in]{media/image33.png}

\includegraphics[width=3.19068in,height=3.19068in]{media/image34.png}

\includegraphics[width=1.61033in,height=1.61033in]{media/image35.png}\\
\strut \\
\textbf{Figure 25 :} Exemple, Masquage des images

\subsection[\textbf{Arborescence Automatique :}
]{\texorpdfstring{\protect\hypertarget{anchor-46}{}{}\textbf{Arborescence
Automatique :}
}{Arborescence Automatique : }}\label{arborescence-automatique}

\hfill\break
\includegraphics[width=2.29215in,height=4.97321in]{media/image36.png}Afin
de pouvoir garder un environnement propre,\\
une arborescence automatique pour trier les éléments générés a été mise
en place.\\
\strut \\
Celle-ci génère dans le dossier ''processed'':\\
\strut \\
Un premier dossier en fonctions de la résolution,\\
Exemple : 256x256 (Nom du dossier).\\
\strut \\
Ensuite, dans ce dossier, 4 autres sont créées pour chacune des
catégories :\\
- Covid\\
- Lung ( Opacity )\\
- Normal\\
- Pneumonia\\
\strut \\
Dans chacun de ces dossiers, on va générer des dossiers par type
d'éléments générés :\\
- Images redimensionnés\\
- Masques redimensionnés\\
- Images avec Masque appliqué\\
\strut \\
\strut \\

\section{\texorpdfstring{\protect\hypertarget{anchor-47}{}{}\protect\hypertarget{anchor-48}{}{}}{}}\label{section}

Etape 02: Pre-processing et features engineering:

\begin{itemize}
\tightlist
\item
  \protect\phantomsection\label{anchor-49}{}\protect\phantomsection\label{anchor-50}{}\protect\phantomsection\label{anchor-51}{}Redimensionnement
  et conversion en niveaux de gris :
\end{itemize}

\begin{quote}
\end{quote}

Dans la phase initiale du pré-processing des données, nous appliquons un
redimensionnement des images dont la dimension initiale est de 299
pixels, pour les réduire à une taille uniforme de 256 pixels. Ce choix,
vise à garantir une cohérence des entrées du modèle tout en facilitant
le traitement par lot et en réduisant la charge computationnelle. Ce
redimensionnement est réalisé en utilisant des techniques
d'interpolation adaptées, telles que l'interpolation bicubique, afin de
préserver au mieux la qualité et les détails pertinents des images.

Par la suite, la conversion de l'ensemble des images du format RGB vers
une représentation en niveaux de gris est effectuée. Cette
transformation réduit la dimension d'entrée des données de trois canaux
à un seul, diminuant ainsi la complexité du modèle tout en conservant
l'essentiel de l'information structurelle pertinente, particulièrement
dans le contexte d'images médicales où la couleur est souvent
secondaire. Cette étape est particulièrement judicieuse dans un cadre de
classification, car elle simplifie le signal d'entrée, réduit le bruit
potentiel lié à la variation chromatique, et permet d'optimiser les
performances des algorithmes d'apprentissage en concentrant l'analyse
sur les contrastes et textures essentielles à la discrimination des
classes.

Le code utilisé est dans la figure ci-dessous:(\textbf{Figure})

\includegraphics[width=6.26042in,height=2.34049in]{media/image37.png}
\textbf{ Figure 33 :} le code utilisé pour le redimensionnement et la
conversion en niveau de gris

Un exemple des images de la classe pneumonie obtenue après conversion en
niveau de gris et redimensionnement est représenté dans la figure
(Figure) suivante :

\includegraphics[width=3.1086in,height=3.18361in]{media/image38.png}

\includegraphics[width=2.17519in,height=2.21686in]{media/image39.png}

\textbf{Figure 34 :} Exemple d'une image de la classe pneumonie avant et
après redimensionnement et conversion

\begin{itemize}
\tightlist
\item
  \protect\phantomsection\label{anchor-52}{}Normalisation des pixels :
\end{itemize}

Après redimensionnement, la normalisation des valeurs de pixels est
essentielle pour aider les modèles d'apprentissage profond à converger
rapidement, dans notre cas nous avons choisie de normaliser les pixels
dans une plage {[}-1,1{]}, le code utiliser est représenter dans la
figure suivante : (Figure0)

\begin{quote}
\includegraphics[width=4.08219in,height=0.65625in]{media/image40.png}
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\end{quote}

\begin{quote}
\textbf{Figure 35 : }Fonction de normalisation
\end{quote}

\begin{itemize}
\tightlist
\item
  \protect\phantomsection\label{anchor-53}{}Steven et Raphael
  Augmentation data
\end{itemize}

\subsection[select\_folders.py]{\texorpdfstring{\protect\hypertarget{anchor-54}{}{}select\_folders.py}{select\_folders.py}}\label{select_folders.py}

\subsubsection[📁 \textbf{Classe Python : Sélecteur de dossiers pour
Jupyter Noteboo}k]{\texorpdfstring{\protect\hypertarget{anchor-55}{}{}📁
\textbf{Classe Python : Sélecteur de dossiers pour Jupyter
Noteboo}k}{📁 Classe Python : Sélecteur de dossiers pour Jupyter Notebook}}\label{classe-python-suxe9lecteur-de-dossiers-pour-jupyter-notebook}

\begin{quote}
Ce code définit une classe FolderSelector permettant de sélectionner
interactivement des dossiers dans un notebook Jupyter.
\end{quote}

\begin{quote}
Bien que Jupyter Notebook accepte les commandes input() (qui
s\textquotesingle affichent en haut du notebook), cette méthode peut
sembler contre-intuitive et peu ergonomique. Pour offrir une expérience
utilisateur plus fluide, ce widget utilise les bibliothèques ipywidgets
et IPython.display afin de proposer une interface graphique intégrée
directement sous la cellule de code.
\end{quote}

\subsubsection[🔧 \textbf{Fonctionnalités
:}]{\texorpdfstring{\protect\hypertarget{anchor-56}{}{}🔧
\textbf{Fonctionnalités
:}}{🔧 Fonctionnalités :}}\label{fonctionnalituxe9s}

\begin{itemize}
\tightlist
\item
  Ajout de chemins de dossiers valides via un champ de texte
\item
  Validation en temps réel de l\textquotesingle existence du dossier
\item
  Affichage des dossiers sélectionnés avec feedback visuel
\item
  Bouton "Terminer" pour valider la sélection et masquer automatiquement
  l\textquotesingle interface après 5 secondes
\end{itemize}

\subsubsection[🧩 \textbf{Avantages par rapport à input()
:}]{\texorpdfstring{\protect\hypertarget{anchor-57}{}{}🧩
\textbf{Avantages par rapport à input()
:}}{🧩 Avantages par rapport à input() :}}\label{avantages-par-rapport-uxe0-input}

\begin{itemize}
\tightlist
\item
  Interface intégrée au flux du notebook
\item
  Feedback immédiat sur la validité des chemins
\item
  Masquage automatique après validation
\item
  Expérience utilisateur améliorée
\end{itemize}

\subsubsection[🧩\textbf{ Utilisation
:}]{\texorpdfstring{\protect\hypertarget{anchor-58}{}{}🧩\textbf{
Utilisation :}}{🧩 Utilisation :}}\label{utilisation}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{39}
\tightlist
\item
  Instancier la classe : selector = FolderSelector()
\item
  Afficher le widget : selector.afficher()
\item
  Ajouter les dossiers via l\textquotesingle interface
\item
  Récupérer les chemins via selector.chemins une fois selector.fini ==
  True
\end{enumerate}

\begin{quote}
\includegraphics[width=4.94427in,height=9.20769in]{media/image41.png}
\end{quote}

\begin{quote}
\textbf{Figure 36 : }Code de select\_folders.py
\end{quote}

\subsection[under\_sampling.ipynb]{\texorpdfstring{\protect\hypertarget{anchor-59}{}{}under\_sampling.ipynb}{under\_sampling.ipynb}}\label{under_sampling.ipynb}

\subsubsection[🔽\textbf{ Fonction Python
:}]{\texorpdfstring{\protect\hypertarget{anchor-60}{}{}🔽\textbf{
Fonction Python :}}{🔽 Fonction Python :}}\label{fonction-python}

\subsubsection[Application d\textquotesingle undersampling sur des
images]{\texorpdfstring{\protect\hypertarget{anchor-61}{}{}Application
d\textquotesingle undersampling sur des
images}{Application d\textquotesingle undersampling sur des images}}\label{application-dundersampling-sur-des-images}

Cette fonction apply\_undersampling permet de réduire le nombre
d\textquotesingle images dans un dossier en sélectionnant aléatoirement
un nombre défini d\textquotesingle images. Cette technique, appelée
undersampling, est couramment utilisée en machine learning pour
équilibrer des jeux de données déséquilibrés.

\subsubsection[🔧\textbf{ Paramètres
:}]{\texorpdfstring{\protect\hypertarget{anchor-62}{}{}🔧\textbf{
Paramètres :}}{🔧 Paramètres :}}\label{paramuxe8tres}

data\_dir : chemin du dossier contenant les images sources

target\_count : nombre d\textquotesingle images souhaité en sortie

output\_dir : dossier de destination des images sélectionnées

\subsubsection[📋 \textbf{Fonctionnement
:}]{\texorpdfstring{\protect\hypertarget{anchor-63}{}{}📋
\textbf{Fonctionnement :}}{📋 Fonctionnement :}}\label{fonctionnement}

Liste toutes les images .png du dossier source, si le nombre
d\textquotesingle images dépasse target\_count, en sélectionne
aléatoirement

target\_count Copie les images sélectionnées dans le dossier de sortie,
crée le dossier de sortie s\textquotesingle il n\textquotesingle existe
pas

\subsubsection[📤 \textbf{Retour
:}]{\texorpdfstring{\protect\hypertarget{anchor-64}{}{}📤 \textbf{Retour
:}}{📤 Retour :}}\label{retour}

Liste des logs détaillant les opérations effectuées

\subsubsection[💡\textbf{ Cas d\textquotesingle usage
:}]{\texorpdfstring{\protect\hypertarget{anchor-65}{}{}💡\textbf{ Cas
d\textquotesingle usage
:}}{💡 Cas d\textquotesingle usage :}}\label{cas-dusage}

Équilibrage de classes dans un dataset d\textquotesingle entraînement

Réduction de la taille d\textquotesingle un dataset trop volumineux

Préparation de données pour l\textquotesingle apprentissage automatique

\includegraphics[width=6.26042in,height=5.35417in]{media/image42.png}

\begin{quote}
\textbf{Figure 37 : }Code de under\_sampling.ipynb
\end{quote}

\subsection[Main.ipynb]{\texorpdfstring{\protect\hypertarget{anchor-66}{}{}Main.ipynb}{Main.ipynb}}\label{main.ipynb}

\subsubsection[🔄 \textbf{Script
principal}]{\texorpdfstring{\protect\hypertarget{anchor-67}{}{}🔄
\textbf{Script principal}}{🔄 Script principal}}\label{script-principal}

Pipeline de traitement d\textquotesingle images avec undersampling

Ce script constitue le programme principal qui orchestre
l\textquotesingle ensemble du processus de traitement des images. Il
combine l\textquotesingle interface interactive de sélection de dossiers
avec l\textquotesingle application de la technique
d\textquotesingle undersampling, puis affiche un aperçu visuel des
résultats.

\subsubsection[🔧\textbf{ Fonctionnement global
:}]{\texorpdfstring{\protect\hypertarget{anchor-68}{}{}🔧\textbf{
Fonctionnement global
:}}{🔧 Fonctionnement global :}}\label{fonctionnement-global}

\paragraph[Sélection interactive des dossiers sources
:]{\texorpdfstring{\protect\hypertarget{anchor-69}{}{}Sélection
interactive des dossiers sources
:}{Sélection interactive des dossiers sources :}}\label{suxe9lection-interactive-des-dossiers-sources}

Utilise la classe FolderSelector pour permettre à
l\textquotesingle utilisateur de choisir les dossiers contenant les
images à traiter

Interface graphique intégrée au notebook Jupyter

\paragraph[Application de l\textquotesingle undersampling
:]{\texorpdfstring{\protect\hypertarget{anchor-70}{}{}Application de
l\textquotesingle undersampling
:}{Application de l\textquotesingle undersampling :}}\label{application-de-lundersampling}

Pour chaque dossier sélectionné, applique la fonction
apply\_undersampling

Réduit chaque dataset à un nombre cible d\textquotesingle images
(target\_count = 4999)

Copie les images sélectionnées dans un dossier de sortie commun

\paragraph[Validation visuelle
:]{\texorpdfstring{\protect\hypertarget{anchor-71}{}{}Validation
visuelle :}{Validation visuelle :}}\label{validation-visuelle}

Affiche un échantillon aléatoire d\textquotesingle images issues du
traitementPermet de vérifier visuellement la qualité et la cohérence des
images traitées

\paragraph[📁 \textbf{Gestion des chemins
:}]{\texorpdfstring{\protect\hypertarget{anchor-72}{}{}📁
\textbf{Gestion des chemins
:}}{📁 Gestion des chemins :}}\label{gestion-des-chemins}

Calcule automatiquement le chemin racine du projet

Construit de manière portable le chemin de sortie
(data/processed/Normal)

Assure la compatibilité multi-plateformes

\paragraph[📊 \textbf{Visualisation
:}]{\texorpdfstring{\protect\hypertarget{anchor-73}{}{}📊
\textbf{Visualisation :}}{📊 Visualisation :}}\label{visualisation}

Affiche 5 images aléatoires du dataset final

Utilise matplotlib pour une visualisation rapide dans le notebook

Titres des images pour identification facile

\paragraph[🎯 \textbf{Cas d\textquotesingle usage
:}]{\texorpdfstring{\protect\hypertarget{anchor-74}{}{}🎯 \textbf{Cas
d\textquotesingle usage
:}}{🎯 Cas d\textquotesingle usage :}}\label{cas-dusage-1}

Préparation automatisée de datasets équilibrés

Pipeline de prétraitement pour l\textquotesingle apprentissage
automatique

Interface utilisateur intuitive dans l\textquotesingle environnement
Jupyter

\includegraphics[width=6.72972in,height=8.75446in]{media/image43.png}

\begin{quote}
\textbf{Figure 38 : }Code de Main.ipynb
\end{quote}

\begin{quote}
\includegraphics[width=4.25792in,height=7.96155in]{media/image44.png}
\end{quote}

\textbf{Figure 38 : }Résultat\textbf{ }de Main.ipynb

\subsection{over\_sampling.ipynb}\label{over_sampling.ipynb}

Pour ce qui est de l'Oversampling, nous avons voulu tester directement
avec Keras, et notamment la classe ImageDataGenerator, qui est faite
pour cette occasion.

Dans le code suivant, nous avons utilisé des valeurs arbitraires, mais
qui sont celles que l'on a pu voir dans la documentation du module.

L'utilisation de la méthode flow\_from\_directory apporte deux avantages
majeurs :

\begin{itemize}
\tightlist
\item
  le chargement des images par batchs (ce qui permet alors directement
  d'anticiper la partie modélisation)
\item
  la possibilité de redimensionner (target\_size) et convertir les
  images (color\_mode), d'un seul coup. C'est donc parfait pour nous
  initier à ce type de workflow.
\end{itemize}

\includegraphics[width=6.16962in,height=6.63119in]{media/image45.png}

\textbf{Figure 39 : }Code\textbf{ }de over\_sampling.ipynb

\includegraphics[width=6.26042in,height=1.40625in]{media/image46.png}\textbf{Figure
40 :} Résultat\textbf{ }de over\_sampling.ipynb

Etape 03 : Modélisation

Step 01 : Model Baseline

Un modèle baseline désigne un modèle simple ou rudimentaire utilisé en
machine learning pour servir de point de comparaison aux modèles plus
complexes développés par la suite. Son objectif principal n'est pas
d'obtenir la meilleure précision possible, mais d'établir un niveau de
performance minimal que tout modèle plus sophistiqué doit dépasser pour
être jugé pertinent. (https://www.lakera.ai/ml-glossary/baseline-models)

\begin{itemize}
\tightlist
\item
  Un modèle baseline en classification peut consister à prédire
  systématiquement la classe majoritaire du jeu de données.
\item
  En régression, il s'agira par exemple de prédire la valeur moyenne ou
  médiane de la variable cible, quelle que soit l'entrée.
\end{itemize}

Les modèles baseline ne cherchent pas la performance, mais servent à
évaluer la difficulté intrinsèque du problème.

Exemples de modèles baseline~:

\begin{itemize}
\tightlist
\item
  Pour classification~: prédire la classe majoritaire, prédire au
  hasard, DummyClassifier.
\item
  Pour régression~: prédire la moyenne/médiane, DummyRegressor.
\end{itemize}

Nous avons choisi de tester les méthodes de machines learning suivantes
: SVM, KNN et Forest Random.

\textbf{SVM (Support Vector Machine):
}(\href{https://blent.ai/blog/a/modele-machine-learning-populaires}{\emph{https://blent.ai/blog/a/modele-machine-learning-populaires}})
(\textbf{Figure 41})

Un SVM (Support Vector Machine) est un algorithme supervisé de
classification et de régression.

Il cherche à tracer une frontière (hyperplan) qui sépare au mieux les
classes dans un espace de caractéristiques, en maximisant la "marge"
entre les points de chaque classe les plus proches de la frontière (les
"vecteurs support").

C'est donc un modèle robuste, notamment pour les données de grande
dimension, qui peut aussi intégrer des fonctions noyau ("kernel") pour
gérer la non-linéarité : il projette les données dans un espace de plus
grande dimension pour trouver une séparation optimale.

Utilisé en binaire ou multiclasse, il est réputé pour sa précision sur
des bases bien structurées.

\includegraphics[width=5.60417in,height=4.8125in]{media/image47.png}

\textbf{ Figure 41: Principe de fonctionnement du SVM }

K-Nearest Neighbors (KNN) :

Le KNN ("K plus proches voisins") est un algorithme non paramétrique
supervisé.

Son principe~: pour une nouvelle donnée à classer, il regarde les K
points les plus proches dans le jeu d'entraînement (selon une mesure de
distance, souvent euclidienne).

Il attribue alors la classe la plus fréquente parmi ces voisins
("majorité") en classification, ou la moyenne pour la régression.
(\textbf{Figure 42})

\includegraphics[width=5.65946in,height=2.98958in]{media/image48.png}

\textbf{ Figure 42 : Principe de fonctionnement des KNN}

Random Forest (Forêt d\textquotesingle Arbres Décisionnels) :

Le Random Forest est un algorithme "ensembliste" basé sur les arbres de
décision.

Il construit une multitude d\textquotesingle arbres de décision sur des
sous-échantillons aléatoires des données (méthode du "bagging").

Chaque arbre fait une prédiction, et dans le cas de la classification,
la classe majoritaire parmi tous les arbres devient la prédiction finale
("vote majoritaire"). En régression, c'est la moyenne des prédictions.

Les arbres sont construits avec des sous-ensembles aléatoires de
variables/features et de données, ce qui réduit le sur-apprentissage et
augmente la robustesse.

Le modèle est très performant pour les données tabulaires et mixte
(catégorielles / numériques), mais peut-être moins adapté à des données
très éparses ou avec beaucoup de valeurs manquantes. (\textbf{Figure
43})

\includegraphics[width=6.26042in,height=3.77083in]{media/image49.png}\textbf{Figure
43 : Principe de fonctionnement Random Forest}

Avantages et Inconvénients :

\begin{itemize}
\tightlist
\item
  \textbf{KNN~:} très simple, mais peu efficace sur des volumes
  importants ou en présence de bruit.
\item
  \textbf{SVM~:} performant et robuste sur petites/moyennes dimensions,
  mais coûteux et difficile à régler.
\item
  \textbf{Random Forest~:} généraliste et précis, bien adapté aux
  données complexes, mais lourd en calcul et moins interprétable.
\end{itemize}

Résultats et Interprétation :
