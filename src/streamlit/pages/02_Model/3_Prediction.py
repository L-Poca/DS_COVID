import streamlit as st
import sys
import os
import numpy as np
import pandas as pd
from pathlib import Path
import time
from PIL import Image
import io
import joblib
from datetime import datetime

# Calcul correct du project_root
current_file = Path(__file__)  # pages/02_Model/3_Prediction.py
current_dir = current_file.parent  # pages/02_Model/
streamlit_dir = current_dir.parent.parent  # streamlit/
src_dir = streamlit_dir.parent  # src/
project_root = src_dir.parent  # DS_COVID/

sys.path.append(str(project_root))

try:
    from src.features.Pipelines.Pipeline_Sklearn import PipelineManager
except ImportError:
    st.error("‚ùå Impossible d'importer PipelineManager. V√©rifiez le chemin d'acc√®s.")

st.title("üîÆ Pr√©diction COVID-19")

st.markdown("""
Cette page permet de faire des pr√©dictions avec les mod√®les entra√Æn√©s.
Vous pouvez utiliser des donn√©es simul√©es ou charger vos propres donn√©es.
""")

# Sidebar pour la configuration
with st.sidebar:
    st.header("‚öôÔ∏è Configuration")
    
    # Mode de pr√©diction
    prediction_mode = st.selectbox(
        "Mode de pr√©diction",
        ["Donn√©es simul√©es", "Upload fichier", "Saisie manuelle", "Batch pr√©diction"]
    )
    
    # S√©lection du mod√®le
    st.subheader("ü§ñ Mod√®le")
    
    model_source = st.radio(
        "Source du mod√®le",
        ["Session courante", "Mod√®le sauvegard√©"],
        help="Choisir entre les mod√®les de la session ou charger un mod√®le sauvegard√©"
    )

# Interface principale
tab1, tab2, tab3 = st.tabs(["üéØ Pr√©diction Simple", "üìä Batch Pr√©diction", "üìà Analyse"])

with tab1:
    st.header("Pr√©diction Simple")
    
    # S√©lection du mod√®le
    selected_model = None
    
    if model_source == "Session courante":
        if 'training_results' in st.session_state:
            results = st.session_state['training_results']
            model_names = list(results.keys())
            
            if model_names:
                selected_model_name = st.selectbox(
                    "Choisissez un mod√®le:",
                    options=model_names,
                    help="Mod√®les disponibles de la session d'entra√Ænement"
                )
                
                # Afficher les informations du mod√®le s√©lectionn√©
                if selected_model_name:
                    result = results[selected_model_name]
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("Pr√©cision Test", f"{result.get('test_accuracy', 0):.4f}")
                    with col2:
                        st.metric("F1-Score", f"{result.get('test_f1', 0):.4f}")
                    with col3:
                        st.metric("Score CV", f"{result.get('cv_mean', 0):.4f}")
                    
                    # R√©cup√©rer le mod√®le
                    selected_model = result.get('pipeline')
            else:
                st.warning("‚ö†Ô∏è Aucun mod√®le disponible en session. Entra√Ænez d'abord un mod√®le.")
        else:
            st.warning("‚ö†Ô∏è Aucun mod√®le en session. Allez dans la page Entra√Ænement.")
    
    else:  # Mod√®le sauvegard√©
        st.info("üöß Chargement de mod√®les sauvegard√©s √† impl√©menter")
    
    # Interface de pr√©diction selon le mode
    if selected_model is not None:
        st.divider()
        
        if prediction_mode == "Donn√©es simul√©es":
            st.subheader("üé≤ G√©n√©ration de Donn√©es Test")
            
            col1, col2 = st.columns(2)
            
            with col1:
                n_samples_pred = st.slider("Nombre d'√©chantillons", 1, 100, 5)
                seed_pred = st.number_input("Seed al√©atoire", 1, 9999, 123)
            
            with col2:
                # R√©cup√©rer les dimensions des features depuis la session
                comparison_data = st.session_state.get('comparison_data', {})
                data_info = comparison_data.get('data_info', {})
                default_features = data_info.get('n_features', 16384)
                default_classes = data_info.get('n_classes', 4)
                
                st.info(f"üìä Features: {default_features}")
                st.info(f"üè∑Ô∏è Classes: {default_classes}")
            
            if st.button("üöÄ G√©n√©rer et Pr√©dire", type="primary"):
                with st.spinner("üîÑ G√©n√©ration des donn√©es et pr√©diction..."):
                    try:
                        # G√©n√©rer les donn√©es
                        np.random.seed(seed_pred)
                        X_pred = np.random.rand(n_samples_pred, default_features)
                        
                        # Faire les pr√©dictions
                        predictions = selected_model.predict(X_pred)
                        probabilities = selected_model.predict_proba(X_pred)
                        
                        # Affichage des r√©sultats
                        st.success("‚úÖ Pr√©dictions termin√©es!")
                        
                        # Tableau des r√©sultats
                        results_df = pd.DataFrame({
                            '√âchantillon': range(1, n_samples_pred + 1),
                            'Pr√©diction': predictions,
                            'Probabilit√© Max': [max(prob) for prob in probabilities],
                            'Confiance': [f"{max(prob):.2%}" for prob in probabilities]
                        })
                        
                        # Ajouter les probabilit√©s par classe
                        for i in range(probabilities.shape[1]):
                            results_df[f'Prob Classe {i}'] = [f"{prob[i]:.3f}" for prob in probabilities]
                        
                        st.dataframe(results_df, use_container_width=True)
                        
                        # Statistiques
                        col1, col2, col3 = st.columns(3)
                        
                        with col1:
                            st.metric("√âchantillons trait√©s", n_samples_pred)
                        
                        with col2:
                            confidence_mean = np.mean([max(prob) for prob in probabilities])
                            st.metric("Confiance moyenne", f"{confidence_mean:.2%}")
                        
                        with col3:
                            unique_preds = len(np.unique(predictions))
                            st.metric("Classes pr√©dites", unique_preds)
                        
                        # Graphique de distribution des pr√©dictions
                        pred_counts = pd.Series(predictions).value_counts().sort_index()
                        
                        st.subheader("üìä Distribution des Pr√©dictions")
                        st.bar_chart(pred_counts)
                        
                        # Graphique de confiance
                        st.subheader("üéØ Distribution de la Confiance")
                        confidence_scores = [max(prob) for prob in probabilities]
                        confidence_df = pd.DataFrame({'Confiance': confidence_scores})
                        st.histogram(confidence_df['Confiance'], bins=20)
                        
                        # Sauvegarder les r√©sultats
                        st.session_state['last_predictions'] = {
                            'model_name': selected_model_name,
                            'predictions': predictions,
                            'probabilities': probabilities,
                            'timestamp': datetime.now(),
                            'n_samples': n_samples_pred
                        }
                        
                    except Exception as e:
                        st.error(f"‚ùå Erreur lors de la pr√©diction: {str(e)}")
        
        elif prediction_mode == "Upload fichier":
            st.subheader("üìÅ Upload de Fichier")
            
            uploaded_file = st.file_uploader(
                "Choisir un fichier CSV",
                type=['csv'],
                help="Le fichier doit contenir les features en colonnes"
            )
            
            if uploaded_file is not None:
                try:
                    df_upload = pd.read_csv(uploaded_file)
                    st.success(f"‚úÖ Fichier charg√©: {df_upload.shape[0]} lignes, {df_upload.shape[1]} colonnes")
                    
                    # Aper√ßu des donn√©es
                    st.subheader("üëÄ Aper√ßu des Donn√©es")
                    st.dataframe(df_upload.head(), use_container_width=True)
                    
                    if st.button("üîÆ Faire les Pr√©dictions"):
                        with st.spinner("üîÑ Pr√©diction en cours..."):
                            try:
                                # Pr√©parer les donn√©es
                                X_upload = df_upload.values
                                
                                # Pr√©dictions
                                predictions = selected_model.predict(X_upload)
                                probabilities = selected_model.predict_proba(X_upload)
                                
                                # Cr√©er le DataFrame de r√©sultats
                                results_df = df_upload.copy()
                                results_df['Prediction'] = predictions
                                results_df['Confidence'] = [max(prob) for prob in probabilities]
                                
                                st.success("‚úÖ Pr√©dictions termin√©es!")
                                st.dataframe(results_df, use_container_width=True)
                                
                                # Option de t√©l√©chargement
                                csv_results = results_df.to_csv(index=False)
                                st.download_button(
                                    label="üì• T√©l√©charger les R√©sultats",
                                    data=csv_results,
                                    file_name=f"predictions_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                    mime="text/csv"
                                )
                                
                            except Exception as e:
                                st.error(f"‚ùå Erreur lors de la pr√©diction: {str(e)}")
                
                except Exception as e:
                    st.error(f"‚ùå Erreur lors du chargement du fichier: {str(e)}")
        
        elif prediction_mode == "Saisie manuelle":
            st.subheader("‚úèÔ∏è Saisie Manuelle des Features")
            
            # Interface simplifi√©e pour la saisie manuelle
            st.info("üöß Saisie manuelle √† impl√©menter selon le type de donn√©es sp√©cifique")
            
            # Exemple d'interface
            with st.expander("üîß Interface de saisie (exemple)"):
                col1, col2 = st.columns(2)
                
                with col1:
                    feature1 = st.number_input("Feature 1", value=0.5)
                    feature2 = st.number_input("Feature 2", value=0.3)
                
                with col2:
                    feature3 = st.number_input("Feature 3", value=0.8)
                    feature4 = st.number_input("Feature 4", value=0.2)
                
                if st.button("üîÆ Pr√©dire"):
                    st.info("Interface de saisie manuelle √† adapter selon vos donn√©es sp√©cifiques")
    
    else:
        st.info("‚ÑπÔ∏è S√©lectionnez un mod√®le pour commencer les pr√©dictions.")

with tab2:
    st.header("Pr√©diction en Lot (Batch)")
    
    if selected_model is not None:
        st.subheader("üì¶ Traitement par Lots")
        
        batch_mode = st.selectbox(
            "Mode de traitement",
            ["Dossier de fichiers", "Multiple fichiers CSV"]
        )
        
        if batch_mode == "Multiple fichiers CSV":
            uploaded_files = st.file_uploader(
                "Choisir plusieurs fichiers CSV",
                type=['csv'],
                accept_multiple_files=True,
                help="S√©lectionnez plusieurs fichiers pour traitement en lot"
            )
            
            if uploaded_files:
                st.success(f"‚úÖ {len(uploaded_files)} fichier(s) charg√©(s)")
                
                if st.button("üöÄ Traiter Tous les Fichiers"):
                    batch_results = []
                    progress_bar = st.progress(0)
                    
                    for i, uploaded_file in enumerate(uploaded_files):
                        st.write(f"üîÑ Traitement de {uploaded_file.name}...")
                        
                        try:
                            df_batch = pd.read_csv(uploaded_file)
                            X_batch = df_batch.values
                            
                            predictions = selected_model.predict(X_batch)
                            probabilities = selected_model.predict_proba(X_batch)
                            
                            batch_results.append({
                                'filename': uploaded_file.name,
                                'n_samples': len(predictions),
                                'predictions': predictions,
                                'avg_confidence': np.mean([max(prob) for prob in probabilities])
                            })
                            
                            progress_bar.progress((i + 1) / len(uploaded_files))
                            
                        except Exception as e:
                            st.error(f"‚ùå Erreur avec {uploaded_file.name}: {str(e)}")
                    
                    # R√©sum√© des r√©sultats
                    if batch_results:
                        st.success("‚úÖ Traitement par lots termin√©!")
                        
                        summary_df = pd.DataFrame([
                            {
                                'Fichier': r['filename'],
                                '√âchantillons': r['n_samples'],
                                'Confiance Moyenne': f"{r['avg_confidence']:.2%}"
                            }
                            for r in batch_results
                        ])
                        
                        st.dataframe(summary_df, use_container_width=True)
                        
                        # Sauvegarder les r√©sultats de batch
                        st.session_state['batch_results'] = batch_results
        
        else:
            st.info("üöß Traitement de dossier √† impl√©menter")
    
    else:
        st.info("‚ÑπÔ∏è S√©lectionnez un mod√®le pour le traitement en lot.")

with tab3:
    st.header("Analyse des Pr√©dictions")
    
    # Analyse des derni√®res pr√©dictions
    if 'last_predictions' in st.session_state:
        last_pred = st.session_state['last_predictions']
        
        st.subheader(f"üìà Derni√®re Pr√©diction ({last_pred['model_name']})")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("√âchantillons", last_pred['n_samples'])
        
        with col2:
            confidence_mean = np.mean([max(prob) for prob in last_pred['probabilities']])
            st.metric("Confiance Moyenne", f"{confidence_mean:.2%}")
        
        with col3:
            timestamp = last_pred['timestamp']
            st.metric("Horodatage", timestamp.strftime("%H:%M:%S"))
        
        # Analyse de la distribution des classes
        st.subheader("üè∑Ô∏è Distribution des Classes Pr√©dites")
        
        pred_counts = pd.Series(last_pred['predictions']).value_counts().sort_index()
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.bar_chart(pred_counts)
        
        with col2:
            # Tableau de fr√©quences
            freq_df = pd.DataFrame({
                'Classe': pred_counts.index,
                'Nombre': pred_counts.values,
                'Pourcentage': [f"{(count/sum(pred_counts.values)*100):.1f}%" 
                              for count in pred_counts.values]
            })
            st.dataframe(freq_df, use_container_width=True)
        
        # Analyse de confiance par classe
        st.subheader("üéØ Confiance par Classe")
        
        confidence_by_class = {}
        for i, pred in enumerate(last_pred['predictions']):
            prob = last_pred['probabilities'][i]
            confidence = max(prob)
            
            if pred not in confidence_by_class:
                confidence_by_class[pred] = []
            confidence_by_class[pred].append(confidence)
        
        conf_stats = []
        for classe, confidences in confidence_by_class.items():
            conf_stats.append({
                'Classe': classe,
                'Confiance Moy.': np.mean(confidences),
                'Confiance Min': np.min(confidences),
                'Confiance Max': np.max(confidences),
                '√âcart-type': np.std(confidences)
            })
        
        conf_df = pd.DataFrame(conf_stats)
        st.dataframe(conf_df, use_container_width=True)
        
        # Histogramme des confidences
        st.subheader("üìä Distribution des Confidences")
        
        all_confidences = [max(prob) for prob in last_pred['probabilities']]
        confidence_hist_df = pd.DataFrame({'Confiance': all_confidences})
        
        st.histogram(confidence_hist_df['Confiance'], bins=20)
        
        # √âchantillons peu confiants
        st.subheader("‚ö†Ô∏è √âchantillons √† Faible Confiance")
        
        low_confidence_threshold = st.slider(
            "Seuil de confiance",
            0.0, 1.0, 0.7,
            help="Afficher les √©chantillons en dessous de ce seuil"
        )
        
        low_conf_indices = [i for i, conf in enumerate(all_confidences) 
                           if conf < low_confidence_threshold]
        
        if low_conf_indices:
            st.warning(f"‚ö†Ô∏è {len(low_conf_indices)} √©chantillon(s) avec confiance < {low_confidence_threshold}")
            
            low_conf_df = pd.DataFrame({
                'Index': low_conf_indices,
                'Pr√©diction': [last_pred['predictions'][i] for i in low_conf_indices],
                'Confiance': [all_confidences[i] for i in low_conf_indices]
            })
            
            st.dataframe(low_conf_df, use_container_width=True)
        
        else:
            st.success(f"‚úÖ Tous les √©chantillons ont une confiance ‚â• {low_confidence_threshold}")
    
    else:
        st.info("""
        ‚ÑπÔ∏è **Analyse des Pr√©dictions**
        
        Effectuez d'abord des pr√©dictions pour voir l'analyse d√©taill√©e.
        
        L'analyse inclura:
        - Distribution des classes pr√©dites
        - Statistiques de confiance par classe
        - Identification des √©chantillons peu confiants
        - Visualisations interactives
        """)