import streamlit as st
import time
import pandas as pd
import numpy as np
import psutil
import gc
from datetime import datetime, timedelta
import threading
import plotly.express as px
import plotly.graph_objects as go

st.header("âš¡ T_08 - Optimisation des Performances")

st.markdown("**ğŸ“‹ Objectif :** MaÃ®triser l'optimisation complÃ¨te des applications Streamlit : cache intelligent, monitoring systÃ¨me, gestion mÃ©moire, et techniques avancÃ©es pour crÃ©er des applications ultra-performantes et scalables.")

st.markdown("---")

# ================================
# 1. STRATÃ‰GIES DE CACHE AVANCÃ‰ES
# ================================
st.subheader("1ï¸âƒ£ StratÃ©gies de cache avancÃ©es")

st.markdown("""
**ğŸ“– Description :**
Le cache est l'arme secrÃ¨te des applications performantes. Au-delÃ  du simple stockage,
une stratÃ©gie de cache intelligente peut transformer une application lente en solution
ultra-rÃ©active. Streamlit offre des outils puissants pour optimiser chaque aspect.

**ğŸ¯ Types de cache et leurs usages :**
- **`@st.cache_data`** : DonnÃ©es sÃ©rialisables (DataFrames, listes, rÃ©sultats calculs)
- **`@st.cache_resource`** : Ressources non-sÃ©rialisables (connexions DB, modÃ¨les ML)
- **Cache conditionnel** : Invalidation basÃ©e sur paramÃ¨tres mÃ©tier
- **Cache hiÃ©rarchique** : DiffÃ©rents niveaux de cache selon la criticitÃ©
- **Cache partagÃ©** : Optimisation pour applications multi-utilisateurs

**ğŸ’¡ StratÃ©gies d'optimisation :**
- TTL adaptatif selon la frÃ©quence de mise Ã  jour des donnÃ©es
- PrÃ©-calcul des rÃ©sultats les plus frÃ©quents
- Cache en cascade pour optimiser les dÃ©pendances
- Monitoring des hit/miss ratios pour ajustements
- Ã‰viction intelligente des donnÃ©es pÃ©rimÃ©es
""")

col1, col2 = st.columns(2)

with col1:
    st.markdown("#### ğŸ’» Code")
    st.code('''
# Cache de donnÃ©es avec TTL adaptatif
@st.cache_data(
    ttl=3600,  # 1 heure pour donnÃ©es statiques
    max_entries=100,
    show_spinner="Chargement des donnÃ©es..."
)
def load_business_data(data_type, filters=None):
    """Cache intelligent pour donnÃ©es mÃ©tier"""
    start_time = time.time()
    
    # Simulation chargement selon le type
    if data_type == "sales":
        time.sleep(1.5)  # Simulation requÃªte DB lourde
        np.random.seed(42)
        data = pd.DataFrame({
            'Date': pd.date_range('2024-01-01', periods=365),
            'Ventes': np.cumsum(np.random.randn(365) * 100) + 10000,
            'Produit': np.random.choice(['A', 'B', 'C'], 365)
        })
    elif data_type == "customers":
        time.sleep(1.0)
        data = pd.DataFrame({
            'ID': range(1000),
            'Age': np.random.randint(18, 70, 1000),
            'Segment': np.random.choice(['Premium', 'Standard', 'Basic'], 1000)
        })
    else:
        time.sleep(0.5)
        data = pd.DataFrame({'empty': []})
    
    # Appliquer les filtres si fournis
    if filters and not data.empty:
        for filter_col, filter_val in filters.items():
            if filter_col in data.columns:
                data = data[data[filter_col] == filter_val]
    
    processing_time = time.time() - start_time
    st.info(f"â±ï¸ Temps de traitement: {processing_time:.2f}s")
    
    return data

# Cache de ressources pour modÃ¨les/connexions
@st.cache_resource
def initialize_ml_model():
    """Cache pour ressources lourdes"""
    time.sleep(2)  # Simulation chargement modÃ¨le
    return {
        'model_type': 'RandomForest',
        'accuracy': 0.95,
        'features': ['feature_1', 'feature_2', 'feature_3'],
        'loaded_at': datetime.now().isoformat()
    }

# Cache conditionnel avec hash_funcs personnalisÃ©s
@st.cache_data(
    ttl=600,  # 10 minutes
    max_entries=50,
    hash_funcs={dict: lambda x: str(sorted(x.items()))}
)
def compute_advanced_metrics(data_dict, calculation_type):
    """Cache pour calculs mÃ©tier complexes"""
    time.sleep(1)  # Simulation calcul intensif
    
    if calculation_type == "aggregation":
        result = {
            'total': sum(data_dict.values()),
            'average': np.mean(list(data_dict.values())),
            'max': max(data_dict.values()),
            'min': min(data_dict.values())
        }
    elif calculation_type == "forecast":
        values = list(data_dict.values())
        trend = np.polyfit(range(len(values)), values, 1)[0]
        result = {
            'trend': trend,
            'next_month': values[-1] + trend,
            'confidence': 0.85
        }
    else:
        result = {'error': 'Unknown calculation type'}
    
    return result

# Interface de dÃ©monstration
st.markdown("**ğŸš€ Test des Caches AvancÃ©s**")

# SÃ©lection du type de donnÃ©es
data_type = st.selectbox(
    "Type de donnÃ©es Ã  charger:",
    ["sales", "customers", "analytics"],
    help="Chaque type a un temps de chargement diffÃ©rent"
)

# Options de filtrage
with st.expander("ğŸ” Filtres avancÃ©s"):
    filter_options = {}
    if data_type == "sales":
        product_filter = st.selectbox("Produit:", ["Tous", "A", "B", "C"])
        if product_filter != "Tous":
            filter_options["Produit"] = product_filter
    elif data_type == "customers":
        segment_filter = st.selectbox("Segment:", ["Tous", "Premium", "Standard", "Basic"])
        if segment_filter != "Tous":
            filter_options["Segment"] = segment_filter

# Boutons de test de cache
col_cache1, col_cache2, col_cache3 = st.columns(3)

with col_cache1:
    if st.button("ğŸ“Š Charger DonnÃ©es", type="primary"):
        start_load = time.time()
        data = load_business_data(data_type, filter_options if filter_options else None)
        end_load = time.time()
        
        st.success(f"âœ… DonnÃ©es chargÃ©es en {end_load - start_load:.2f}s")
        st.dataframe(data.head(), use_container_width=True)
        st.info(f"ğŸ“ˆ {len(data)} lignes chargÃ©es")

with col_cache2:
    if st.button("ğŸ¤– Initialiser ModÃ¨le"):
        model_info = initialize_ml_model()
        st.json(model_info)
        st.success("ğŸ¯ ModÃ¨le prÃªt (mis en cache pour rÃ©utilisation)")

with col_cache3:
    if st.button("ğŸ“Š Calculs AvancÃ©s"):
        # DonnÃ©es d'exemple pour calculs
        sample_data = {
            'jan': 1000, 'feb': 1200, 'mar': 1100, 
            'apr': 1300, 'may': 1250, 'jun': 1400
        }
        
        calc_type = st.radio("Type de calcul:", ["aggregation", "forecast"], horizontal=True)
        
        results = compute_advanced_metrics(sample_data, calc_type)
        st.json(results)

# Gestion du cache
st.markdown("**ğŸ› ï¸ Gestion du Cache**")
cache_cols = st.columns(3)

with cache_cols[0]:
    if st.button("ğŸ—‘ï¸ Vider Cache DonnÃ©es"):
        st.cache_data.clear()
        st.success("Cache donnÃ©es vidÃ©!")

with cache_cols[1]:
    if st.button("ğŸ—‘ï¸ Vider Cache Ressources"):
        st.cache_resource.clear()
        st.success("Cache ressources vidÃ©!")

with cache_cols[2]:
    # Statistiques de cache (simulation)
    st.metric("Cache Hits", "ğŸ”¥ 87%", "â†—ï¸ +5%")
''', language="python")

with col2:
    st.markdown("#### ğŸ¯ RÃ©sultat")
    
    # DÃ©monstration simplifiÃ©e des caches
    @st.cache_data(ttl=300)
    def demo_load_data(data_size):
        time.sleep(0.5)  # Simulation charge
        np.random.seed(42)
        return pd.DataFrame({
            'ID': range(data_size),
            'Valeur': np.random.randn(data_size) * 100,
            'CatÃ©gorie': np.random.choice(['A', 'B', 'C'], data_size)
        })
    
    @st.cache_resource  
    def demo_init_resource():
        time.sleep(0.3)
        return {'status': 'ready', 'version': '1.0'}
    
    st.markdown("**âš¡ Tests Cache**")
    
    demo_size = st.slider("Taille des donnÃ©es", 10, 1000, 100, key="demo_cache_size")
    
    if st.button("ğŸ”„ Charger (avec cache)", key="demo_cache_load"):
        start = time.time()
        data = demo_load_data(demo_size)
        end = time.time()
        
        st.success(f"âœ… ChargÃ© en {end-start:.3f}s")
        st.write(f"ğŸ“Š {len(data)} lignes")
        st.dataframe(data.head(3))
        
        if end - start < 0.1:
            st.info("âš¡ DonnÃ©es servies depuis le cache!")
    
    if st.button("ğŸ›ï¸ Initialiser Ressource", key="demo_resource"):
        resource = demo_init_resource()
        st.json(resource)
    
    # Stats de cache simplifiÃ©
    demo_stats_col1, demo_stats_col2 = st.columns(2)
    with demo_stats_col1:
        st.metric("Cache Data", "Actif", "âœ…")
    with demo_stats_col2:
        st.metric("Cache Resource", "Actif", "âœ…")

st.divider()

# ================================
# 2. MONITORING SYSTÃˆME ET PERFORMANCE
# ================================
st.subheader("2ï¸âƒ£ Monitoring systÃ¨me et performance")

st.markdown("""
**ğŸ“– Description :**
Le monitoring en temps rÃ©el est essentiel pour maintenir des performances optimales.
Il permet de dÃ©tecter les goulots d'Ã©tranglement, d'anticiper les problÃ¨mes de capacitÃ©,
et d'optimiser l'allocation des ressources pour une expÃ©rience utilisateur fluide.

**ğŸ¯ MÃ©triques critiques Ã  surveiller :**
- **CPU et MÃ©moire** : Utilisation des ressources systÃ¨me
- **Temps de rÃ©ponse** : Latence des opÃ©rations critiques
- **Cache hit ratio** : EfficacitÃ© du systÃ¨me de cache
- **Concurrent users** : Charge utilisateur simultanÃ©e
- **Error rates** : Taux d'erreur et stabilitÃ©

**ğŸ’¡ Techniques d'optimisation :**
- Alertes proactives sur les seuils critiques
- Auto-scaling basÃ© sur la charge
- Profilage des fonctions les plus coÃ»teuses
- Optimisation des requÃªtes et calculs
- Load balancing intelligent
""")

col1, col2 = st.columns(2)

with col1:
    st.markdown("#### ğŸ’» Code")
    st.code('''
# Monitoring des ressources systÃ¨me
def get_system_metrics():
    """Collecte des mÃ©triques systÃ¨me"""
    cpu_percent = psutil.cpu_percent(interval=1)
    memory = psutil.virtual_memory()
    disk = psutil.disk_usage('/')
    
    return {
        'cpu_percent': cpu_percent,
        'memory_percent': memory.percent,
        'memory_available_gb': memory.available / (1024**3),
        'disk_percent': disk.percent,
        'disk_free_gb': disk.free / (1024**3)
    }

# Profilage de performance
def profile_function_performance(func, *args, **kwargs):
    """Profile les performances d'une fonction"""
    import tracemalloc
    
    # DÃ©marrer le monitoring mÃ©moire
    tracemalloc.start()
    start_time = time.time()
    start_memory = psutil.Process().memory_info().rss
    
    # ExÃ©cuter la fonction
    result = func(*args, **kwargs)
    
    # Mesurer les ressources
    end_time = time.time()
    end_memory = psutil.Process().memory_info().rss
    current, peak = tracemalloc.get_traced_memory()
    tracemalloc.stop()
    
    metrics = {
        'execution_time': end_time - start_time,
        'memory_delta_mb': (end_memory - start_memory) / (1024*1024),
        'peak_memory_mb': peak / (1024*1024),
        'success': True
    }
    
    return result, metrics

# Dashboard de monitoring en temps rÃ©el
def create_performance_dashboard():
    """CrÃ©e un dashboard de monitoring"""
    
    # MÃ©triques systÃ¨me actuelles
    metrics = get_system_metrics()
    
    # Affichage des mÃ©triques principales
    metric_cols = st.columns(4)
    
    with metric_cols[0]:
        cpu_color = "ğŸ”´" if metrics['cpu_percent'] > 80 else "ğŸŸ¡" if metrics['cpu_percent'] > 60 else "ğŸŸ¢"
        st.metric(
            f"{cpu_color} CPU", 
            f"{metrics['cpu_percent']:.1f}%",
            help="Utilisation CPU actuelle"
        )
    
    with metric_cols[1]:
        mem_color = "ğŸ”´" if metrics['memory_percent'] > 85 else "ğŸŸ¡" if metrics['memory_percent'] > 70 else "ğŸŸ¢"
        st.metric(
            f"{mem_color} MÃ©moire", 
            f"{metrics['memory_percent']:.1f}%",
            f"({metrics['memory_available_gb']:.1f}GB libre)"
        )
    
    with metric_cols[2]:
        disk_color = "ğŸ”´" if metrics['disk_percent'] > 90 else "ğŸŸ¡" if metrics['disk_percent'] > 80 else "ğŸŸ¢"
        st.metric(
            f"{disk_color} Disque", 
            f"{metrics['disk_percent']:.1f}%",
            f"({metrics['disk_free_gb']:.1f}GB libre)"
        )
    
    with metric_cols[3]:
        # Simulation charge utilisateur
        current_users = np.random.randint(5, 25)
        user_color = "ğŸ”´" if current_users > 20 else "ğŸŸ¡" if current_users > 15 else "ğŸŸ¢"
        st.metric(f"{user_color} Utilisateurs", current_users)
    
    return metrics

# Fonction de test pour le profilage
@st.cache_data
def heavy_computation(n_iterations, use_cache=True):
    """Simulation calcul intensif pour tests de performance"""
    result = 0
    for i in range(n_iterations):
        result += np.sum(np.random.randn(1000))
    return result

# Interface de monitoring
st.markdown("**ğŸ“Š Dashboard de Monitoring**")

# Actualisation automatique
auto_refresh = st.checkbox("ğŸ”„ Actualisation automatique (5s)", value=False)

if auto_refresh:
    # Placeholder pour refresh automatique
    dashboard_placeholder = st.empty()
    
    with dashboard_placeholder.container():
        metrics = create_performance_dashboard()
        st.caption(f"DerniÃ¨re mise Ã  jour: {datetime.now().strftime('%H:%M:%S')}")
else:
    if st.button("ğŸ”„ Actualiser MÃ©triques"):
        metrics = create_performance_dashboard()

# Test de performance avec profilage
st.markdown("**âš™ï¸ Test de Performance avec Profilage**")

test_cols = st.columns(2)

with test_cols[0]:
    iterations = st.slider("Nombre d'itÃ©rations", 100, 10000, 1000)
    use_cache_test = st.checkbox("Utiliser le cache", value=True)

with test_cols[1]:
    if st.button("ğŸš€ Lancer Test de Performance"):
        with st.spinner("Test en cours..."):
            result, perf_metrics = profile_function_performance(
                heavy_computation, iterations, use_cache_test
            )
        
        st.success("âœ… Test terminÃ©!")
        
        # Affichage des rÃ©sultats de performance
        perf_result_cols = st.columns(3)
        
        with perf_result_cols[0]:
            st.metric("Temps d'exÃ©cution", f"{perf_metrics['execution_time']:.3f}s")
        
        with perf_result_cols[1]:
            st.metric("MÃ©moire utilisÃ©e", f"{perf_metrics['memory_delta_mb']:.1f}MB")
        
        with perf_result_cols[2]:
            st.metric("Pic mÃ©moire", f"{perf_metrics['peak_memory_mb']:.1f}MB")
        
        # Recommandations basÃ©es sur les mÃ©triques
        if perf_metrics['execution_time'] > 2.0:
            st.warning("âš ï¸ Temps d'exÃ©cution Ã©levÃ© - ConsidÃ©rez l'optimisation")
        if perf_metrics['memory_delta_mb'] > 100:
            st.warning("âš ï¸ Consommation mÃ©moire importante - VÃ©rifiez les fuites")
        if perf_metrics['execution_time'] < 0.1:
            st.info("âš¡ Excellent! Optimisation rÃ©ussie")
''', language="python")

with col2:
    st.markdown("#### ğŸ¯ RÃ©sultat")
    
    # Monitoring simplifiÃ© pour la dÃ©mo
    def demo_get_metrics():
        return {
            'cpu': np.random.uniform(20, 80),
            'memory': np.random.uniform(40, 85),
            'users': np.random.randint(3, 15)
        }
    
    st.markdown("**ğŸ“Š Monitoring Demo**")
    
    if st.button("ğŸ“ˆ VÃ©rifier SystÃ¨me", key="demo_monitoring"):
        demo_metrics = demo_get_metrics()
        
        demo_metric_cols = st.columns(3)
        
        with demo_metric_cols[0]:
            cpu_status = "ğŸŸ¢" if demo_metrics['cpu'] < 60 else "ğŸŸ¡" if demo_metrics['cpu'] < 80 else "ğŸ”´"
            st.metric(f"{cpu_status} CPU", f"{demo_metrics['cpu']:.1f}%")
        
        with demo_metric_cols[1]:
            mem_status = "ğŸŸ¢" if demo_metrics['memory'] < 70 else "ğŸŸ¡" if demo_metrics['memory'] < 85 else "ğŸ”´"
            st.metric(f"{mem_status} RAM", f"{demo_metrics['memory']:.1f}%")
        
        with demo_metric_cols[2]:
            user_status = "ğŸŸ¢" if demo_metrics['users'] < 10 else "ğŸŸ¡"
            st.metric(f"{user_status} Users", demo_metrics['users'])
    
    # Test de performance simplifiÃ©
    st.markdown("**âš¡ Test Performance**")
    
    demo_iterations = st.slider("ItÃ©rations de test", 10, 100, 50, key="demo_perf_iterations")
    
    if st.button("ğŸ§ª Tester", key="demo_perf_test"):
        start_demo = time.time()
        
        # Simulation calcul
        result = sum(range(demo_iterations * 100))
        
        end_demo = time.time()
        execution_time = end_demo - start_demo
        
        st.success(f"âœ… TerminÃ© en {execution_time:.3f}s")
        
        # Ã‰valuation performance
        if execution_time < 0.01:
            st.info("âš¡ Excellent!")
        elif execution_time < 0.1:
            st.info("ğŸ‘ Bon")
        else:
            st.warning("âš ï¸ Optimisation possible")

st.divider()

# ================================
# 3. OPTIMISATION MÃ‰MOIRE ET GARBAGE COLLECTION
# ================================
st.subheader("3ï¸âƒ£ Optimisation mÃ©moire et garbage collection")

st.markdown("""
**ğŸ“– Description :**
La gestion intelligente de la mÃ©moire est cruciale pour maintenir des performances stables,
surtout dans les applications avec de gros volumes de donnÃ©es ou des sessions utilisateur longues.
Une stratÃ©gie d'optimisation mÃ©moire Ã©vite les fuites et maintient la rÃ©activitÃ©.

**ğŸ¯ Techniques d'optimisation mÃ©moire :**
- **Garbage Collection manuel** : LibÃ©ration proactive de la mÃ©moire
- **Weak references** : RÃ©fÃ©rences qui n'empÃªchent pas le GC
- **Memory profiling** : DÃ©tection des fuites et optimisations
- **Lazy loading** : Chargement Ã  la demande pour Ã©conomiser la RAM
- **Data chunking** : Traitement par blocs pour gros datasets

**ğŸ’¡ StratÃ©gies avancÃ©es :**
- Session state cleanup automatique
- Cache size limits adaptatifs
- Monitoring des memory leaks
- Optimisation des structures de donnÃ©es
- Compression en mÃ©moire pour gros volumes
""")

col1, col2 = st.columns(2)

with col1:
    st.markdown("#### ğŸ’» Code")
    st.code('''
# Utilitaires de gestion mÃ©moire
def get_memory_usage():
    """Analyse dÃ©taillÃ©e de l'usage mÃ©moire"""
    process = psutil.Process()
    memory_info = process.memory_info()
    memory_percent = process.memory_percent()
    
    return {
        'rss_mb': memory_info.rss / (1024 * 1024),  # Resident Set Size
        'vms_mb': memory_info.vms / (1024 * 1024),  # Virtual Memory Size
        'percent': memory_percent,
        'available_mb': psutil.virtual_memory().available / (1024 * 1024)
    }

def optimize_session_state():
    """Nettoyage intelligent du session state"""
    keys_to_remove = []
    total_size = 0
    
    for key, value in st.session_state.items():
        # Calculer la taille approximative
        try:
            import sys
            size = sys.getsizeof(value)
            total_size += size
            
            # Marquer pour suppression si trop ancien ou gros
            if key.startswith('temp_') or size > 10 * 1024 * 1024:  # 10MB
                keys_to_remove.append(key)
        except:
            pass
    
    # Nettoyer les clÃ©s identifiÃ©es
    for key in keys_to_remove:
        if key in st.session_state:
            del st.session_state[key]
    
    return len(keys_to_remove), total_size

def process_large_dataset_chunked(data, chunk_size=1000):
    """Traitement par chunks pour Ã©conomiser la mÃ©moire"""
    results = []
    
    for i in range(0, len(data), chunk_size):
        chunk = data.iloc[i:i+chunk_size] if hasattr(data, 'iloc') else data[i:i+chunk_size]
        
        # Traitement du chunk
        processed_chunk = chunk.copy() if hasattr(chunk, 'copy') else list(chunk)
        
        # Simulation traitement
        time.sleep(0.01)  # Simulation calcul
        
        results.append(processed_chunk)
        
        # LibÃ©ration mÃ©moire explicite
        del chunk, processed_chunk
        
        # Force garbage collection pÃ©riodique
        if i % (chunk_size * 5) == 0:
            gc.collect()
    
    return results

# Interface de gestion mÃ©moire
st.markdown("**ğŸ§  Gestionnaire de MÃ©moire**")

# Monitoring mÃ©moire en temps rÃ©el
if st.button("ğŸ“Š Analyser MÃ©moire Actuelle"):
    memory_stats = get_memory_usage()
    
    mem_cols = st.columns(4)
    
    with mem_cols[0]:
        st.metric("RSS", f"{memory_stats['rss_mb']:.1f} MB", 
                 help="MÃ©moire physique rÃ©ellement utilisÃ©e")
    
    with mem_cols[1]:
        st.metric("VMS", f"{memory_stats['vms_mb']:.1f} MB",
                 help="MÃ©moire virtuelle totale")
    
    with mem_cols[2]:
        st.metric("Utilisation", f"{memory_stats['percent']:.1f}%",
                 help="Pourcentage de mÃ©moire systÃ¨me utilisÃ©e")
    
    with mem_cols[3]:
        st.metric("Disponible", f"{memory_stats['available_mb']:.0f} MB",
                 help="MÃ©moire systÃ¨me disponible")

# Test de traitement par chunks
st.markdown("**âš™ï¸ Test Traitement par Chunks**")

chunk_test_cols = st.columns(2)

with chunk_test_cols[0]:
    data_size = st.slider("Taille du dataset", 1000, 50000, 10000, step=1000)
    chunk_size = st.slider("Taille des chunks", 100, 5000, 1000, step=100)

with chunk_test_cols[1]:
    if st.button("ğŸš€ Test Chunked Processing"):
        # CrÃ©er un dataset de test
        test_data = pd.DataFrame({
            'id': range(data_size),
            'value': np.random.randn(data_size),
            'category': np.random.choice(['A', 'B', 'C'], data_size)
        })
        
        # Mesurer la mÃ©moire avant
        memory_before = get_memory_usage()
        
        # Traitement par chunks
        with st.spinner("Traitement en cours..."):
            start_time = time.time()
            results = process_large_dataset_chunked(test_data, chunk_size)
            end_time = time.time()
        
        # Mesurer la mÃ©moire aprÃ¨s
        memory_after = get_memory_usage()
        
        st.success(f"âœ… TraitÃ© en {end_time - start_time:.2f}s")
        
        # Afficher les stats
        processing_cols = st.columns(3)
        
        with processing_cols[0]:
            st.metric("Chunks traitÃ©s", len(results))
        
        with processing_cols[1]:
            memory_delta = memory_after['rss_mb'] - memory_before['rss_mb']
            st.metric("Delta mÃ©moire", f"{memory_delta:+.1f} MB")
        
        with processing_cols[2]:
            throughput = data_size / (end_time - start_time)
            st.metric("DÃ©bit", f"{throughput:.0f} lignes/s")

# Nettoyage et optimisation
st.markdown("**ğŸ§¹ Nettoyage et Optimisation**")

cleanup_cols = st.columns(3)

with cleanup_cols[0]:
    if st.button("ğŸ—‘ï¸ Nettoyer Session State"):
        removed_count, total_size = optimize_session_state()
        st.success(f"âœ… {removed_count} clÃ©s supprimÃ©es")
        st.info(f"ğŸ“Š Taille totale analysÃ©e: {total_size / (1024*1024):.1f} MB")

with cleanup_cols[1]:
    if st.button("â™»ï¸ Force Garbage Collection"):
        # Mesurer avant
        memory_before_gc = get_memory_usage()
        
        # Forcer le garbage collection
        collected = gc.collect()
        
        # Mesurer aprÃ¨s
        memory_after_gc = get_memory_usage()
        memory_freed = memory_before_gc['rss_mb'] - memory_after_gc['rss_mb']
        
        st.success(f"âœ… {collected} objets collectÃ©s")
        if memory_freed > 0:
            st.info(f"ğŸ†“ {memory_freed:.1f} MB libÃ©rÃ©s")
        else:
            st.info("ğŸ’š MÃ©moire dÃ©jÃ  optimisÃ©e")

with cleanup_cols[2]:
    # Statistiques du garbage collector
    gc_stats = gc.get_stats()
    if gc_stats:
        st.metric("GC GÃ©nÃ©ration 0", gc_stats[0]['collections'])
''', language="python")

with col2:
    st.markdown("#### ğŸ¯ RÃ©sultat")
    
    # Simulation monitoring mÃ©moire
    st.markdown("**ğŸ§  Monitoring MÃ©moire**")
    
    if st.button("ğŸ” Analyser", key="demo_memory"):
        # Simulation mÃ©triques mÃ©moire
        demo_rss = np.random.uniform(50, 150)
        demo_percent = np.random.uniform(30, 80)
        
        demo_mem_cols = st.columns(2)
        
        with demo_mem_cols[0]:
            st.metric("MÃ©moire utilisÃ©e", f"{demo_rss:.1f} MB")
        
        with demo_mem_cols[1]:
            mem_status = "ğŸŸ¢" if demo_percent < 70 else "ğŸŸ¡" if demo_percent < 85 else "ğŸ”´"
            st.metric(f"{mem_status} Utilisation", f"{demo_percent:.1f}%")
    
    # Test de chunking simplifiÃ©
    st.markdown("**âš™ï¸ Test Chunking**")
    
    demo_data_size = st.slider("Taille test", 100, 1000, 500, key="demo_chunk_size")
    
    if st.button("ğŸ§ª Test Chunking", key="demo_chunk_test"):
        start_chunk = time.time()
        
        # Simulation traitement par chunks
        chunks_count = demo_data_size // 100
        
        progress_bar = st.progress(0)
        for i in range(chunks_count):
            progress_bar.progress((i + 1) / chunks_count)
            time.sleep(0.05)
        
        end_chunk = time.time()
        
        st.success(f"âœ… {chunks_count} chunks traitÃ©s en {end_chunk - start_chunk:.2f}s")
        st.info("ğŸ’¡ MÃ©moire optimisÃ©e par traitement sÃ©quentiel")
    
    # Nettoyage demo
    st.markdown("**ğŸ§¹ Nettoyage**")
    
    demo_cleanup_cols = st.columns(2)
    
    with demo_cleanup_cols[0]:
        if st.button("ğŸ—‘ï¸ Nettoyer", key="demo_cleanup"):
            st.success("âœ… Session nettoyÃ©e")
    
    with demo_cleanup_cols[1]:
        if st.button("â™»ï¸ GC", key="demo_gc"):
            st.success("âœ… MÃ©moire optimisÃ©e")

st.markdown("---")

st.success("ğŸ‰ **FÃ©licitations !** Vous maÃ®trisez maintenant l'optimisation complÃ¨te des performances Streamlit !")

st.markdown("""
**ğŸš€ Points clÃ©s Ã  retenir :**

**âš¡ Cache AvancÃ© :**
- Utilisez `@st.cache_data` pour les donnÃ©es et `@st.cache_resource` pour les ressources
- Configurez TTL et max_entries selon vos besoins
- ImplÃ©mentez des stratÃ©gies de cache hiÃ©rarchique
- Monitorer les hit/miss ratios pour optimiser

**ğŸ“Š Monitoring SystÃ¨me :**
- Surveillez CPU, mÃ©moire, et charge utilisateur
- Profilez les fonctions critiques pour identifier les goulots
- ImplÃ©mentez des alertes proactives sur les seuils
- Optimisez basÃ© sur les mÃ©triques rÃ©elles

**ğŸ§  Gestion MÃ©moire :**
- Nettoyez rÃ©guliÃ¨rement le session state
- Utilisez le traitement par chunks pour gros volumes
- Forcez le garbage collection si nÃ©cessaire
- Monitoring continu pour Ã©viter les fuites

**ğŸ”— Prochaine Ã©tape :** DÃ©couvrez T_09_Astuces pour les techniques avancÃ©es et les secrets de dÃ©veloppement !
""")
