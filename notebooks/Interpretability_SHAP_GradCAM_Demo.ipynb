{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16746e7",
   "metadata": {},
   "source": [
    "# üîç Interpr√©tabilit√© des Mod√®les COVID-19 avec SHAP, GradCAM et LIME\n",
    "\n",
    "Ce notebook d√©montre l'utilisation des techniques d'interpr√©tabilit√© **SHAP**, **GradCAM** et **LIME** pour expliquer les pr√©dictions des mod√®les de classification COVID-19.\n",
    "\n",
    "## üìã Objectifs\n",
    "\n",
    "1. **üéØ GradCAM** : Visualiser les zones importantes pour les pr√©dictions CNN\n",
    "2. **üìä SHAP** : Quantifier l'importance des features pour tous types de mod√®les\n",
    "3. **üçÉ LIME** : Explications locales par superpixels pour mod√®les image\n",
    "4. **‚öñÔ∏è Comparaison** : Analyser la coh√©rence entre les diff√©rentes m√©thodes\n",
    "5. **üè• Application** : Cas d'usage m√©dical pour le diagnostic COVID-19\n",
    "\n",
    "## üöÄ Framework RAF\n",
    "\n",
    "Nous utilisons le **framework RAF** (Raw Augmentation Framework) qui int√®gre maintenant les modules d'interpr√©tabilit√© :\n",
    "- `raf.interpretability.SHAPExplainer` - Explications SHAP universelles\n",
    "- `raf.interpretability.GradCAMExplainer` - Visualisations GradCAM pour CNN\n",
    "- `raf.interpretability.LIMEExplainer` - Explications LIME par superpixels\n",
    "- `raf.interpretability.InterpretabilityAnalyzer` - Analyse comparative\n",
    "- `raf.data.DataLoader` - Chargement de vos vraies donn√©es COVID-19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2002ae",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18daafb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Chargement de la configuration .env...\n",
      "‚úÖ Configuration charg√©e depuis: /home/cepa/DST/projet_DS/DS_COVID/.env\n",
      "üìÅ R√©pertoire de travail: /home/cepa/DST/projet_DS/DS_COVID\n",
      "üéØ R√©pertoire source: /home/cepa/DST/projet_DS/DS_COVID\n",
      "üîß Configuration du framework RAF...\n",
      "‚úÖ Configuration de base termin√©e\n",
      "‚úÖ Configuration de base termin√©e\n"
     ]
    }
   ],
   "source": [
    "# Configuration universelle avec le framework RAF\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Chargement des variables d'environnement\n",
    "print(\"üîß Chargement de la configuration .env...\")\n",
    "\n",
    "# D√©tection automatique du r√©pertoire racine\n",
    "current_dir = Path().cwd()\n",
    "if 'notebooks' in str(current_dir):\n",
    "    project_root = current_dir.parent\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "# Chargement du fichier .env\n",
    "env_path = project_root / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"‚úÖ Configuration charg√©e depuis: {env_path}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Fichier .env non trouv√©: {env_path}\")\n",
    "\n",
    "# Configuration du PYTHONPATH avec les variables d'environnement\n",
    "src_root = os.getenv('PROJECT_ROOT', str(project_root))\n",
    "if src_root not in sys.path:\n",
    "    sys.path.insert(0, src_root)\n",
    "\n",
    "print(f\"üìÅ R√©pertoire de travail: {project_root}\")\n",
    "print(f\"üéØ R√©pertoire source: {src_root}\")\n",
    "print(\"üîß Configuration du framework RAF...\")\n",
    "\n",
    "# Imports standards\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration graphiques depuis .env\n",
    "plot_style = os.getenv('PLOT_STYLE', 'default')\n",
    "color_palette = os.getenv('COLOR_PALETTE', 'husl')\n",
    "\n",
    "try:\n",
    "    plt.style.use(plot_style)\n",
    "except:\n",
    "    plt.style.use('default')\n",
    "    \n",
    "sns.set_palette(color_palette)\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuration warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Configuration de base termin√©e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7246f24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ R√©pertoire projet: /home/cepa/DST/projet_DS/DS_COVID\n",
      "üêç PYTHONPATH ajust√©\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 22:16:40.789604: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® RAF (Raw Augmentation Framework) v2.0.0 charg√© avec succ√®s\n",
      "‚ú® NOUVELLE FONCTIONNALIT√â: setup_universal_environment() remplace la cellule 1!\n",
      "ÔøΩ NOUVEAU MODULE: interpretability (SHAP + GradCAM)\n",
      "ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ Modules disponibles: utils, data, augmentation, interpretability\n",
      "‚úÖ Modules RAF d'interpr√©tabilit√© charg√©s (SHAP, GradCAM, LIME)\n",
      "‚úÖ DataLoader RAF charg√©\n",
      "‚úÖ TensorFlow disponible\n",
      "‚úÖ SHAP disponible\n",
      "‚úÖ OpenCV disponible\n",
      "‚úÖ Scikit-learn disponible\n",
      "‚úÖ LIME disponible\n",
      "\n",
      "üéâ Toutes les d√©pendances sont disponibles !\n",
      "\n",
      "üìä Statut des modules:\n",
      "‚Ä¢ RAF Interpretability: ‚úÖ\n",
      "‚Ä¢ DataLoader RAF: ‚úÖ\n",
      "üéâ Framework d'interpr√©tabilit√© pr√™t avec SHAP, GradCAM et LIME !\n"
     ]
    }
   ],
   "source": [
    "# Imports du framework RAF\n",
    "# Configuration du chemin d'import\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# D√©tection automatique du r√©pertoire racine\n",
    "current_dir = Path.cwd()\n",
    "if 'notebooks' in str(current_dir):\n",
    "    project_root = current_dir.parent\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "# Ajout du r√©pertoire racine au PYTHONPATH\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"üìÅ R√©pertoire projet: {project_root}\")\n",
    "print(f\"üêç PYTHONPATH ajust√©\")\n",
    "\n",
    "# Import direct depuis src/\n",
    "try:\n",
    "    from src.features.raf.interpretability import (\n",
    "        SHAPExplainer,\n",
    "        GradCAMExplainer,\n",
    "        LIMEExplainer,\n",
    "        InterpretabilityAnalyzer,\n",
    "        create_interpretability_dashboard,\n",
    "        generate_interpretability_report,\n",
    "        visualize_lime_comparison\n",
    "    )\n",
    "    print(\"‚úÖ Modules RAF d'interpr√©tabilit√© charg√©s (SHAP, GradCAM, LIME)\")\n",
    "    RAF_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erreur import RAF: {e}\")\n",
    "    print(\"üí° V√©rifiez l'installation du framework RAF\")\n",
    "    RAF_AVAILABLE = False\n",
    "\n",
    "# Import du DataLoader RAF pour les vraies donn√©es\n",
    "try:\n",
    "    from src.features.raf.data import DataLoader\n",
    "    print(\"‚úÖ DataLoader RAF charg√©\")\n",
    "    DATALOADER_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erreur DataLoader: {e}\")\n",
    "    DATALOADER_AVAILABLE = False\n",
    "\n",
    "# V√©rification des d√©pendances\n",
    "dependencies = {\n",
    "    'tensorflow': 'TensorFlow',\n",
    "    'shap': 'SHAP',\n",
    "    'cv2': 'OpenCV',\n",
    "    'sklearn': 'Scikit-learn',\n",
    "    'lime': 'LIME'\n",
    "}\n",
    "\n",
    "missing_deps = []\n",
    "for module, name in dependencies.items():\n",
    "    try:\n",
    "        __import__(module)\n",
    "        print(f\"‚úÖ {name} disponible\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {name} manquant\")\n",
    "        missing_deps.append(name)\n",
    "\n",
    "if missing_deps:\n",
    "    print(f\"\\nüì¶ Installation n√©cessaire:\")\n",
    "    for dep in missing_deps:\n",
    "        if dep == 'SHAP':\n",
    "            print(\"!pip install shap\")\n",
    "        elif dep == 'TensorFlow':\n",
    "            print(\"!pip install tensorflow\")\n",
    "        elif dep == 'OpenCV':\n",
    "            print(\"!pip install opencv-python\")\n",
    "        elif dep == 'LIME':\n",
    "            print(\"!pip install lime\")\n",
    "else:\n",
    "    print(\"\\nüéâ Toutes les d√©pendances sont disponibles !\")\n",
    "\n",
    "print(f\"\\nüìä Statut des modules:\")\n",
    "print(f\"‚Ä¢ RAF Interpretability: {'‚úÖ' if RAF_AVAILABLE else '‚ùå'}\")\n",
    "print(f\"‚Ä¢ DataLoader RAF: {'‚úÖ' if DATALOADER_AVAILABLE else '‚ùå'}\")\n",
    "\n",
    "if RAF_AVAILABLE:\n",
    "    print(\"üéâ Framework d'interpr√©tabilit√© pr√™t avec SHAP, GradCAM et LIME !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c80faf",
   "metadata": {},
   "source": [
    "## üìä Chargement des Donn√©es et Mod√®les\n",
    "\n",
    "Nous allons utiliser des donn√©es simul√©es pour la d√©monstration. En pratique, vous remplacerez ceci par vos vrais mod√®les et donn√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc5ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des vraies donn√©es COVID-19 avec DataLoader RAF\n",
    "print(\"üîÑ Chargement des donn√©es r√©elles COVID-19...\")\n",
    "\n",
    "# Import de tqdm pour les barres de progression\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "if DATALOADER_AVAILABLE:\n",
    "    # üéØ Configuration depuis .env avec CHEMINS ABSOLUS (Plus de probl√®mes !)\n",
    "    print(\"‚öôÔ∏è Chargement de la configuration depuis .env...\")\n",
    "    \n",
    "    # Chemins absolus depuis .env\n",
    "    DATA_DIR = os.getenv('DATA_DIR', '/home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset')\n",
    "    MODELS_DIR = os.getenv('MODELS_DIR', '/home/cepa/DST/projet_DS/DS_COVID/models')\n",
    "    RESULTS_DIR = os.getenv('RESULTS_DIR', '/home/cepa/DST/projet_DS/DS_COVID/reports')\n",
    "    PROJECT_ROOT = os.getenv('PROJECT_ROOT', '/home/cepa/DST/projet_DS/DS_COVID')\n",
    "    \n",
    "    # Param√®tres d'images\n",
    "    IMG_WIDTH = int(os.getenv('IMG_WIDTH', 224))\n",
    "    IMG_HEIGHT = int(os.getenv('IMG_HEIGHT', 224))\n",
    "    IMG_SIZE = (IMG_WIDTH, IMG_HEIGHT)\n",
    "    \n",
    "    # Param√®tres de classes\n",
    "    NUM_CLASSES = int(os.getenv('NUM_CLASSES', 4))\n",
    "    CLASS_NAMES = os.getenv('CLASS_NAMES', 'COVID,Lung_Opacity,Normal,Viral Pneumonia').split(',')\n",
    "    RANDOM_SEED = int(os.getenv('RANDOM_SEED', 42))\n",
    "    \n",
    "    # Configuration d'interpr√©tabilit√© depuis .env\n",
    "    GRADCAM_ALPHA = float(os.getenv('GRADCAM_ALPHA', 0.4))\n",
    "    GRADCAM_COLORMAP = os.getenv('GRADCAM_COLORMAP', 'jet')\n",
    "    SHAP_MAX_EVALS = int(os.getenv('SHAP_MAX_EVALS', 100))\n",
    "    SHAP_BACKGROUND_SIZE = int(os.getenv('SHAP_BACKGROUND_SIZE', 50))\n",
    "    LIME_NUM_SAMPLES = int(os.getenv('LIME_NUM_SAMPLES', 1000))\n",
    "    \n",
    "    print(f\"\\nüìã Configuration charg√©e (CHEMINS ABSOLUS):\")\n",
    "    print(f\"üè† Racine du projet: {PROJECT_ROOT}\")\n",
    "    print(f\"üìÅ R√©pertoire de donn√©es: {DATA_DIR}\")\n",
    "    print(f\"ü§ñ R√©pertoire mod√®les: {MODELS_DIR}\")\n",
    "    print(f\"\udcca R√©pertoire r√©sultats: {RESULTS_DIR}\")\n",
    "    print(f\"\ud83düñºÔ∏è Taille d'image: {IMG_SIZE}\")\n",
    "    print(f\"üè∑Ô∏è Nombre de classes: {NUM_CLASSES}\")\n",
    "    print(f\"üìã Classes: {CLASS_NAMES}\")\n",
    "    print(f\"üéØ Config interpr√©tabilit√©:\")\n",
    "    print(f\"  ‚Ä¢ GradCAM Alpha: {GRADCAM_ALPHA}, Colormap: {GRADCAM_COLORMAP}\")\n",
    "    print(f\"  ‚Ä¢ SHAP Max Evals: {SHAP_MAX_EVALS}, Background Size: {SHAP_BACKGROUND_SIZE}\")\n",
    "    print(f\"  ‚Ä¢ LIME Samples: {LIME_NUM_SAMPLES}\")\n",
    "    \n",
    "    # V√©rification simple de la structure avec chemins absolus\n",
    "    from pathlib import Path\n",
    "    data_path = Path(DATA_DIR)\n",
    "    \n",
    "    print(f\"\\nüîç V√©rification de la structure des donn√©es...\")\n",
    "    with tqdm(total=len(CLASS_NAMES) + 2, desc=\"V√©rification structure\", colour='blue') as pbar:\n",
    "        print(f\"üìÇ Chemin absolu: {data_path}\")\n",
    "        print(f\"üìÇ Existe: {data_path.exists()}\")\n",
    "        pbar.update(1)\n",
    "        \n",
    "        if data_path.exists():\n",
    "            # V√©rifier chaque classe\n",
    "            found_classes = []\n",
    "            class_counts_manual = {}\n",
    "            \n",
    "            for class_name in CLASS_NAMES:\n",
    "                class_path = data_path / class_name\n",
    "                exists = class_path.exists()\n",
    "                \n",
    "                if exists:\n",
    "                    # Compter les images\n",
    "                    images = list(class_path.glob('**/*.png')) + list(class_path.glob('**/*.jpg')) + list(class_path.glob('**/*.jpeg'))\n",
    "                    image_count = len(images)\n",
    "                    class_counts_manual[class_name] = image_count\n",
    "                    \n",
    "                    print(f\"üìÅ {class_name}: ‚úÖ {image_count} images\")\n",
    "                    if image_count > 0:\n",
    "                        found_classes.append(class_name)\n",
    "                else:\n",
    "                    print(f\"üìÅ {class_name}: ‚ùå (dossier introuvable)\")\n",
    "                    class_counts_manual[class_name] = 0\n",
    "                \n",
    "                pbar.update(1)\n",
    "            \n",
    "            total_images_manual = sum(class_counts_manual.values())\n",
    "            print(f\"\\n‚úÖ R√©sum√©:\")\n",
    "            print(f\"üìä Classes trouv√©es: {len(found_classes)}/{len(CLASS_NAMES)}\")\n",
    "            print(f\"üñºÔ∏è Total images: {total_images_manual}\")\n",
    "            pbar.update(1)\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå Le r√©pertoire de donn√©es n'existe pas !\")\n",
    "            pbar.update(len(CLASS_NAMES) + 1)\n",
    "    \n",
    "    # Initialisation du DataLoader\n",
    "    try:\n",
    "        print(\"\\nüîß Configuration du DataLoader...\")\n",
    "        with tqdm(total=4, desc=\"Configuration\", colour='green') as pbar:\n",
    "            from src.features.raf.utils import get_config, Config\n",
    "            config = get_config()\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Configuration avec chemins absolus\n",
    "            config.data_dir = data_path\n",
    "            config.img_size = IMG_SIZE\n",
    "            config.classes = CLASS_NAMES\n",
    "            config.random_seed = RANDOM_SEED\n",
    "            config.max_images_per_class = int(os.getenv('MAX_IMAGES_PER_CLASS', 100))\n",
    "            pbar.update(1)\n",
    "            \n",
    "            print(f\"üîß Configuration DataLoader:\")\n",
    "            print(f\"  ‚Ä¢ Data dir (absolu): {config.data_dir}\")\n",
    "            print(f\"  ‚Ä¢ Classes: {config.classes}\")\n",
    "            print(f\"  ‚Ä¢ Max images/classe: {config.max_images_per_class}\")\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Cr√©er le DataLoader avec chemin absolu\n",
    "            loader = DataLoader(data_dir=data_path, config=config)\n",
    "            pbar.update(1)\n",
    "        \n",
    "        print(f\"‚úÖ DataLoader configur√© avec succ√®s\")\n",
    "        \n",
    "        print(f\"\\nüìä Chargement du dataset...\")\n",
    "        \n",
    "        # Charger les chemins et labels avec progression\n",
    "        with tqdm(total=1, desc=\"Scan des fichiers\", colour='orange') as pbar:\n",
    "            try:\n",
    "                print(\"üîç Lancement du scan...\")\n",
    "                image_paths, labels, class_counts = loader.load_image_paths_and_labels()\n",
    "                pbar.update(1)\n",
    "                print(f\"‚úÖ Scan termin√©: {len(image_paths)} images trouv√©es\")\n",
    "                \n",
    "                if class_counts:\n",
    "                    print(f\"üìä R√©partition d√©taill√©e par classe:\")\n",
    "                    for class_name, count in class_counts.items():\n",
    "                        print(f\"  ‚Ä¢ {class_name}: {count} images\")\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è Aucun comptage de classes disponible\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erreur lors du scan: {e}\")\n",
    "                print(f\"üîç D√©tails de l'erreur:\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                pbar.update(1)\n",
    "                image_paths, labels, class_counts = [], [], {}\n",
    "        \n",
    "        if len(image_paths) > 0:\n",
    "            # Cr√©er un sous-ensemble √©quilibr√© pour la d√©mo\n",
    "            max_per_class = min(20, max(class_counts.values()) if class_counts.values() else 10)\n",
    "            \n",
    "            with tqdm(total=1, desc=\"Cr√©ation sous-ensemble\", colour='purple') as pbar:\n",
    "                subset_paths, subset_labels = loader.create_balanced_subset(\n",
    "                    image_paths, labels, max_per_class=max_per_class\n",
    "                )\n",
    "                pbar.update(1)\n",
    "            \n",
    "            print(f\"üì¶ Sous-ensemble cr√©√©: {len(subset_paths)} images ({max_per_class} par classe)\")\n",
    "            \n",
    "            # Charger un √©chantillon d'images pour visualisation\n",
    "            n_samples = min(10, len(subset_paths))\n",
    "            \n",
    "            print(f\"\\nüñºÔ∏è Chargement de {n_samples} images √©chantillons...\")\n",
    "            with tqdm(total=1, desc=\"Chargement images\", colour='cyan') as pbar:\n",
    "                try:\n",
    "                    sample_images, sample_labels_final = loader.load_sample_images(\n",
    "                        subset_paths, subset_labels, n_samples=n_samples\n",
    "                    )\n",
    "                    pbar.update(1)\n",
    "                    print(f\"‚úÖ {len(sample_images)} images charg√©es avec succ√®s\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Erreur chargement images: {e}\")\n",
    "                    sample_images, sample_labels_final = [], []\n",
    "                    pbar.update(1)\n",
    "            \n",
    "            if len(sample_images) > 0:\n",
    "                # Convertir en format numpy pour les mod√®les\n",
    "                print(\"\\n‚öôÔ∏è Conversion des donn√©es...\")\n",
    "                with tqdm(total=3, desc=\"Conversion numpy\", colour='yellow') as pbar:\n",
    "                    X_images = np.array(sample_images)\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                    if len(X_images.shape) == 3:\n",
    "                        X_images = np.expand_dims(X_images, axis=-1)\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                    # Convertir les labels en indices\n",
    "                    label_to_idx = {label: idx for idx, label in enumerate(CLASS_NAMES)}\n",
    "                    y_true = np.array([label_to_idx.get(label, 0) for label in sample_labels_final])\n",
    "                    pbar.update(1)\n",
    "                \n",
    "                # Version aplatie pour les mod√®les ML classiques\n",
    "                with tqdm(total=1, desc=\"Aplatissement ML\", colour='magenta') as pbar:\n",
    "                    X_flat = X_images.reshape(len(X_images), -1)\n",
    "                    pbar.update(1)\n",
    "                \n",
    "                print(f\"\\nüìä Donn√©es charg√©es pour la d√©mo:\")\n",
    "                print(f\"‚Ä¢ Images CNN: {X_images.shape}\")\n",
    "                print(f\"‚Ä¢ Images ML: {X_flat.shape}\")\n",
    "                print(f\"‚Ä¢ Labels: {y_true.shape}\")\n",
    "                print(f\"‚Ä¢ Classes uniques: {np.unique(y_true)}\")\n",
    "                print(f\"‚Ä¢ Labels √©chantillons: {sample_labels_final}\")\n",
    "                \n",
    "                # Affichage de quelques √©chantillons\n",
    "                print(\"\\nüé® Affichage des √©chantillons...\")\n",
    "                fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "                \n",
    "                with tqdm(total=min(10, len(X_images)), desc=\"Affichage\", colour='red') as pbar:\n",
    "                    for i in range(min(10, len(X_images))):\n",
    "                        row, col = i // 5, i % 5\n",
    "                        axes[row, col].imshow(X_images[i].squeeze(), cmap='gray')\n",
    "                        axes[row, col].set_title(f'{sample_labels_final[i] if i < len(sample_labels_final) else \"N/A\"}')\n",
    "                        axes[row, col].axis('off')\n",
    "                        pbar.update(1)\n",
    "                \n",
    "                plt.suptitle('√âchantillons de Donn√©es R√©elles COVID-19', fontsize=14)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                REAL_DATA_LOADED = True\n",
    "                \n",
    "                print(f\"\\nüéâ SUCC√àS AVEC CHEMINS ABSOLUS !\")\n",
    "                print(f\"üìä {len(image_paths)} images totales trouv√©es\")\n",
    "                print(f\"üéØ {len(sample_images)} images √©chantillons pr√™tes pour l'interpr√©tabilit√©\")\n",
    "                print(f\"‚ú® Pr√™t pour SHAP, GradCAM et LIME !\")\n",
    "                \n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Aucune image n'a pu √™tre charg√©e\")\n",
    "                REAL_DATA_LOADED = False\n",
    "                \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Aucune image trouv√©e dans le dataset\")\n",
    "            REAL_DATA_LOADED = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur chargement dataset: {e}\")\n",
    "        print(f\"üí° V√©rifiez que le dossier {DATA_DIR} existe et contient les donn√©es\")\n",
    "        print(f\"üîç D√©tails de l'erreur:\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        REAL_DATA_LOADED = False\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå DataLoader RAF non disponible\")\n",
    "    print(\"üí° V√©rifiez l'installation des d√©pendances RAF\")\n",
    "    REAL_DATA_LOADED = False\n",
    "\n",
    "print(f\"\\nüìã STATUT FINAL:\")\n",
    "print(f\"üîß DataLoader disponible: {'‚úÖ' if DATALOADER_AVAILABLE else '‚ùå'}\")\n",
    "print(f\"üìä Donn√©es r√©elles charg√©es: {'‚úÖ' if REAL_DATA_LOADED else '‚ùå'}\")\n",
    "print(f\"üéØ Configuration: CHEMINS ABSOLUS (Fini les gal√®res !)\")\n",
    "if REAL_DATA_LOADED:\n",
    "    print(f\"üöÄ Pr√™t pour la suite : Mod√®les et Interpr√©tabilit√© ! üéâ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11836f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TEST IND√âPENDANT DU DATALOADER RAF\n",
      "==================================================\n",
      "üìÇ R√©pertoire de test: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "üè∑Ô∏è Classes √† tester: ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
      "\n",
      "üîç TEST 1: V√©rification directe des dossiers\n",
      "----------------------------------------\n",
      "üìç Chemin absolu: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "üìÇ Existe: True\n",
      "üìÅ Tous les √©l√©ments (9): ['README.md.txt', 'Viral Pneumonia', 'Viral Pneumonia.metadata.xlsx', 'Normal.metadata.xlsx', 'Lung_Opacity.metadata.xlsx', 'Normal', 'COVID.metadata.xlsx', 'Lung_Opacity', 'COVID']\n",
      "üìÅ Dossiers seulement (4): ['Viral Pneumonia', 'Normal', 'Lung_Opacity', 'COVID']\n",
      "\n",
      "üß™ Test de chaque classe:\n",
      "  ‚úÖ COVID: 7232 images, 2 sous-dossiers\n",
      "     üìÅ Sous-dossiers: ['images', 'masks']\n",
      "  ‚úÖ Lung_Opacity: 12024 images, 2 sous-dossiers\n",
      "     üìÅ Sous-dossiers: ['images', 'masks']\n",
      "  ‚úÖ Normal: 20384 images, 2 sous-dossiers\n",
      "     üìÅ Sous-dossiers: ['images', 'masks']\n",
      "  ‚úÖ Viral Pneumonia: 2690 images, 2 sous-dossiers\n",
      "     üìÅ Sous-dossiers: ['images', 'masks']\n",
      "\n",
      "üîç TEST 2: Test du DataLoader RAF\n",
      "----------------------------------------\n",
      "‚úÖ Imports DataLoader r√©ussis\n",
      "üîß === CONFIGURATION UNIVERSELLE RAF ===\n",
      "üìç Environnement: üíª WSL/Linux Local\n",
      "‚úÖ Environnement virtuel .venv d√©tect√©\n",
      "‚úÖ Configuration charg√©e: /home/cepa/DST/projet_DS/DS_COVID/.env\n",
      "üîß Configuration cr√©√©e:\n",
      "  ‚Ä¢ Data dir: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "  ‚Ä¢ Classes: ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
      "\n",
      "üèóÔ∏è Cr√©ation du DataLoader...\n",
      "üìÇ DataLoader initialis√©: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "‚úÖ DataLoader cr√©√© avec succ√®s\n",
      "\n",
      "üìä Test de load_image_paths_and_labels()...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0a1b1883ac46ce8f7f4373eb630e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test chargement:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Chargement des chemins d'images...\n",
      "  COVID: 3616 images\n",
      "  Lung_Opacity: 6012 images\n",
      "  COVID: 3616 images\n",
      "  Lung_Opacity: 6012 images\n",
      "  Normal: 10192 images\n",
      "  Viral Pneumonia: 1345 images\n",
      "üìä Total: 21165 images\n",
      "‚úÖ M√©thode ex√©cut√©e avec succ√®s\n",
      "üìä R√©sultats:\n",
      "  ‚Ä¢ Images trouv√©es: 21165\n",
      "  ‚Ä¢ Labels: 21165\n",
      "  ‚Ä¢ Comptage par classe: {'COVID': 3616, 'Lung_Opacity': 6012, 'Normal': 10192, 'Viral Pneumonia': 1345}\n",
      "  ‚Ä¢ Premier chemin: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset/COVID/images/COVID-3039.png\n",
      "  ‚Ä¢ Premier label: COVID\n",
      "\n",
      "üñºÔ∏è Test de chargement d'images...\n",
      "üñºÔ∏è Chargement de 3 images d'exemple...\n",
      "‚úÖ 3 images charg√©es avec succ√®s\n",
      "‚úÖ √âchantillons charg√©s: 3 images\n",
      "  ‚Ä¢ Shape premi√®re image: (256, 256, 3)\n",
      "\n",
      "üîç TEST 3: Recherche manuelle d'images\n",
      "----------------------------------------\n",
      "üìÅ COVID: 7232 images (PNG: 7232, JPG: 0, JPEG: 0)\n",
      "   üìÑ Premier fichier: COVID-3039.png\n",
      "üìÅ Lung_Opacity: 12024 images (PNG: 12024, JPG: 0, JPEG: 0)\n",
      "   üìÑ Premier fichier: Lung_Opacity-4819.png\n",
      "  Normal: 10192 images\n",
      "  Viral Pneumonia: 1345 images\n",
      "üìä Total: 21165 images\n",
      "‚úÖ M√©thode ex√©cut√©e avec succ√®s\n",
      "üìä R√©sultats:\n",
      "  ‚Ä¢ Images trouv√©es: 21165\n",
      "  ‚Ä¢ Labels: 21165\n",
      "  ‚Ä¢ Comptage par classe: {'COVID': 3616, 'Lung_Opacity': 6012, 'Normal': 10192, 'Viral Pneumonia': 1345}\n",
      "  ‚Ä¢ Premier chemin: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset/COVID/images/COVID-3039.png\n",
      "  ‚Ä¢ Premier label: COVID\n",
      "\n",
      "üñºÔ∏è Test de chargement d'images...\n",
      "üñºÔ∏è Chargement de 3 images d'exemple...\n",
      "‚úÖ 3 images charg√©es avec succ√®s\n",
      "‚úÖ √âchantillons charg√©s: 3 images\n",
      "  ‚Ä¢ Shape premi√®re image: (256, 256, 3)\n",
      "\n",
      "üîç TEST 3: Recherche manuelle d'images\n",
      "----------------------------------------\n",
      "üìÅ COVID: 7232 images (PNG: 7232, JPG: 0, JPEG: 0)\n",
      "   üìÑ Premier fichier: COVID-3039.png\n",
      "üìÅ Lung_Opacity: 12024 images (PNG: 12024, JPG: 0, JPEG: 0)\n",
      "   üìÑ Premier fichier: Lung_Opacity-4819.png\n",
      "üìÅ Normal: 20384 images (PNG: 20384, JPG: 0, JPEG: 0)\n",
      "   üìÑ Premier fichier: Normal-6868.png\n",
      "üìÅ Viral Pneumonia: 2690 images (PNG: 2690, JPG: 0, JPEG: 0)\n",
      "   üìÑ Premier fichier: Viral Pneumonia-657.png\n",
      "\n",
      "üìä R√âSUM√â DU TEST MANUEL:\n",
      "‚Ä¢ Total images trouv√©es: 42330\n",
      "‚Ä¢ R√©partition: {'COVID': 7232, 'Lung_Opacity': 12024, 'Normal': 20384, 'Viral Pneumonia': 2690}\n",
      "\n",
      "üéØ CONCLUSION DU TEST\n",
      "==============================\n",
      "‚úÖ Les images existent dans la structure de dossiers\n",
      "üîß Le probl√®me semble venir du DataLoader RAF\n",
      "üí° Suggestions:\n",
      "  1. V√©rifier la m√©thode load_image_paths_and_labels() du DataLoader\n",
      "  2. V√©rifier les patterns de recherche d'images\n",
      "  3. V√©rifier les chemins relatifs vs absolus\n",
      "\n",
      "üèÅ Test termin√© - Vous pouvez maintenant identifier le probl√®me !\n",
      "üìÅ Normal: 20384 images (PNG: 20384, JPG: 0, JPEG: 0)\n",
      "   üìÑ Premier fichier: Normal-6868.png\n",
      "üìÅ Viral Pneumonia: 2690 images (PNG: 2690, JPG: 0, JPEG: 0)\n",
      "   üìÑ Premier fichier: Viral Pneumonia-657.png\n",
      "\n",
      "üìä R√âSUM√â DU TEST MANUEL:\n",
      "‚Ä¢ Total images trouv√©es: 42330\n",
      "‚Ä¢ R√©partition: {'COVID': 7232, 'Lung_Opacity': 12024, 'Normal': 20384, 'Viral Pneumonia': 2690}\n",
      "\n",
      "üéØ CONCLUSION DU TEST\n",
      "==============================\n",
      "‚úÖ Les images existent dans la structure de dossiers\n",
      "üîß Le probl√®me semble venir du DataLoader RAF\n",
      "üí° Suggestions:\n",
      "  1. V√©rifier la m√©thode load_image_paths_and_labels() du DataLoader\n",
      "  2. V√©rifier les patterns de recherche d'images\n",
      "  3. V√©rifier les chemins relatifs vs absolus\n",
      "\n",
      "üèÅ Test termin√© - Vous pouvez maintenant identifier le probl√®me !\n"
     ]
    }
   ],
   "source": [
    "# üß™ Test ind√©pendant du DataLoader RAF\n",
    "print(\"üß™ TEST IND√âPENDANT DU DATALOADER RAF\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Configuration du test\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Configuration de base\n",
    "DATA_DIR = os.getenv('DATA_DIR', './data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset')\n",
    "CLASS_NAMES = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
    "\n",
    "print(f\"üìÇ R√©pertoire de test: {DATA_DIR}\")\n",
    "print(f\"üè∑Ô∏è Classes √† tester: {CLASS_NAMES}\")\n",
    "\n",
    "# Test 1: V√©rification directe des dossiers\n",
    "print(f\"\\nüîç TEST 1: V√©rification directe des dossiers\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "data_path = Path(DATA_DIR)\n",
    "print(f\"üìç Chemin absolu: {data_path.resolve()}\")\n",
    "print(f\"üìÇ Existe: {data_path.exists()}\")\n",
    "\n",
    "if data_path.exists():\n",
    "    all_items = list(data_path.iterdir())\n",
    "    dirs_only = [p for p in all_items if p.is_dir()]\n",
    "    \n",
    "    print(f\"üìÅ Tous les √©l√©ments ({len(all_items)}): {[p.name for p in all_items]}\")\n",
    "    print(f\"üìÅ Dossiers seulement ({len(dirs_only)}): {[p.name for p in dirs_only]}\")\n",
    "    \n",
    "    # Test de chaque classe\n",
    "    print(f\"\\nüß™ Test de chaque classe:\")\n",
    "    for class_name in CLASS_NAMES:\n",
    "        class_path = data_path / class_name\n",
    "        exists = class_path.exists()\n",
    "        is_dir = class_path.is_dir() if exists else False\n",
    "        \n",
    "        if exists and is_dir:\n",
    "            # Compter les images\n",
    "            images = list(class_path.glob('**/*.png')) + list(class_path.glob('**/*.jpg'))\n",
    "            subfolders = [p for p in class_path.iterdir() if p.is_dir()]\n",
    "            \n",
    "            print(f\"  ‚úÖ {class_name}: {len(images)} images, {len(subfolders)} sous-dossiers\")\n",
    "            if subfolders:\n",
    "                print(f\"     üìÅ Sous-dossiers: {[p.name for p in subfolders]}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå {class_name}: {'fichier' if exists else 'inexistant'}\")\n",
    "\n",
    "# Test 2: Test du DataLoader si disponible\n",
    "print(f\"\\nüîç TEST 2: Test du DataLoader RAF\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if DATALOADER_AVAILABLE:\n",
    "    try:\n",
    "        # Import et configuration\n",
    "        from src.features.raf.data import DataLoader\n",
    "        from src.features.raf.utils import get_config\n",
    "        \n",
    "        print(\"‚úÖ Imports DataLoader r√©ussis\")\n",
    "        \n",
    "        # Configuration minimale\n",
    "        config = get_config()\n",
    "        config.data_dir = data_path\n",
    "        config.classes = CLASS_NAMES\n",
    "        config.max_images_per_class = 10  # Limit√© pour le test\n",
    "        \n",
    "        print(f\"üîß Configuration cr√©√©e:\")\n",
    "        print(f\"  ‚Ä¢ Data dir: {config.data_dir}\")\n",
    "        print(f\"  ‚Ä¢ Classes: {config.classes}\")\n",
    "        \n",
    "        # Initialisation du DataLoader\n",
    "        print(f\"\\nüèóÔ∏è Cr√©ation du DataLoader...\")\n",
    "        loader = DataLoader(data_dir=data_path, config=config)\n",
    "        print(\"‚úÖ DataLoader cr√©√© avec succ√®s\")\n",
    "        \n",
    "        # Test de la m√©thode load_image_paths_and_labels\n",
    "        print(f\"\\nüìä Test de load_image_paths_and_labels()...\")\n",
    "        with tqdm(total=1, desc=\"Test chargement\", colour='green') as pbar:\n",
    "            try:\n",
    "                image_paths, labels, class_counts = loader.load_image_paths_and_labels()\n",
    "                pbar.update(1)\n",
    "                \n",
    "                print(f\"‚úÖ M√©thode ex√©cut√©e avec succ√®s\")\n",
    "                print(f\"üìä R√©sultats:\")\n",
    "                print(f\"  ‚Ä¢ Images trouv√©es: {len(image_paths)}\")\n",
    "                print(f\"  ‚Ä¢ Labels: {len(labels)}\")\n",
    "                print(f\"  ‚Ä¢ Comptage par classe: {dict(class_counts) if class_counts else 'Vide'}\")\n",
    "                \n",
    "                if len(image_paths) > 0:\n",
    "                    print(f\"  ‚Ä¢ Premier chemin: {image_paths[0]}\")\n",
    "                    print(f\"  ‚Ä¢ Premier label: {labels[0]}\")\n",
    "                    \n",
    "                    # Test de quelques √©chantillons\n",
    "                    print(f\"\\nüñºÔ∏è Test de chargement d'images...\")\n",
    "                    try:\n",
    "                        sample_images, sample_labels = loader.load_sample_images(\n",
    "                            image_paths[:3], labels[:3], n_samples=3\n",
    "                        )\n",
    "                        print(f\"‚úÖ √âchantillons charg√©s: {len(sample_images)} images\")\n",
    "                        if len(sample_images) > 0:\n",
    "                            print(f\"  ‚Ä¢ Shape premi√®re image: {sample_images[0].shape}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ùå Erreur chargement √©chantillons: {e}\")\n",
    "                        \n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è Aucune image trouv√©e par le DataLoader\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erreur dans load_image_paths_and_labels: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                pbar.update(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors du test DataLoader: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"‚ùå DataLoader non disponible pour le test\")\n",
    "\n",
    "# Test 3: Test manuel de recherche d'images\n",
    "print(f\"\\nüîç TEST 3: Recherche manuelle d'images\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "manual_count = {}\n",
    "total_manual = 0\n",
    "\n",
    "for class_name in CLASS_NAMES:\n",
    "    class_path = data_path / class_name\n",
    "    if class_path.exists():\n",
    "        # Recherche r√©cursive d'images\n",
    "        png_files = list(class_path.glob('**/*.png'))\n",
    "        jpg_files = list(class_path.glob('**/*.jpg'))\n",
    "        jpeg_files = list(class_path.glob('**/*.jpeg'))\n",
    "        \n",
    "        total_files = len(png_files) + len(jpg_files) + len(jpeg_files)\n",
    "        manual_count[class_name] = total_files\n",
    "        total_manual += total_files\n",
    "        \n",
    "        print(f\"üìÅ {class_name}: {total_files} images (PNG: {len(png_files)}, JPG: {len(jpg_files)}, JPEG: {len(jpeg_files)})\")\n",
    "        \n",
    "        if total_files > 0:\n",
    "            first_file = (png_files + jpg_files + jpeg_files)[0]\n",
    "            print(f\"   üìÑ Premier fichier: {first_file.name}\")\n",
    "    else:\n",
    "        manual_count[class_name] = 0\n",
    "        print(f\"üìÅ {class_name}: dossier inexistant\")\n",
    "\n",
    "print(f\"\\nüìä R√âSUM√â DU TEST MANUEL:\")\n",
    "print(f\"‚Ä¢ Total images trouv√©es: {total_manual}\")\n",
    "print(f\"‚Ä¢ R√©partition: {manual_count}\")\n",
    "\n",
    "# Conclusion du test\n",
    "print(f\"\\nüéØ CONCLUSION DU TEST\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if total_manual > 0:\n",
    "    print(\"‚úÖ Les images existent dans la structure de dossiers\")\n",
    "    if DATALOADER_AVAILABLE:\n",
    "        print(\"üîß Le probl√®me semble venir du DataLoader RAF\")\n",
    "        print(\"üí° Suggestions:\")\n",
    "        print(\"  1. V√©rifier la m√©thode load_image_paths_and_labels() du DataLoader\")\n",
    "        print(\"  2. V√©rifier les patterns de recherche d'images\")\n",
    "        print(\"  3. V√©rifier les chemins relatifs vs absolus\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è DataLoader RAF non disponible\")\n",
    "else:\n",
    "    print(\"‚ùå Aucune image trouv√©e manuellement\")\n",
    "    print(\"üí° V√©rifiez la structure des dossiers et les chemins\")\n",
    "\n",
    "print(f\"\\nüèÅ Test termin√© - Vous pouvez maintenant identifier le probl√®me !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8430da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß CORRECTION AUTOMATIQUE DES CHEMINS\n",
      "==================================================\n",
      "üìç R√©pertoire de travail actuel: /home/cepa/DST/projet_DS/DS_COVID/notebooks\n",
      "\n",
      "üîç Test des chemins possibles...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0eb43c772e1479ba80c002b96a1e679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test chemins:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Test 1: ../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "   üìç Absolu: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "   üìÇ Existe: True\n",
      "   ‚úÖ COVID: True\n",
      "   ‚úÖ Lung_Opacity: True\n",
      "   ‚úÖ Normal: True\n",
      "   ‚úÖ Viral Pneumonia: True\n",
      "   üéØ CHEMIN CORRECT TROUV√â !\n",
      "\n",
      "‚úÖ CHEMIN CORRIG√â TROUV√â !\n",
      "üìÇ Chemin correct: ../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "üìç Chemin absolu: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "\n",
      "üîÑ Mise √† jour de la configuration...\n",
      "\n",
      "üß™ TEST AVEC LE CHEMIN CORRIG√â\n",
      "----------------------------------------\n",
      "üìÅ COVID: 7232 images\n",
      "üìÅ Lung_Opacity: 12024 images\n",
      "üìÅ Normal: 20384 images\n",
      "üìÅ Viral Pneumonia: 2690 images\n",
      "\n",
      "üìä R√âSUM√â AVEC CHEMIN CORRIG√â:\n",
      "‚Ä¢ Total images: 42330\n",
      "‚Ä¢ R√©partition: {'COVID': 7232, 'Lung_Opacity': 12024, 'Normal': 20384, 'Viral Pneumonia': 2690}\n",
      "\n",
      "üéâ PROBL√àME R√âSOLU !\n",
      "üí° Le probl√®me √©tait un chemin relatif incorrect\n",
      "üîß Solution: Utiliser le chemin '../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset'\n",
      "üìù Variable DATA_DIR_CORRECTED cr√©√©e: ../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "\n",
      "üß™ TEST RAPIDE DU DATALOADER CORRIG√â\n",
      "----------------------------------------\n",
      "üìÇ DataLoader initialis√©: ../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "üìÅ COVID: 7232 images\n",
      "üìÅ Lung_Opacity: 12024 images\n",
      "üìÅ Normal: 20384 images\n",
      "üìÅ Viral Pneumonia: 2690 images\n",
      "\n",
      "üìä R√âSUM√â AVEC CHEMIN CORRIG√â:\n",
      "‚Ä¢ Total images: 42330\n",
      "‚Ä¢ R√©partition: {'COVID': 7232, 'Lung_Opacity': 12024, 'Normal': 20384, 'Viral Pneumonia': 2690}\n",
      "\n",
      "üéâ PROBL√àME R√âSOLU !\n",
      "üí° Le probl√®me √©tait un chemin relatif incorrect\n",
      "üîß Solution: Utiliser le chemin '../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset'\n",
      "üìù Variable DATA_DIR_CORRECTED cr√©√©e: ../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "\n",
      "üß™ TEST RAPIDE DU DATALOADER CORRIG√â\n",
      "----------------------------------------\n",
      "üìÇ DataLoader initialis√©: ../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c778c7605ce495eaee4eada071718bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test DataLoader corrig√©:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Chargement des chemins d'images...\n",
      "  COVID: 3616 images\n",
      "  Lung_Opacity: 6012 images\n",
      "  Normal: 10192 images\n",
      "  Viral Pneumonia: 1345 images\n",
      "üìä Total: 21165 images\n",
      "‚úÖ DataLoader avec chemin corrig√©: 21165 images trouv√©es\n",
      "üìä Comptage par classe: {'COVID': 3616, 'Lung_Opacity': 6012, 'Normal': 10192, 'Viral Pneumonia': 1345}\n",
      "üéØ DATALOADER FONCTIONNEL !\n",
      "\n",
      "üèÅ Diagnostic termin√© !\n",
      "  Normal: 10192 images\n",
      "  Viral Pneumonia: 1345 images\n",
      "üìä Total: 21165 images\n",
      "‚úÖ DataLoader avec chemin corrig√©: 21165 images trouv√©es\n",
      "üìä Comptage par classe: {'COVID': 3616, 'Lung_Opacity': 6012, 'Normal': 10192, 'Viral Pneumonia': 1345}\n",
      "üéØ DATALOADER FONCTIONNEL !\n",
      "\n",
      "üèÅ Diagnostic termin√© !\n"
     ]
    }
   ],
   "source": [
    "# üîß CORRECTION AUTOMATIQUE DES CHEMINS\n",
    "print(\"üîß CORRECTION AUTOMATIQUE DES CHEMINS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# D√©tection du probl√®me de chemin\n",
    "current_working_dir = Path.cwd()\n",
    "print(f\"üìç R√©pertoire de travail actuel: {current_working_dir}\")\n",
    "\n",
    "# Configuration des chemins possibles\n",
    "possible_paths = [\n",
    "    # Chemin depuis notebooks/ (actuel)\n",
    "    Path('../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset'),\n",
    "    # Chemin depuis racine du projet\n",
    "    Path('./data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset'),\n",
    "    # Chemin avec un seul niveau\n",
    "    Path('../data/raw/COVID-19_Radiography_Dataset'),\n",
    "    # Chemin absolu bas√© sur project_root\n",
    "    current_working_dir.parent / 'data' / 'raw' / 'COVID-19_Radiography_Dataset' / 'COVID-19_Radiography_Dataset'\n",
    "]\n",
    "\n",
    "CLASS_NAMES = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
    "\n",
    "print(f\"\\nüîç Test des chemins possibles...\")\n",
    "correct_path = None\n",
    "\n",
    "with tqdm(total=len(possible_paths), desc=\"Test chemins\", colour='blue') as pbar:\n",
    "    for i, test_path in enumerate(possible_paths):\n",
    "        print(f\"\\nüìÇ Test {i+1}: {test_path}\")\n",
    "        print(f\"   üìç Absolu: {test_path.resolve()}\")\n",
    "        print(f\"   üìÇ Existe: {test_path.exists()}\")\n",
    "        \n",
    "        if test_path.exists():\n",
    "            # V√©rifier la pr√©sence des dossiers de classes\n",
    "            class_found = 0\n",
    "            for class_name in CLASS_NAMES:\n",
    "                class_path = test_path / class_name\n",
    "                if class_path.exists():\n",
    "                    class_found += 1\n",
    "                    print(f\"   ‚úÖ {class_name}: {class_path.exists()}\")\n",
    "                else:\n",
    "                    print(f\"   ‚ùå {class_name}: {class_path.exists()}\")\n",
    "            \n",
    "            if class_found == len(CLASS_NAMES):\n",
    "                print(f\"   üéØ CHEMIN CORRECT TROUV√â !\")\n",
    "                correct_path = test_path\n",
    "                break\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Seulement {class_found}/{len(CLASS_NAMES)} classes trouv√©es\")\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "# R√©sultat de la correction\n",
    "if correct_path:\n",
    "    print(f\"\\n‚úÖ CHEMIN CORRIG√â TROUV√â !\")\n",
    "    print(f\"üìÇ Chemin correct: {correct_path}\")\n",
    "    print(f\"üìç Chemin absolu: {correct_path.resolve()}\")\n",
    "    \n",
    "    # Mise √† jour des variables d'environnement\n",
    "    corrected_data_dir = str(correct_path)\n",
    "    print(f\"\\nüîÑ Mise √† jour de la configuration...\")\n",
    "    \n",
    "    # Test avec le bon chemin\n",
    "    print(f\"\\nüß™ TEST AVEC LE CHEMIN CORRIG√â\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Compter les images par classe\n",
    "    total_images = 0\n",
    "    class_distribution = {}\n",
    "    \n",
    "    for class_name in CLASS_NAMES:\n",
    "        class_path = correct_path / class_name\n",
    "        if class_path.exists():\n",
    "            images = list(class_path.glob('**/*.png')) + list(class_path.glob('**/*.jpg'))\n",
    "            class_distribution[class_name] = len(images)\n",
    "            total_images += len(images)\n",
    "            print(f\"üìÅ {class_name}: {len(images)} images\")\n",
    "        else:\n",
    "            class_distribution[class_name] = 0\n",
    "            print(f\"üìÅ {class_name}: 0 images (dossier inexistant)\")\n",
    "    \n",
    "    print(f\"\\nüìä R√âSUM√â AVEC CHEMIN CORRIG√â:\")\n",
    "    print(f\"‚Ä¢ Total images: {total_images}\")\n",
    "    print(f\"‚Ä¢ R√©partition: {class_distribution}\")\n",
    "    \n",
    "    if total_images > 0:\n",
    "        print(f\"\\nüéâ PROBL√àME R√âSOLU !\")\n",
    "        print(f\"üí° Le probl√®me √©tait un chemin relatif incorrect\")\n",
    "        print(f\"üîß Solution: Utiliser le chemin '{corrected_data_dir}'\")\n",
    "        \n",
    "        # Mettre √† jour la variable globale pour la suite\n",
    "        DATA_DIR_CORRECTED = corrected_data_dir\n",
    "        print(f\"üìù Variable DATA_DIR_CORRECTED cr√©√©e: {DATA_DIR_CORRECTED}\")\n",
    "        \n",
    "        # Test rapide du DataLoader avec le bon chemin\n",
    "        if DATALOADER_AVAILABLE:\n",
    "            print(f\"\\nüß™ TEST RAPIDE DU DATALOADER CORRIG√â\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            try:\n",
    "                from src.features.raf.data import DataLoader\n",
    "                from src.features.raf.utils import get_config\n",
    "                \n",
    "                # Configuration avec le bon chemin\n",
    "                config = get_config()\n",
    "                config.data_dir = correct_path\n",
    "                config.classes = CLASS_NAMES\n",
    "                config.max_images_per_class = 5  # Test rapide\n",
    "                \n",
    "                loader_corrected = DataLoader(data_dir=correct_path, config=config)\n",
    "                \n",
    "                with tqdm(total=1, desc=\"Test DataLoader corrig√©\", colour='green') as pbar:\n",
    "                    image_paths, labels, class_counts = loader_corrected.load_image_paths_and_labels()\n",
    "                    pbar.update(1)\n",
    "                \n",
    "                print(f\"‚úÖ DataLoader avec chemin corrig√©: {len(image_paths)} images trouv√©es\")\n",
    "                print(f\"üìä Comptage par classe: {dict(class_counts)}\")\n",
    "                \n",
    "                if len(image_paths) > 0:\n",
    "                    print(f\"üéØ DATALOADER FONCTIONNEL !\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è DataLoader toujours ne trouve pas d'images\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erreur test DataLoader corrig√©: {e}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n‚ùå AUCUN CHEMIN CORRECT TROUV√â\")\n",
    "    print(f\"üí° Suggestions:\")\n",
    "    print(f\"  1. V√©rifiez que le dataset COVID-19 est bien t√©l√©charg√©\")\n",
    "    print(f\"  2. V√©rifiez la structure des dossiers:\")\n",
    "    print(f\"     data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset/\")\n",
    "    print(f\"       ‚îú‚îÄ‚îÄ COVID/\")\n",
    "    print(f\"       ‚îú‚îÄ‚îÄ Lung_Opacity/\")\n",
    "    print(f\"       ‚îú‚îÄ‚îÄ Normal/\")\n",
    "    print(f\"       ‚îî‚îÄ‚îÄ Viral Pneumonia/\")\n",
    "    print(f\"  3. Relancez depuis le r√©pertoire racine du projet\")\n",
    "\n",
    "print(f\"\\nüèÅ Diagnostic termin√© !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b1022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation de mod√®les simul√©s pour la d√©monstration\n",
    "# En pratique, vous chargerez vos mod√®les pr√©-entra√Æn√©s\n",
    "\n",
    "print(\"üèóÔ∏è Cr√©ation des mod√®les de d√©monstration...\")\n",
    "\n",
    "# Configuration depuis .env\n",
    "EPOCHS = int(os.getenv('EPOCHS', 2))  # Epochs rapides pour d√©mo\n",
    "BATCH_SIZE = int(os.getenv('BATCH_SIZE', 32))\n",
    "LEARNING_RATE = float(os.getenv('LEARNING_RATE', 0.001))\n",
    "\n",
    "# Configuration Random Forest depuis .env\n",
    "RF_N_ESTIMATORS = int(os.getenv('RF_N_ESTIMATORS', 50))\n",
    "RF_MAX_DEPTH = int(os.getenv('RF_MAX_DEPTH', 10))\n",
    "\n",
    "# Mod√®le CNN simul√© (TensorFlow/Keras)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    \n",
    "    # CNN simple pour d√©monstration\n",
    "    cnn_model = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, 3, activation='relu', input_shape=(*IMG_SIZE, 1)),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    cnn_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Mod√®le CNN cr√©√©\")\n",
    "    print(f\"üìä Architecture: {len(cnn_model.layers)} couches\")\n",
    "    print(f\"üéØ Learning rate: {LEARNING_RATE}\")\n",
    "    \n",
    "    # Entra√Ænement rapide pour avoir des poids\n",
    "    print(f\"üèãÔ∏è Entra√Ænement rapide ({EPOCHS} √©poques)...\")\n",
    "    cnn_model.fit(X_images, y_true, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "    print(\"‚úÖ Mod√®le CNN entra√Æn√©\")\n",
    "    \n",
    "    CNN_AVAILABLE = True\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ùå TensorFlow non disponible - pas de mod√®le CNN\")\n",
    "    cnn_model = None\n",
    "    CNN_AVAILABLE = False\n",
    "\n",
    "# Mod√®le ML classique (Random Forest)\n",
    "try:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Cr√©ation et entra√Ænement du Random Forest avec config .env\n",
    "    ml_model = RandomForestClassifier(\n",
    "        n_estimators=RF_N_ESTIMATORS,\n",
    "        max_depth=RF_MAX_DEPTH,\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    # Entra√Ænement\n",
    "    ml_model.fit(X_flat, y_true)\n",
    "    \n",
    "    print(\"‚úÖ Mod√®le Random Forest cr√©√© et entra√Æn√©\")\n",
    "    print(f\"üìä Nombre d'arbres: {ml_model.n_estimators}\")\n",
    "    print(f\"üå≥ Profondeur max: {ml_model.max_depth}\")\n",
    "    \n",
    "    ML_AVAILABLE = True\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"‚ùå Scikit-learn non disponible - pas de mod√®le ML\")\n",
    "    ml_model = None\n",
    "    ML_AVAILABLE = False\n",
    "\n",
    "print(f\"\\nüìä R√©sum√© des mod√®les:\")\n",
    "print(f\"‚Ä¢ CNN disponible: {CNN_AVAILABLE}\")\n",
    "print(f\"‚Ä¢ ML disponible: {ML_AVAILABLE}\")\n",
    "print(f\"‚Ä¢ Configuration depuis .env: ‚úÖ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a42d7c9",
   "metadata": {},
   "source": [
    "## üéØ D√©monstration GradCAM\n",
    "\n",
    "GradCAM (Gradient-weighted Class Activation Mapping) permet de visualiser les r√©gions importantes pour la pr√©diction d'un CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18715b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CNN_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"üéØ D√©monstration GradCAM\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Initialisation de l'explainer GradCAM\n",
    "    try:\n",
    "        gradcam_explainer = GradCAMExplainer(cnn_model)\n",
    "        print(f\"‚úÖ GradCAM explainer initialis√©\")\n",
    "        print(f\"üîç Couche analys√©e: {gradcam_explainer.layer_name}\")\n",
    "        \n",
    "        # S√©lection d'une image pour l'analyse\n",
    "        test_image = X_images[0]  # Premi√®re image\n",
    "        true_class = y_true[0]\n",
    "        \n",
    "        print(f\"\\nüñºÔ∏è Analyse de l'image test\")\n",
    "        print(f\"‚Ä¢ Classe r√©elle: {CLASS_NAMES[true_class]}\")\n",
    "        print(f\"‚Ä¢ Shape: {test_image.shape}\")\n",
    "        \n",
    "        # G√©n√©ration de la carte GradCAM avec param√®tres .env\n",
    "        print(f\"\\nüîç G√©n√©ration GradCAM (alpha={GRADCAM_ALPHA}, colormap={GRADCAM_COLORMAP})...\")\n",
    "        gradcam_results = gradcam_explainer.generate_gradcam(\n",
    "            test_image, \n",
    "            alpha=GRADCAM_ALPHA, \n",
    "            colormap=GRADCAM_COLORMAP\n",
    "        )\n",
    "        \n",
    "        predicted_class = gradcam_results['predicted_class']\n",
    "        confidence = gradcam_results['prediction_confidence']\n",
    "        \n",
    "        print(f\"‚úÖ GradCAM g√©n√©r√© !\")\n",
    "        print(f\"‚Ä¢ Classe pr√©dite: {CLASS_NAMES[predicted_class]}\")\n",
    "        print(f\"‚Ä¢ Confiance: {confidence:.2%}\")\n",
    "        \n",
    "        # Seuils de confiance depuis .env\n",
    "        confidence_high = float(os.getenv('CONFIDENCE_HIGH_THRESHOLD', 0.8))\n",
    "        confidence_medium = float(os.getenv('CONFIDENCE_MEDIUM_THRESHOLD', 0.6))\n",
    "        \n",
    "        if confidence > confidence_high:\n",
    "            print(\"üî• Confiance √©lev√©e\")\n",
    "        elif confidence > confidence_medium:\n",
    "            print(\"‚ö° Confiance moyenne\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Confiance faible\")\n",
    "        \n",
    "        # Visualisation des r√©sultats\n",
    "        fig = gradcam_explainer.plot_gradcam(\n",
    "            gradcam_results,\n",
    "            title=f\"Analyse GradCAM - {CLASS_NAMES[predicted_class]}\",\n",
    "            class_names=CLASS_NAMES\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        # Analyse quantitative\n",
    "        from src.features.raf.interpretability.gradcam_explainer import (\n",
    "            extract_gradcam_features,\n",
    "            analyze_gradcam_regions\n",
    "        )\n",
    "        \n",
    "        features = extract_gradcam_features(gradcam_results['heatmap'])\n",
    "        regions = analyze_gradcam_regions(gradcam_results['heatmap'])\n",
    "        \n",
    "        print(f\"\\nüìä Analyse quantitative:\")\n",
    "        print(f\"‚Ä¢ Activation moyenne: {features['mean_activation']:.3f}\")\n",
    "        print(f\"‚Ä¢ Activation maximale: {features['max_activation']:.3f}\")\n",
    "        print(f\"‚Ä¢ Entropie: {features['entropy']:.3f}\")\n",
    "        print(f\"‚Ä¢ Concentration >75%: {features['concentration_75']:.1%}\")\n",
    "        print(f\"‚Ä¢ R√©gion importante: {regions['importance_ratio']:.1%}\")\n",
    "        print(f\"‚Ä¢ Configuration depuis .env: ‚úÖ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur GradCAM: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GradCAM non disponible (CNN ou RAF manquant)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CNN_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"üîÑ Comparaison GradCAM vs GradCAM++\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # G√©n√©ration des deux m√©thodes\n",
    "        test_image = X_images[1]  # Deuxi√®me image\n",
    "        \n",
    "        gradcam_result = gradcam_explainer.generate_gradcam(test_image)\n",
    "        gradcam_plus_result = gradcam_explainer.generate_gradcam_plus_plus(test_image)\n",
    "        \n",
    "        # Comparaison visuelle\n",
    "        from src.features.raf.interpretability.gradcam_explainer import visualize_gradcam_comparison\n",
    "        \n",
    "        comparison_results = {\n",
    "            'GradCAM': gradcam_result,\n",
    "            'GradCAM++': gradcam_plus_result\n",
    "        }\n",
    "        \n",
    "        fig = visualize_gradcam_comparison(\n",
    "            comparison_results,\n",
    "            title=\"Comparaison GradCAM vs GradCAM++\",\n",
    "            class_names=CLASS_NAMES\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        # Comparaison quantitative\n",
    "        features_gradcam = extract_gradcam_features(gradcam_result['heatmap'])\n",
    "        features_gradcam_plus = extract_gradcam_features(gradcam_plus_result['heatmap'])\n",
    "        \n",
    "        comparison_df = pd.DataFrame({\n",
    "            'M√©trique': ['Activation moyenne', 'Activation max', 'Entropie', 'Concentration 75%'],\n",
    "            'GradCAM': [\n",
    "                features_gradcam['mean_activation'],\n",
    "                features_gradcam['max_activation'],\n",
    "                features_gradcam['entropy'],\n",
    "                features_gradcam['concentration_75']\n",
    "            ],\n",
    "            'GradCAM++': [\n",
    "                features_gradcam_plus['mean_activation'],\n",
    "                features_gradcam_plus['max_activation'],\n",
    "                features_gradcam_plus['entropy'],\n",
    "                features_gradcam_plus['concentration_75']\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        print(\"\\nüìä Comparaison quantitative:\")\n",
    "        print(comparison_df.to_string(index=False, float_format='%.3f'))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur comparaison: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Comparaison GradCAM non disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d3d56a",
   "metadata": {},
   "source": [
    "## üìä D√©monstration SHAP\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) permet d'expliquer les pr√©dictions de tout type de mod√®le en quantifiant l'importance de chaque feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b997e9",
   "metadata": {},
   "source": [
    "## üçÉ D√©monstration LIME\n",
    "\n",
    "LIME (Local Interpretable Model-agnostic Explanations) explique les pr√©dictions en approximant localement le mod√®le avec un mod√®le interpr√©table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CNN_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"üçÉ D√©monstration LIME\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # V√©rifier que LIME est disponible\n",
    "        try:\n",
    "            import lime\n",
    "            print(\"‚úÖ LIME disponible\")\n",
    "            LIME_AVAILABLE = True\n",
    "        except ImportError:\n",
    "            print(\"‚ùå LIME non disponible - installation n√©cessaire\")\n",
    "            print(\"!pip install lime\")\n",
    "            LIME_AVAILABLE = False\n",
    "        \n",
    "        if LIME_AVAILABLE:\n",
    "            # Initialisation de l'explainer LIME\n",
    "            def preprocess_for_lime(images):\n",
    "                \"\"\"Fonction de pr√©processing pour LIME\"\"\"\n",
    "                if len(images.shape) == 3:\n",
    "                    images = np.expand_dims(images, axis=0)\n",
    "                # Normalisation pour le mod√®le CNN\n",
    "                return images.astype(np.float32) / 255.0\n",
    "            \n",
    "            lime_explainer = LIMEExplainer(cnn_model, preprocess_fn=preprocess_for_lime)\n",
    "            print(f\"‚úÖ LIME explainer initialis√©\")\n",
    "            \n",
    "            # S√©lection d'une image pour l'analyse LIME\n",
    "            test_image = X_images[0]  # Premi√®re image\n",
    "            true_class = y_true[0]\n",
    "            \n",
    "            print(f\"\\nüñºÔ∏è Analyse LIME de l'image test\")\n",
    "            print(f\"‚Ä¢ Classe r√©elle: {CLASS_NAMES[true_class]}\")\n",
    "            print(f\"‚Ä¢ Shape: {test_image.shape}\")\n",
    "            print(f\"‚Ä¢ √âchantillons LIME: {LIME_NUM_SAMPLES}\")\n",
    "            \n",
    "            # G√©n√©ration de l'explication LIME\n",
    "            print(f\"\\nüîç G√©n√©ration de l'explication LIME...\")\n",
    "            lime_results = lime_explainer.explain_image(\n",
    "                test_image.squeeze(),  # LIME attend (H, W, C)\n",
    "                top_labels=NUM_CLASSES,\n",
    "                num_samples=LIME_NUM_SAMPLES,\n",
    "                num_features=100\n",
    "            )\n",
    "            \n",
    "            predicted_class = lime_results['predicted_class']\n",
    "            confidence = lime_results['prediction_confidence']\n",
    "            \n",
    "            print(f\"‚úÖ Explication LIME g√©n√©r√©e !\")\n",
    "            print(f\"‚Ä¢ Classe pr√©dite: {CLASS_NAMES[predicted_class]}\")\n",
    "            print(f\"‚Ä¢ Confiance: {confidence:.2%}\")\n",
    "            \n",
    "            # Visualisation des r√©sultats LIME\n",
    "            fig = lime_explainer.plot_lime_explanation(\n",
    "                lime_results,\n",
    "                title=f\"Analyse LIME - {CLASS_NAMES[predicted_class]}\",\n",
    "                class_names=CLASS_NAMES,\n",
    "                num_features=10\n",
    "            )\n",
    "            plt.show()\n",
    "            \n",
    "            # Analyse quantitative LIME\n",
    "            analysis = lime_explainer.analyze_lime_features(lime_results)\n",
    "            \n",
    "            print(f\"\\nüìä Analyse quantitative LIME:\")\n",
    "            print(f\"‚Ä¢ Nombre total de superpixels: {analysis['num_features']}\")\n",
    "            print(f\"‚Ä¢ Features positives: {analysis['positive_features']}\")\n",
    "            print(f\"‚Ä¢ Features n√©gatives: {analysis['negative_features']}\")\n",
    "            print(f\"‚Ä¢ Ratio positif: {analysis['positive_ratio']:.1%}\")\n",
    "            print(f\"‚Ä¢ Poids total: {analysis['total_weight']:.3f}\")\n",
    "            \n",
    "            # Top features\n",
    "            print(f\"\\nüèÜ Top 5 Features Positives:\")\n",
    "            for i, (feature_id, weight) in enumerate(analysis['top_positive_features'][:5]):\n",
    "                print(f\"  {i+1}. Superpixel {feature_id}: {weight:.3f}\")\n",
    "            \n",
    "            if analysis['top_negative_features']:\n",
    "                print(f\"\\n‚ö†Ô∏è Top 5 Features N√©gatives:\")\n",
    "                for i, (feature_id, weight) in enumerate(analysis['top_negative_features'][:5]):\n",
    "                    print(f\"  {i+1}. Superpixel {feature_id}: {weight:.3f}\")\n",
    "        \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è LIME non disponible pour cette d√©monstration\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur LIME: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è LIME non disponible (CNN ou RAF manquant)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb89d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CNN_AVAILABLE and RAF_AVAILABLE and 'lime_explainer' in locals():\n",
    "    print(\"üîÑ Comparaison LIME avec Multiple Images\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # S√©lection de plusieurs images pour comparaison\n",
    "        n_compare = min(3, len(X_images))\n",
    "        compare_images = [X_images[i].squeeze() for i in range(n_compare)]\n",
    "        compare_labels = [f\"{CLASS_NAMES[y_true[i]]} (r√©el)\" for i in range(n_compare)]\n",
    "        \n",
    "        print(f\"üîç Comparaison LIME sur {n_compare} images...\")\n",
    "        \n",
    "        # Comparaison LIME\n",
    "        comparison_results = lime_explainer.compare_lime_explanations(\n",
    "            compare_images,\n",
    "            labels=compare_labels,\n",
    "            num_samples=500  # Moins d'√©chantillons pour acc√©l√©rer\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Comparaison LIME termin√©e !\")\n",
    "        \n",
    "        # Visualisation de la comparaison\n",
    "        fig = visualize_lime_comparison(comparison_results, class_names=CLASS_NAMES)\n",
    "        if fig is not None:\n",
    "            plt.show()\n",
    "        \n",
    "        # Analyse comparative des r√©sultats\n",
    "        analyses = comparison_results['analyses']\n",
    "        valid_analyses = [a for a in analyses if a is not None]\n",
    "        \n",
    "        if valid_analyses:\n",
    "            print(f\"\\nüìä Analyse Comparative LIME:\")\n",
    "            \n",
    "            # Statistiques moyennes\n",
    "            avg_positive = np.mean([a['positive_features'] for a in valid_analyses])\n",
    "            avg_negative = np.mean([a['negative_features'] for a in valid_analyses])\n",
    "            avg_ratio = np.mean([a['positive_ratio'] for a in valid_analyses])\n",
    "            \n",
    "            print(f\"‚Ä¢ Features positives (moyenne): {avg_positive:.1f}\")\n",
    "            print(f\"‚Ä¢ Features n√©gatives (moyenne): {avg_negative:.1f}\")\n",
    "            print(f\"‚Ä¢ Ratio positif (moyenne): {avg_ratio:.1%}\")\n",
    "            \n",
    "            # Comparaison par image\n",
    "            for i, (analysis, label) in enumerate(zip(analyses, compare_labels)):\n",
    "                if analysis:\n",
    "                    print(f\"\\n{label}:\")\n",
    "                    print(f\"  ‚Ä¢ Features: {analysis['positive_features']}(+) / {analysis['negative_features']}(-)\")\n",
    "                    print(f\"  ‚Ä¢ Ratio positif: {analysis['positive_ratio']:.1%}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur comparaison LIME: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Comparaison LIME non disponible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ML_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"üìä D√©monstration SHAP\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Configuration SHAP depuis .env\n",
    "        shap_model_type = os.getenv('SHAP_MODEL_TYPE', 'tree')\n",
    "        \n",
    "        # Initialisation de l'explainer SHAP\n",
    "        shap_explainer = SHAPExplainer(ml_model, model_type=shap_model_type)\n",
    "        print(f\"‚úÖ SHAP explainer initialis√© (type: {shap_model_type})\")\n",
    "        \n",
    "        # Pr√©paration des donn√©es avec taille configur√©e dans .env\n",
    "        X_background = X_flat[:SHAP_BACKGROUND_SIZE]  # √âchantillons d'arri√®re-plan\n",
    "        X_explain = X_flat[SHAP_BACKGROUND_SIZE:SHAP_BACKGROUND_SIZE+2]   # √âchantillons √† expliquer\n",
    "        \n",
    "        print(f\"\\nüîß Configuration depuis .env:\")\n",
    "        print(f\"‚Ä¢ Donn√©es arri√®re-plan: {X_background.shape} (size={SHAP_BACKGROUND_SIZE})\")\n",
    "        print(f\"‚Ä¢ Donn√©es √† expliquer: {X_explain.shape}\")\n",
    "        print(f\"‚Ä¢ Max √©valuations: {SHAP_MAX_EVALS}\")\n",
    "        \n",
    "        # Ajustement de l'explainer\n",
    "        print(\"\\nüîç Ajustement de l'explainer...\")\n",
    "        shap_explainer.fit_explainer(X_background)\n",
    "        \n",
    "        # Calcul des valeurs SHAP\n",
    "        print(\"üìä Calcul des valeurs SHAP...\")\n",
    "        shap_values = shap_explainer.explain(X_explain, max_evals=SHAP_MAX_EVALS)\n",
    "        \n",
    "        print(f\"‚úÖ Valeurs SHAP calcul√©es !\")\n",
    "        print(f\"‚Ä¢ Shape: {shap_values.shape if not isinstance(shap_values, list) else [v.shape for v in shap_values]}\")\n",
    "        \n",
    "        # Visualisation waterfall pour le premier √©chantillon\n",
    "        print(\"\\nüåä Graphique Waterfall...\")\n",
    "        try:\n",
    "            # S√©lection des features les plus importantes pour la visualisation\n",
    "            if isinstance(shap_values, list):\n",
    "                sample_shap = shap_values[0][0]  # Premier √©chantillon, premi√®re classe\n",
    "            else:\n",
    "                sample_shap = shap_values[0]     # Premier √©chantillon\n",
    "            \n",
    "            # Top 20 features par importance absolue\n",
    "            top_indices = np.argsort(np.abs(sample_shap))[-20:]\n",
    "            feature_names = [f'Pixel_{i}' for i in top_indices]\n",
    "            \n",
    "            fig = shap_explainer.plot_waterfall(\n",
    "                instance_idx=0,\n",
    "                feature_names=feature_names,\n",
    "                show=True\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Waterfall non disponible: {e}\")\n",
    "            # Graphique alternatif\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            \n",
    "            if isinstance(shap_values, list):\n",
    "                values = shap_values[0][0][:50]  # Top 50 pixels\n",
    "            else:\n",
    "                values = shap_values[0][:50]\n",
    "            \n",
    "            colors = ['red' if v > 0 else 'blue' for v in values]\n",
    "            bars = ax.bar(range(len(values)), values, color=colors, alpha=0.7)\n",
    "            ax.set_xlabel('Pixels')\n",
    "            ax.set_ylabel('Valeur SHAP')\n",
    "            ax.set_title('Contribution des Pixels (SHAP) - Top 50')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # Importance globale des features\n",
    "        print(\"\\nüìà Importance globale des features...\")\n",
    "        importance_df = shap_explainer.get_feature_importance()\n",
    "        \n",
    "        # Visualisation de l'importance\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        top_features = importance_df.head(20)\n",
    "        \n",
    "        bars = ax.barh(range(len(top_features)), top_features['importance'], alpha=0.7)\n",
    "        ax.set_yticks(range(len(top_features)))\n",
    "        ax.set_yticklabels([f'Pixel_{i}' for i in range(len(top_features))])\n",
    "        ax.set_xlabel('Importance SHAP moyenne')\n",
    "        ax.set_title('Top 20 Pixels - Importance SHAP')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Statistiques SHAP\n",
    "        if isinstance(shap_values, list):\n",
    "            stats_values = shap_values[0]\n",
    "        else:\n",
    "            stats_values = shap_values\n",
    "            \n",
    "        print(f\"\\nüìä Statistiques SHAP:\")\n",
    "        print(f\"‚Ä¢ Nombre d'√©chantillons: {stats_values.shape[0]}\")\n",
    "        print(f\"‚Ä¢ Nombre de features: {stats_values.shape[1]}\")\n",
    "        print(f\"‚Ä¢ Valeur moyenne: {np.mean(stats_values):.4f}\")\n",
    "        print(f\"‚Ä¢ Valeur max: {np.max(stats_values):.4f}\")\n",
    "        print(f\"‚Ä¢ Valeur min: {np.min(stats_values):.4f}\")\n",
    "        print(f\"‚Ä¢ √âcart-type: {np.std(stats_values):.4f}\")\n",
    "        print(f\"‚Ä¢ Configuration depuis .env: ‚úÖ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur SHAP: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è SHAP non disponible (ML ou RAF manquant)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f73ae6",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Analyse Comparative SHAP vs GradCAM\n",
    "\n",
    "Comparaison des explications fournies par les deux m√©thodes sur la m√™me image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CNN_AVAILABLE and ML_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"‚öñÔ∏è Analyse Comparative SHAP vs GradCAM\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Initialisation de l'analyseur int√©gr√©\n",
    "        analyzer = InterpretabilityAnalyzer(\n",
    "            cnn_model=cnn_model,\n",
    "            ml_model=ml_model\n",
    "        )\n",
    "        \n",
    "        # S√©lection d'une image pour l'analyse comparative\n",
    "        test_idx = 2\n",
    "        test_image_cnn = X_images[test_idx]\n",
    "        test_image_ml = X_flat[test_idx]\n",
    "        true_class = y_true[test_idx]\n",
    "        \n",
    "        print(f\"\\nüñºÔ∏è Image test s√©lectionn√©e:\")\n",
    "        print(f\"‚Ä¢ Index: {test_idx}\")\n",
    "        print(f\"‚Ä¢ Classe r√©elle: {CLASS_NAMES[true_class]}\")\n",
    "        print(f\"‚Ä¢ Shape CNN: {test_image_cnn.shape}\")\n",
    "        print(f\"‚Ä¢ Shape ML: {test_image_ml.shape}\")\n",
    "        \n",
    "        # Analyse comparative\n",
    "        print(\"\\nüîç Lancement de l'analyse comparative...\")\n",
    "        comparison_results = analyzer.compare_predictions(\n",
    "            img=test_image_cnn,\n",
    "            X_flat=test_image_ml.reshape(1, -1),\n",
    "            X_background=X_flat[:3],  # Donn√©es d'arri√®re-plan\n",
    "            class_names=CLASS_NAMES\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Analyse comparative termin√©e !\")\n",
    "        \n",
    "        # Cr√©ation du tableau de bord int√©gr√©\n",
    "        print(\"\\nüìä G√©n√©ration du tableau de bord...\")\n",
    "        dashboard_fig = create_interpretability_dashboard(\n",
    "            analyzer=analyzer,\n",
    "            img=test_image_cnn,\n",
    "            X_flat=test_image_ml,\n",
    "            X_background=X_flat[:3],\n",
    "            class_names=CLASS_NAMES\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        # Rapport textuel de comparaison\n",
    "        if 'comparison_report' in comparison_results:\n",
    "            report = comparison_results['comparison_report']\n",
    "            print(f\"\\nüìã Rapport de Comparaison:\")\n",
    "            print(f\"‚Ä¢ Confiance CNN: {report.get('cnn_confidence', 'N/A')}\")\n",
    "            print(f\"‚Ä¢ Classe pr√©dite CNN: {report.get('cnn_predicted_class', 'N/A')}\")\n",
    "            print(f\"‚Ä¢ R√©sum√©: {report.get('summary', 'N/A')}\")\n",
    "        \n",
    "        # Coh√©rence des explications\n",
    "        print(f\"\\nüéØ Analyse de Coh√©rence:\")\n",
    "        \n",
    "        if 'cnn' in comparison_results and 'ml' in comparison_results:\n",
    "            cnn_confidence = comparison_results['cnn']['gradcam']['prediction_confidence']\n",
    "            cnn_class = comparison_results['cnn']['gradcam']['predicted_class']\n",
    "            \n",
    "            print(f\"‚Ä¢ GradCAM - Classe: {CLASS_NAMES[cnn_class]}, Confiance: {cnn_confidence:.2%}\")\n",
    "            print(f\"‚Ä¢ Classe r√©elle: {CLASS_NAMES[true_class]}\")\n",
    "            \n",
    "            if cnn_class == true_class:\n",
    "                print(\"‚úÖ Pr√©diction correcte !\")\n",
    "            else:\n",
    "                print(\"‚ùå Pr√©diction incorrecte\")\n",
    "            \n",
    "            if cnn_confidence > 0.8:\n",
    "                print(\"üî• Confiance √©lev√©e\")\n",
    "            elif cnn_confidence > 0.6:\n",
    "                print(\"‚ö° Confiance moyenne\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Confiance faible\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur analyse comparative: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Analyse comparative non disponible\")\n",
    "    print(f\"‚Ä¢ CNN: {CNN_AVAILABLE}\")\n",
    "    print(f\"‚Ä¢ ML: {ML_AVAILABLE}\")\n",
    "    print(f\"‚Ä¢ RAF: {RAF_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b3968",
   "metadata": {},
   "source": [
    "## üìà Analyse Batch et Rapport\n",
    "\n",
    "G√©n√©ration d'un rapport d'interpr√©tabilit√© sur plusieurs √©chantillons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581ff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CNN_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"üìà G√©n√©ration de Rapport Batch\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # S√©lection d'un batch d'images\n",
    "        batch_size = 5\n",
    "        batch_images = X_images[:batch_size]\n",
    "        batch_labels = y_true[:batch_size]\n",
    "        \n",
    "        print(f\"\\nüìä Configuration du batch:\")\n",
    "        print(f\"‚Ä¢ Nombre d'images: {batch_size}\")\n",
    "        print(f\"‚Ä¢ Classes: {[CLASS_NAMES[label] for label in batch_labels]}\")\n",
    "        \n",
    "        # G√©n√©ration du rapport\n",
    "        print(\"\\nüîç G√©n√©ration du rapport...\")\n",
    "        \n",
    "        analyzer = InterpretabilityAnalyzer(cnn_model=cnn_model)\n",
    "        \n",
    "        report_df = generate_interpretability_report(\n",
    "            analyzer=analyzer,\n",
    "            images=list(batch_images),\n",
    "            X_background=X_flat[:3],\n",
    "            class_names=CLASS_NAMES,\n",
    "            sample_names=[f\"Sample_{i+1}\" for i in range(batch_size)]\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Rapport g√©n√©r√© !\")\n",
    "        \n",
    "        # Affichage du rapport\n",
    "        print(\"\\nüìã Rapport d'Interpr√©tabilit√©:\")\n",
    "        print(report_df.to_string(index=False, float_format='%.3f'))\n",
    "        \n",
    "        # Analyse statistique du batch\n",
    "        if not report_df.empty:\n",
    "            print(f\"\\nüìä Statistiques du Batch:\")\n",
    "            print(f\"‚Ä¢ Confiance moyenne: {report_df['confidence'].mean():.2%}\")\n",
    "            print(f\"‚Ä¢ Confiance min: {report_df['confidence'].min():.2%}\")\n",
    "            print(f\"‚Ä¢ Confiance max: {report_df['confidence'].max():.2%}\")\n",
    "            \n",
    "            # Distribution des classes pr√©dites\n",
    "            class_dist = report_df['predicted_class_name'].value_counts() if 'predicted_class_name' in report_df.columns else report_df['predicted_class'].value_counts()\n",
    "            print(f\"\\nüè∑Ô∏è Distribution des pr√©dictions:\")\n",
    "            for class_name, count in class_dist.items():\n",
    "                print(f\"‚Ä¢ {class_name}: {count} ({count/len(report_df)*100:.1f}%)\")\n",
    "            \n",
    "            # Visualisation de la distribution des confiances\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            \n",
    "            # Histogramme des confiances\n",
    "            ax1.hist(report_df['confidence'], bins=10, alpha=0.7, edgecolor='black')\n",
    "            ax1.set_xlabel('Confiance')\n",
    "            ax1.set_ylabel('Nombre d\\'images')\n",
    "            ax1.set_title('Distribution des Confiances')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Graphique des activations moyennes\n",
    "            if 'gradcam_mean_activation' in report_df.columns:\n",
    "                ax2.scatter(report_df['confidence'], report_df['gradcam_mean_activation'], alpha=0.7)\n",
    "                ax2.set_xlabel('Confiance')\n",
    "                ax2.set_ylabel('Activation GradCAM Moyenne')\n",
    "                ax2.set_title('Confiance vs Activation GradCAM')\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # R√©sum√© visuel avec les meilleures pr√©dictions\n",
    "        print(\"\\nüñºÔ∏è R√©sum√© visuel des meilleures pr√©dictions...\")\n",
    "        \n",
    "        # G√©n√©ration des r√©sultats GradCAM pour visualisation\n",
    "        gradcam_results = []\n",
    "        for img in batch_images:\n",
    "            try:\n",
    "                result = gradcam_explainer.generate_gradcam(img)\n",
    "                gradcam_results.append(result)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if gradcam_results:\n",
    "            from src.features.raf.interpretability.utils import plot_interpretability_summary\n",
    "            \n",
    "            summary_fig = plot_interpretability_summary(\n",
    "                gradcam_results[:4],  # Max 4 √©chantillons\n",
    "                class_names=CLASS_NAMES\n",
    "            )\n",
    "            plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur rapport batch: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Rapport batch non disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc115361",
   "metadata": {},
   "source": [
    "## üè• Application M√©dicale - Cas d'Usage COVID-19\n",
    "\n",
    "D√©monstration d'un cas d'usage r√©aliste pour le diagnostic m√©dical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üè• Cas d'Usage M√©dical - Diagnostic COVID-19\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Simulation d'un cas m√©dical r√©aliste\n",
    "print(\"\\nüë®‚Äç‚öïÔ∏è Scenario: Diagnostic d'une radiographie pulmonaire\")\n",
    "print(\"\" * 50)\n",
    "\n",
    "# Informations patient (simul√©es)\n",
    "patient_info = {\n",
    "    'id': 'P001',\n",
    "    'age': 65,\n",
    "    'sexe': 'M',\n",
    "    'symptomes': ['Toux', 'Fi√®vre', 'Difficult√©s respiratoires'],\n",
    "    'antecedents': ['Hypertension'],\n",
    "    'date_exam': '2024-10-16'\n",
    "}\n",
    "\n",
    "print(f\"üìã Informations Patient:\")\n",
    "for key, value in patient_info.items():\n",
    "    print(f\"‚Ä¢ {key.capitalize()}: {value}\")\n",
    "\n",
    "# S√©lection d'une image \"suspecte\"\n",
    "suspect_image = X_images[0]\n",
    "print(f\"\\nüñºÔ∏è Radiographie analys√©e: {suspect_image.shape}\")\n",
    "\n",
    "# Affichage de l'image\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.imshow(suspect_image.squeeze(), cmap='gray')\n",
    "ax.set_title(f'Radiographie Patient {patient_info[\"id\"]}', fontsize=14)\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "if CNN_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"\\nüîç Analyse IA de la radiographie...\")\n",
    "    \n",
    "    try:\n",
    "        # Analyse GradCAM\n",
    "        gradcam_result = gradcam_explainer.generate_gradcam(suspect_image)\n",
    "        \n",
    "        predicted_class = gradcam_result['predicted_class']\n",
    "        confidence = gradcam_result['prediction_confidence']\n",
    "        predicted_disease = CLASS_NAMES[predicted_class]\n",
    "        \n",
    "        print(f\"\\nüéØ R√©sultats de l'Analyse IA:\")\n",
    "        print(f\"‚Ä¢ Diagnostic sugg√©r√©: {predicted_disease}\")\n",
    "        print(f\"‚Ä¢ Confiance du mod√®le: {confidence:.1%}\")\n",
    "        \n",
    "        # Interpr√©tation m√©dicale\n",
    "        if predicted_disease == 'COVID':\n",
    "            print(f\"‚ö†Ô∏è ALERTE: Suspicion COVID-19 d√©tect√©e\")\n",
    "            print(f\"üìã Recommandations:\")\n",
    "            print(f\"   ‚Ä¢ Test PCR recommand√©\")\n",
    "            print(f\"   ‚Ä¢ Isolement pr√©ventif\")\n",
    "            print(f\"   ‚Ä¢ Surveillance des sympt√¥mes\")\n",
    "        elif predicted_disease == 'Normal':\n",
    "            print(f\"‚úÖ Radiographie apparemment normale\")\n",
    "            print(f\"üìã Recommandations:\")\n",
    "            print(f\"   ‚Ä¢ Surveillance clinique\")\n",
    "            print(f\"   ‚Ä¢ Suivi si sympt√¥mes persistent\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Anomalie d√©tect√©e: {predicted_disease}\")\n",
    "            print(f\"üìã Recommandations:\")\n",
    "            print(f\"   ‚Ä¢ √âvaluation sp√©cialis√©e recommand√©e\")\n",
    "            print(f\"   ‚Ä¢ Tests compl√©mentaires\")\n",
    "        \n",
    "        # Visualisation avec zones d'int√©r√™t\n",
    "        print(f\"\\nüîç Zones d'attention identifi√©es par l'IA:\")\n",
    "        \n",
    "        fig = gradcam_explainer.plot_gradcam(\n",
    "            gradcam_result,\n",
    "            title=f\"Analyse IA - Patient {patient_info['id']} - {predicted_disease}\",\n",
    "            class_names=CLASS_NAMES\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        # Analyse quantitative pour le rapport m√©dical\n",
    "        features = extract_gradcam_features(gradcam_result['heatmap'])\n",
    "        regions = analyze_gradcam_regions(gradcam_result['heatmap'])\n",
    "        \n",
    "        print(f\"\\nüìä Analyse Quantitative (pour le dossier m√©dical):\")\n",
    "        print(f\"‚Ä¢ Zone d'attention: {regions['importance_ratio']:.1%} de l'image\")\n",
    "        print(f\"‚Ä¢ Intensit√© moyenne des zones suspectes: {features['mean_activation']:.3f}\")\n",
    "        print(f\"‚Ä¢ Score de confiance technique: {confidence:.3f}\")\n",
    "        \n",
    "        # Niveau de confiance pour le m√©decin\n",
    "        if confidence > 0.9:\n",
    "            confidence_level = \"Tr√®s √©lev√©e\"\n",
    "            recommendation = \"Diagnostic IA tr√®s fiable\"\n",
    "        elif confidence > 0.75:\n",
    "            confidence_level = \"√âlev√©e\"\n",
    "            recommendation = \"Diagnostic IA fiable, confirmation clinique recommand√©e\"\n",
    "        elif confidence > 0.6:\n",
    "            confidence_level = \"Mod√©r√©e\"\n",
    "            recommendation = \"Diagnostic IA incertain, expertise m√©dicale n√©cessaire\"\n",
    "        else:\n",
    "            confidence_level = \"Faible\"\n",
    "            recommendation = \"Diagnostic IA peu fiable, r√©√©valuation recommand√©e\"\n",
    "        \n",
    "        print(f\"\\nüë®‚Äç‚öïÔ∏è Interpr√©tation pour le M√©decin:\")\n",
    "        print(f\"‚Ä¢ Niveau de confiance: {confidence_level}\")\n",
    "        print(f\"‚Ä¢ Recommandation: {recommendation}\")\n",
    "        \n",
    "        # G√©n√©ration d'un rapport m√©dical structur√©\n",
    "        medical_report = f\"\"\"\n",
    "RAPPORT D'ANALYSE IA - RADIOGRAPHIE PULMONAIRE\n",
    "=============================================\n",
    "\n",
    "Patient: {patient_info['id']}\n",
    "Date: {patient_info['date_exam']}\n",
    "√Çge: {patient_info['age']} ans, Sexe: {patient_info['sexe']}\n",
    "\n",
    "R√âSULTATS DE L'ANALYSE IA:\n",
    "‚Ä¢ Diagnostic sugg√©r√©: {predicted_disease}\n",
    "‚Ä¢ Confiance du mod√®le: {confidence:.1%}\n",
    "‚Ä¢ Niveau de confiance: {confidence_level}\n",
    "\n",
    "ANALYSE QUANTITATIVE:\n",
    "‚Ä¢ Zone d'attention: {regions['importance_ratio']:.1%} de l'image\n",
    "‚Ä¢ Intensit√© des anomalies: {features['mean_activation']:.3f}\n",
    "‚Ä¢ Score de concentration: {features['concentration_75']:.1%}\n",
    "\n",
    "RECOMMANDATIONS CLINIQUES:\n",
    "{recommendation}\n",
    "\n",
    "NOTES:\n",
    "‚Ä¢ Cette analyse IA est un outil d'aide au diagnostic\n",
    "‚Ä¢ L'expertise m√©dicale reste indispensable\n",
    "‚Ä¢ En cas de doute, privil√©gier l'√©valuation clinique\n",
    "\n",
    "G√©n√©r√© automatiquement le {patient_info['date_exam']}\n",
    "        \"\"\"\n",
    "        \n",
    "        print(medical_report)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur analyse m√©dicale: {e}\")\n",
    "        print(f\"‚ö†Ô∏è En situation r√©elle, consulter un radiologue\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Analyse IA non disponible\")\n",
    "    print(\"En situation r√©elle, la radiographie serait analys√©e par un m√©decin\")\n",
    "\n",
    "print(f\"\\nüè• Fin du cas m√©dical - Patient {patient_info['id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572958f7",
   "metadata": {},
   "source": [
    "## üìù Conclusion et Bonnes Pratiques\n",
    "\n",
    "### üéØ R√©sum√© des Techniques\n",
    "\n",
    "1. **GradCAM** : Visualisation des zones importantes pour les CNN\n",
    "   - ‚úÖ Intuitive et visuelle\n",
    "   - ‚úÖ Sp√©cifique aux r√©seaux convolutionnels\n",
    "   - ‚ùå Limit√©e aux mod√®les avec couches convolutionnelles\n",
    "\n",
    "2. **SHAP** : Quantification de l'importance des features\n",
    "   - ‚úÖ Universel (tous types de mod√®les)\n",
    "   - ‚úÖ Fondements th√©oriques solides\n",
    "   - ‚ùå Plus lent sur de grandes donn√©es\n",
    "\n",
    "3. **LIME** : Explication par approximation locale\n",
    "   - ‚úÖ Agnostique au mod√®le\n",
    "   - ‚úÖ Explications intuitives par superpixels\n",
    "   - ‚úÖ Fonctionne bien sur les images\n",
    "   - ‚ùå Peut √™tre instable selon l'√©chantillonnage\n",
    "\n",
    "### üè• Applications M√©dicales\n",
    "\n",
    "- **Aide au diagnostic** : Identifier les zones suspectes\n",
    "- **Formation** : Comprendre les crit√®res du mod√®le\n",
    "- **Validation** : V√©rifier la coh√©rence des pr√©dictions\n",
    "- **Confiance** : √âvaluer la fiabilit√© des r√©sultats\n",
    "- **Tra√ßabilit√©** : Documenter les d√©cisions automatis√©es\n",
    "\n",
    "### ‚öñÔ∏è Bonnes Pratiques\n",
    "\n",
    "1. **Combinaison des m√©thodes** : Utiliser SHAP, GradCAM ET LIME\n",
    "2. **Validation humaine** : Toujours confirmer avec un expert\n",
    "3. **Seuils de confiance** : D√©finir des niveaux d'alerte\n",
    "4. **Documentation** : Tracer les d√©cisions du mod√®le\n",
    "5. **Donn√©es r√©elles** : Tester sur de vraies donn√©es m√©dicales\n",
    "\n",
    "### üîß Framework RAF\n",
    "\n",
    "Le framework RAF facilite l'int√©gration de l'interpr√©tabilit√© :\n",
    "- Modules pr√™ts √† l'emploi (SHAP, GradCAM, LIME)\n",
    "- Interface unifi√©e avec DataLoader int√©gr√©\n",
    "- Visualisations automatiques\n",
    "- Rapports structur√©s\n",
    "- Configuration via fichiers .env\n",
    "\n",
    "### üöÄ Prochaines √âtapes\n",
    "\n",
    "1. Int√©grer vos vrais mod√®les entra√Æn√©s\n",
    "2. Tester sur de vraies donn√©es m√©dicales COVID-19\n",
    "3. Valider avec des experts m√©dicaux\n",
    "4. D√©ployer dans l'interface Streamlit\n",
    "5. Automatiser les rapports d'interpr√©tabilit√©\n",
    "6. Comparer les r√©sultats SHAP, GradCAM et LIME\n",
    "\n",
    "### üìä Recommandations d'Usage\n",
    "\n",
    "- **GradCAM** : Pour visualiser rapidement les zones d'attention\n",
    "- **LIME** : Pour expliquer des cas sp√©cifiques aux m√©decins\n",
    "- **SHAP** : Pour des analyses quantitatives et comparatives\n",
    "- **Combinaison** : Pour une validation crois√©e des explications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f147b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéâ NOTEBOOK D'INTERPR√âTABILIT√â TERMIN√â\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summary_stats = {\n",
    "    'Modules test√©s': {\n",
    "        'SHAP': 'Disponible' if RAF_AVAILABLE else 'Non disponible',\n",
    "        'GradCAM': 'Disponible' if RAF_AVAILABLE else 'Non disponible',\n",
    "        'LIME': 'Disponible' if RAF_AVAILABLE else 'Non disponible',\n",
    "        'Framework RAF': 'Disponible' if RAF_AVAILABLE else 'Non disponible'\n",
    "    },\n",
    "    'Donn√©es': {\n",
    "        'DataLoader RAF': 'Disponible' if DATALOADER_AVAILABLE else 'Non disponible',\n",
    "        'Donn√©es r√©elles': 'Charg√©es' if 'REAL_DATA_LOADED' in locals() and REAL_DATA_LOADED else 'Simul√©es',\n",
    "        'Dataset COVID-19': 'Utilis√©' if 'REAL_DATA_LOADED' in locals() and REAL_DATA_LOADED else 'Non utilis√©'\n",
    "    },\n",
    "    'Mod√®les utilis√©s': {\n",
    "        'CNN (TensorFlow)': 'Cr√©√©' if CNN_AVAILABLE else 'Non disponible',\n",
    "        'ML (Random Forest)': 'Cr√©√©' if ML_AVAILABLE else 'Non disponible'\n",
    "    },\n",
    "    'Analyses r√©alis√©es': {\n",
    "        'GradCAM simple': '‚úÖ' if CNN_AVAILABLE and RAF_AVAILABLE else '‚ùå',\n",
    "        'GradCAM++': '‚úÖ' if CNN_AVAILABLE and RAF_AVAILABLE else '‚ùå',\n",
    "        'LIME Image': '‚úÖ' if CNN_AVAILABLE and RAF_AVAILABLE else '‚ùå',\n",
    "        'LIME Comparaison': '‚úÖ' if CNN_AVAILABLE and RAF_AVAILABLE else '‚ùå',\n",
    "        'SHAP Tree': '‚úÖ' if ML_AVAILABLE and RAF_AVAILABLE else '‚ùå',\n",
    "        'Analyse comparative': '‚úÖ' if CNN_AVAILABLE and ML_AVAILABLE and RAF_AVAILABLE else '‚ùå',\n",
    "        'Rapport batch': '‚úÖ' if CNN_AVAILABLE and RAF_AVAILABLE else '‚ùå',\n",
    "        'Cas m√©dical': '‚úÖ' if CNN_AVAILABLE and RAF_AVAILABLE else '‚ùå'\n",
    "    }\n",
    "}\n",
    "\n",
    "for category, items in summary_stats.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for item, status in items.items():\n",
    "        print(f\"  ‚Ä¢ {item}: {status}\")\n",
    "\n",
    "print(f\"\\nüìö Ressources:\")\n",
    "print(f\"  ‚Ä¢ Framework RAF: src/features/raf/interpretability/\")\n",
    "print(f\"  ‚Ä¢ DataLoader RAF: src/features/raf/data/\")\n",
    "print(f\"  ‚Ä¢ Interface Streamlit: src/streamlit/pages/03_Interpretability.py\")\n",
    "print(f\"  ‚Ä¢ Documentation SHAP: https://shap.readthedocs.io/\")\n",
    "print(f\"  ‚Ä¢ Paper GradCAM: https://arxiv.org/abs/1610.02391\")\n",
    "print(f\"  ‚Ä¢ Paper LIME: https://arxiv.org/abs/1602.04938\")\n",
    "\n",
    "print(f\"\\nüöÄ Prochaines √©tapes:\")\n",
    "print(f\"  1. Installer LIME si n√©cessaire: pip install lime\")\n",
    "print(f\"  2. Charger vos mod√®les r√©els entra√Æn√©s\")\n",
    "print(f\"  3. Tester sur vraies donn√©es COVID-19\")\n",
    "print(f\"  4. Valider avec experts m√©dicaux\")\n",
    "print(f\"  5. Comparer SHAP, GradCAM et LIME\")\n",
    "print(f\"  6. Int√©grer dans pipeline de production\")\n",
    "\n",
    "print(f\"\\n‚ú® L'interpr√©tabilit√© est essentielle pour l'IA m√©dicale !\")\n",
    "print(f\"üîç SHAP + GradCAM + LIME = Triangle d'or de l'explicabilit√©\")\n",
    "print(f\"üè• Continuez √† explorer et √† valider vos mod√®les.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
