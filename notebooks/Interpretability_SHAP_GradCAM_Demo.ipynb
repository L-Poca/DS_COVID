{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16746e7",
   "metadata": {},
   "source": [
    "# 🔍 Interprétabilité des Modèles COVID-19 avec SHAP, GradCAM et LIME\n",
    "\n",
    "Ce notebook démontre l'utilisation des techniques d'interprétabilité **SHAP**, **GradCAM** et **LIME** pour expliquer les prédictions des modèles de classification COVID-19.\n",
    "\n",
    "## 📋 Objectifs\n",
    "\n",
    "1. **🎯 GradCAM** : Visualiser les zones importantes pour les prédictions CNN\n",
    "2. **📊 SHAP** : Quantifier l'importance des features pour tous types de modèles\n",
    "3. **🍃 LIME** : Explications locales par superpixels pour modèles image\n",
    "4. **⚖️ Comparaison** : Analyser la cohérence entre les différentes méthodes\n",
    "5. **🏥 Application** : Cas d'usage médical pour le diagnostic COVID-19\n",
    "\n",
    "## 🚀 Framework RAF\n",
    "\n",
    "Nous utilisons le **framework RAF** (Raw Augmentation Framework) qui intègre maintenant les modules d'interprétabilité :\n",
    "- `raf.interpretability.SHAPExplainer` - Explications SHAP universelles\n",
    "- `raf.interpretability.GradCAMExplainer` - Visualisations GradCAM pour CNN\n",
    "- `raf.interpretability.LIMEExplainer` - Explications LIME par superpixels\n",
    "- `raf.interpretability.InterpretabilityAnalyzer` - Analyse comparative\n",
    "- `raf.data.DataLoader` - Chargement de vos vraies données COVID-19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2002ae",
   "metadata": {},
   "source": [
    "## ⚙️ Configuration et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18daafb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Chargement de la configuration .env...\n",
      "✅ Configuration chargée depuis: /home/cepa/DST/projet_DS/DS_COVID/.env\n",
      "📁 Répertoire de travail: /home/cepa/DST/projet_DS/DS_COVID\n",
      "🎯 Répertoire source: /home/cepa/DST/projet_DS/DS_COVID\n",
      "🔧 Configuration du framework RAF...\n",
      "✅ Configuration de base terminée\n",
      "✅ Configuration de base terminée\n"
     ]
    }
   ],
   "source": [
    "# Configuration universelle avec le framework RAF\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Chargement des variables d'environnement\n",
    "print(\"🔧 Chargement de la configuration .env...\")\n",
    "\n",
    "# Détection automatique du répertoire racine\n",
    "current_dir = Path().cwd()\n",
    "if 'notebooks' in str(current_dir):\n",
    "    project_root = current_dir.parent\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "# Chargement du fichier .env\n",
    "env_path = project_root / '.env'\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(f\"✅ Configuration chargée depuis: {env_path}\")\n",
    "else:\n",
    "    print(f\"⚠️ Fichier .env non trouvé: {env_path}\")\n",
    "\n",
    "# Configuration du PYTHONPATH avec les variables d'environnement\n",
    "src_root = os.getenv('PROJECT_ROOT', str(project_root))\n",
    "if src_root not in sys.path:\n",
    "    sys.path.insert(0, src_root)\n",
    "\n",
    "print(f\"📁 Répertoire de travail: {project_root}\")\n",
    "print(f\"🎯 Répertoire source: {src_root}\")\n",
    "print(\"🔧 Configuration du framework RAF...\")\n",
    "\n",
    "# Imports standards\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuration graphiques depuis .env\n",
    "plot_style = os.getenv('PLOT_STYLE', 'default')\n",
    "color_palette = os.getenv('COLOR_PALETTE', 'husl')\n",
    "\n",
    "try:\n",
    "    plt.style.use(plot_style)\n",
    "except:\n",
    "    plt.style.use('default')\n",
    "    \n",
    "sns.set_palette(color_palette)\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuration warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Configuration de base terminée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7246f24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Répertoire projet: /home/cepa/DST/projet_DS/DS_COVID\n",
      "🐍 PYTHONPATH ajusté\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-16 22:16:40.789604: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎨 RAF (Raw Augmentation Framework) v2.0.0 chargé avec succès\n",
      "✨ NOUVELLE FONCTIONNALITÉ: setup_universal_environment() remplace la cellule 1!\n",
      "� NOUVEAU MODULE: interpretability (SHAP + GradCAM)\n",
      "��������� Modules disponibles: utils, data, augmentation, interpretability\n",
      "✅ Modules RAF d'interprétabilité chargés (SHAP, GradCAM, LIME)\n",
      "✅ DataLoader RAF chargé\n",
      "✅ TensorFlow disponible\n",
      "✅ SHAP disponible\n",
      "✅ OpenCV disponible\n",
      "✅ Scikit-learn disponible\n",
      "✅ LIME disponible\n",
      "\n",
      "🎉 Toutes les dépendances sont disponibles !\n",
      "\n",
      "📊 Statut des modules:\n",
      "• RAF Interpretability: ✅\n",
      "• DataLoader RAF: ✅\n",
      "🎉 Framework d'interprétabilité prêt avec SHAP, GradCAM et LIME !\n"
     ]
    }
   ],
   "source": [
    "# Imports du framework RAF\n",
    "# Configuration du chemin d'import\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Détection automatique du répertoire racine\n",
    "current_dir = Path.cwd()\n",
    "if 'notebooks' in str(current_dir):\n",
    "    project_root = current_dir.parent\n",
    "else:\n",
    "    project_root = current_dir\n",
    "\n",
    "# Ajout du répertoire racine au PYTHONPATH\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"📁 Répertoire projet: {project_root}\")\n",
    "print(f\"🐍 PYTHONPATH ajusté\")\n",
    "\n",
    "# Import direct depuis src/\n",
    "try:\n",
    "    from src.features.raf.interpretability import (\n",
    "        SHAPExplainer,\n",
    "        GradCAMExplainer,\n",
    "        LIMEExplainer,\n",
    "        InterpretabilityAnalyzer,\n",
    "        create_interpretability_dashboard,\n",
    "        generate_interpretability_report,\n",
    "        visualize_lime_comparison\n",
    "    )\n",
    "    print(\"✅ Modules RAF d'interprétabilité chargés (SHAP, GradCAM, LIME)\")\n",
    "    RAF_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Erreur import RAF: {e}\")\n",
    "    print(\"💡 Vérifiez l'installation du framework RAF\")\n",
    "    RAF_AVAILABLE = False\n",
    "\n",
    "# Import du DataLoader RAF pour les vraies données\n",
    "try:\n",
    "    from src.features.raf.data import DataLoader\n",
    "    print(\"✅ DataLoader RAF chargé\")\n",
    "    DATALOADER_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Erreur DataLoader: {e}\")\n",
    "    DATALOADER_AVAILABLE = False\n",
    "\n",
    "# Vérification des dépendances\n",
    "dependencies = {\n",
    "    'tensorflow': 'TensorFlow',\n",
    "    'shap': 'SHAP',\n",
    "    'cv2': 'OpenCV',\n",
    "    'sklearn': 'Scikit-learn',\n",
    "    'lime': 'LIME'\n",
    "}\n",
    "\n",
    "missing_deps = []\n",
    "for module, name in dependencies.items():\n",
    "    try:\n",
    "        __import__(module)\n",
    "        print(f\"✅ {name} disponible\")\n",
    "    except ImportError:\n",
    "        print(f\"❌ {name} manquant\")\n",
    "        missing_deps.append(name)\n",
    "\n",
    "if missing_deps:\n",
    "    print(f\"\\n📦 Installation nécessaire:\")\n",
    "    for dep in missing_deps:\n",
    "        if dep == 'SHAP':\n",
    "            print(\"!pip install shap\")\n",
    "        elif dep == 'TensorFlow':\n",
    "            print(\"!pip install tensorflow\")\n",
    "        elif dep == 'OpenCV':\n",
    "            print(\"!pip install opencv-python\")\n",
    "        elif dep == 'LIME':\n",
    "            print(\"!pip install lime\")\n",
    "else:\n",
    "    print(\"\\n🎉 Toutes les dépendances sont disponibles !\")\n",
    "\n",
    "print(f\"\\n📊 Statut des modules:\")\n",
    "print(f\"• RAF Interpretability: {'✅' if RAF_AVAILABLE else '❌'}\")\n",
    "print(f\"• DataLoader RAF: {'✅' if DATALOADER_AVAILABLE else '❌'}\")\n",
    "\n",
    "if RAF_AVAILABLE:\n",
    "    print(\"🎉 Framework d'interprétabilité prêt avec SHAP, GradCAM et LIME !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c80faf",
   "metadata": {},
   "source": [
    "## 📊 Chargement des Données et Modèles\n",
    "\n",
    "Nous allons utiliser des données simulées pour la démonstration. En pratique, vous remplacerez ceci par vos vrais modèles et données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc5ec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des vraies données COVID-19 avec DataLoader RAF\n",
    "print(\"🔄 Chargement des données réelles COVID-19...\")\n",
    "\n",
    "# Import de tqdm pour les barres de progression\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "if DATALOADER_AVAILABLE:\n",
    "    # 🎯 Configuration depuis .env avec CHEMINS ABSOLUS (Plus de problèmes !)\n",
    "    print(\"⚙️ Chargement de la configuration depuis .env...\")\n",
    "    \n",
    "    # Chemins absolus depuis .env\n",
    "    DATA_DIR = os.getenv('DATA_DIR', '/home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset')\n",
    "    MODELS_DIR = os.getenv('MODELS_DIR', '/home/cepa/DST/projet_DS/DS_COVID/models')\n",
    "    RESULTS_DIR = os.getenv('RESULTS_DIR', '/home/cepa/DST/projet_DS/DS_COVID/reports')\n",
    "    PROJECT_ROOT = os.getenv('PROJECT_ROOT', '/home/cepa/DST/projet_DS/DS_COVID')\n",
    "    \n",
    "    # Paramètres d'images\n",
    "    IMG_WIDTH = int(os.getenv('IMG_WIDTH', 224))\n",
    "    IMG_HEIGHT = int(os.getenv('IMG_HEIGHT', 224))\n",
    "    IMG_SIZE = (IMG_WIDTH, IMG_HEIGHT)\n",
    "    \n",
    "    # Paramètres de classes\n",
    "    NUM_CLASSES = int(os.getenv('NUM_CLASSES', 4))\n",
    "    CLASS_NAMES = os.getenv('CLASS_NAMES', 'COVID,Lung_Opacity,Normal,Viral Pneumonia').split(',')\n",
    "    RANDOM_SEED = int(os.getenv('RANDOM_SEED', 42))\n",
    "    \n",
    "    # Configuration d'interprétabilité depuis .env\n",
    "    GRADCAM_ALPHA = float(os.getenv('GRADCAM_ALPHA', 0.4))\n",
    "    GRADCAM_COLORMAP = os.getenv('GRADCAM_COLORMAP', 'jet')\n",
    "    SHAP_MAX_EVALS = int(os.getenv('SHAP_MAX_EVALS', 100))\n",
    "    SHAP_BACKGROUND_SIZE = int(os.getenv('SHAP_BACKGROUND_SIZE', 50))\n",
    "    LIME_NUM_SAMPLES = int(os.getenv('LIME_NUM_SAMPLES', 1000))\n",
    "    \n",
    "    print(f\"\\n📋 Configuration chargée (CHEMINS ABSOLUS):\")\n",
    "    print(f\"🏠 Racine du projet: {PROJECT_ROOT}\")\n",
    "    print(f\"📁 Répertoire de données: {DATA_DIR}\")\n",
    "    print(f\"🤖 Répertoire modèles: {MODELS_DIR}\")\n",
    "    print(f\"\udcca Répertoire résultats: {RESULTS_DIR}\")\n",
    "    print(f\"\ud83d🖼️ Taille d'image: {IMG_SIZE}\")\n",
    "    print(f\"🏷️ Nombre de classes: {NUM_CLASSES}\")\n",
    "    print(f\"📋 Classes: {CLASS_NAMES}\")\n",
    "    print(f\"🎯 Config interprétabilité:\")\n",
    "    print(f\"  • GradCAM Alpha: {GRADCAM_ALPHA}, Colormap: {GRADCAM_COLORMAP}\")\n",
    "    print(f\"  • SHAP Max Evals: {SHAP_MAX_EVALS}, Background Size: {SHAP_BACKGROUND_SIZE}\")\n",
    "    print(f\"  • LIME Samples: {LIME_NUM_SAMPLES}\")\n",
    "    \n",
    "    # Vérification simple de la structure avec chemins absolus\n",
    "    from pathlib import Path\n",
    "    data_path = Path(DATA_DIR)\n",
    "    \n",
    "    print(f\"\\n🔍 Vérification de la structure des données...\")\n",
    "    with tqdm(total=len(CLASS_NAMES) + 2, desc=\"Vérification structure\", colour='blue') as pbar:\n",
    "        print(f\"📂 Chemin absolu: {data_path}\")\n",
    "        print(f\"📂 Existe: {data_path.exists()}\")\n",
    "        pbar.update(1)\n",
    "        \n",
    "        if data_path.exists():\n",
    "            # Vérifier chaque classe\n",
    "            found_classes = []\n",
    "            class_counts_manual = {}\n",
    "            \n",
    "            for class_name in CLASS_NAMES:\n",
    "                class_path = data_path / class_name\n",
    "                exists = class_path.exists()\n",
    "                \n",
    "                if exists:\n",
    "                    # Compter les images\n",
    "                    images = list(class_path.glob('**/*.png')) + list(class_path.glob('**/*.jpg')) + list(class_path.glob('**/*.jpeg'))\n",
    "                    image_count = len(images)\n",
    "                    class_counts_manual[class_name] = image_count\n",
    "                    \n",
    "                    print(f\"📁 {class_name}: ✅ {image_count} images\")\n",
    "                    if image_count > 0:\n",
    "                        found_classes.append(class_name)\n",
    "                else:\n",
    "                    print(f\"📁 {class_name}: ❌ (dossier introuvable)\")\n",
    "                    class_counts_manual[class_name] = 0\n",
    "                \n",
    "                pbar.update(1)\n",
    "            \n",
    "            total_images_manual = sum(class_counts_manual.values())\n",
    "            print(f\"\\n✅ Résumé:\")\n",
    "            print(f\"📊 Classes trouvées: {len(found_classes)}/{len(CLASS_NAMES)}\")\n",
    "            print(f\"🖼️ Total images: {total_images_manual}\")\n",
    "            pbar.update(1)\n",
    "            \n",
    "        else:\n",
    "            print(\"❌ Le répertoire de données n'existe pas !\")\n",
    "            pbar.update(len(CLASS_NAMES) + 1)\n",
    "    \n",
    "    # Initialisation du DataLoader\n",
    "    try:\n",
    "        print(\"\\n🔧 Configuration du DataLoader...\")\n",
    "        with tqdm(total=4, desc=\"Configuration\", colour='green') as pbar:\n",
    "            from src.features.raf.utils import get_config, Config\n",
    "            config = get_config()\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Configuration avec chemins absolus\n",
    "            config.data_dir = data_path\n",
    "            config.img_size = IMG_SIZE\n",
    "            config.classes = CLASS_NAMES\n",
    "            config.random_seed = RANDOM_SEED\n",
    "            config.max_images_per_class = int(os.getenv('MAX_IMAGES_PER_CLASS', 100))\n",
    "            pbar.update(1)\n",
    "            \n",
    "            print(f\"🔧 Configuration DataLoader:\")\n",
    "            print(f\"  • Data dir (absolu): {config.data_dir}\")\n",
    "            print(f\"  • Classes: {config.classes}\")\n",
    "            print(f\"  • Max images/classe: {config.max_images_per_class}\")\n",
    "            pbar.update(1)\n",
    "            \n",
    "            # Créer le DataLoader avec chemin absolu\n",
    "            loader = DataLoader(data_dir=data_path, config=config)\n",
    "            pbar.update(1)\n",
    "        \n",
    "        print(f\"✅ DataLoader configuré avec succès\")\n",
    "        \n",
    "        print(f\"\\n📊 Chargement du dataset...\")\n",
    "        \n",
    "        # Charger les chemins et labels avec progression\n",
    "        with tqdm(total=1, desc=\"Scan des fichiers\", colour='orange') as pbar:\n",
    "            try:\n",
    "                print(\"🔍 Lancement du scan...\")\n",
    "                image_paths, labels, class_counts = loader.load_image_paths_and_labels()\n",
    "                pbar.update(1)\n",
    "                print(f\"✅ Scan terminé: {len(image_paths)} images trouvées\")\n",
    "                \n",
    "                if class_counts:\n",
    "                    print(f\"📊 Répartition détaillée par classe:\")\n",
    "                    for class_name, count in class_counts.items():\n",
    "                        print(f\"  • {class_name}: {count} images\")\n",
    "                else:\n",
    "                    print(\"⚠️ Aucun comptage de classes disponible\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Erreur lors du scan: {e}\")\n",
    "                print(f\"🔍 Détails de l'erreur:\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                pbar.update(1)\n",
    "                image_paths, labels, class_counts = [], [], {}\n",
    "        \n",
    "        if len(image_paths) > 0:\n",
    "            # Créer un sous-ensemble équilibré pour la démo\n",
    "            max_per_class = min(20, max(class_counts.values()) if class_counts.values() else 10)\n",
    "            \n",
    "            with tqdm(total=1, desc=\"Création sous-ensemble\", colour='purple') as pbar:\n",
    "                subset_paths, subset_labels = loader.create_balanced_subset(\n",
    "                    image_paths, labels, max_per_class=max_per_class\n",
    "                )\n",
    "                pbar.update(1)\n",
    "            \n",
    "            print(f\"📦 Sous-ensemble créé: {len(subset_paths)} images ({max_per_class} par classe)\")\n",
    "            \n",
    "            # Charger un échantillon d'images pour visualisation\n",
    "            n_samples = min(10, len(subset_paths))\n",
    "            \n",
    "            print(f\"\\n🖼️ Chargement de {n_samples} images échantillons...\")\n",
    "            with tqdm(total=1, desc=\"Chargement images\", colour='cyan') as pbar:\n",
    "                try:\n",
    "                    sample_images, sample_labels_final = loader.load_sample_images(\n",
    "                        subset_paths, subset_labels, n_samples=n_samples\n",
    "                    )\n",
    "                    pbar.update(1)\n",
    "                    print(f\"✅ {len(sample_images)} images chargées avec succès\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Erreur chargement images: {e}\")\n",
    "                    sample_images, sample_labels_final = [], []\n",
    "                    pbar.update(1)\n",
    "            \n",
    "            if len(sample_images) > 0:\n",
    "                # Convertir en format numpy pour les modèles\n",
    "                print(\"\\n⚙️ Conversion des données...\")\n",
    "                with tqdm(total=3, desc=\"Conversion numpy\", colour='yellow') as pbar:\n",
    "                    X_images = np.array(sample_images)\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                    if len(X_images.shape) == 3:\n",
    "                        X_images = np.expand_dims(X_images, axis=-1)\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                    # Convertir les labels en indices\n",
    "                    label_to_idx = {label: idx for idx, label in enumerate(CLASS_NAMES)}\n",
    "                    y_true = np.array([label_to_idx.get(label, 0) for label in sample_labels_final])\n",
    "                    pbar.update(1)\n",
    "                \n",
    "                # Version aplatie pour les modèles ML classiques\n",
    "                with tqdm(total=1, desc=\"Aplatissement ML\", colour='magenta') as pbar:\n",
    "                    X_flat = X_images.reshape(len(X_images), -1)\n",
    "                    pbar.update(1)\n",
    "                \n",
    "                print(f\"\\n📊 Données chargées pour la démo:\")\n",
    "                print(f\"• Images CNN: {X_images.shape}\")\n",
    "                print(f\"• Images ML: {X_flat.shape}\")\n",
    "                print(f\"• Labels: {y_true.shape}\")\n",
    "                print(f\"• Classes uniques: {np.unique(y_true)}\")\n",
    "                print(f\"• Labels échantillons: {sample_labels_final}\")\n",
    "                \n",
    "                # Affichage de quelques échantillons\n",
    "                print(\"\\n🎨 Affichage des échantillons...\")\n",
    "                fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "                \n",
    "                with tqdm(total=min(10, len(X_images)), desc=\"Affichage\", colour='red') as pbar:\n",
    "                    for i in range(min(10, len(X_images))):\n",
    "                        row, col = i // 5, i % 5\n",
    "                        axes[row, col].imshow(X_images[i].squeeze(), cmap='gray')\n",
    "                        axes[row, col].set_title(f'{sample_labels_final[i] if i < len(sample_labels_final) else \"N/A\"}')\n",
    "                        axes[row, col].axis('off')\n",
    "                        pbar.update(1)\n",
    "                \n",
    "                plt.suptitle('Échantillons de Données Réelles COVID-19', fontsize=14)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                REAL_DATA_LOADED = True\n",
    "                \n",
    "                print(f\"\\n🎉 SUCCÈS AVEC CHEMINS ABSOLUS !\")\n",
    "                print(f\"📊 {len(image_paths)} images totales trouvées\")\n",
    "                print(f\"🎯 {len(sample_images)} images échantillons prêtes pour l'interprétabilité\")\n",
    "                print(f\"✨ Prêt pour SHAP, GradCAM et LIME !\")\n",
    "                \n",
    "            else:\n",
    "                print(\"⚠️ Aucune image n'a pu être chargée\")\n",
    "                REAL_DATA_LOADED = False\n",
    "                \n",
    "        else:\n",
    "            print(\"⚠️ Aucune image trouvée dans le dataset\")\n",
    "            REAL_DATA_LOADED = False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur chargement dataset: {e}\")\n",
    "        print(f\"💡 Vérifiez que le dossier {DATA_DIR} existe et contient les données\")\n",
    "        print(f\"🔍 Détails de l'erreur:\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        REAL_DATA_LOADED = False\n",
    "        \n",
    "else:\n",
    "    print(\"❌ DataLoader RAF non disponible\")\n",
    "    print(\"💡 Vérifiez l'installation des dépendances RAF\")\n",
    "    REAL_DATA_LOADED = False\n",
    "\n",
    "print(f\"\\n📋 STATUT FINAL:\")\n",
    "print(f\"🔧 DataLoader disponible: {'✅' if DATALOADER_AVAILABLE else '❌'}\")\n",
    "print(f\"📊 Données réelles chargées: {'✅' if REAL_DATA_LOADED else '❌'}\")\n",
    "print(f\"🎯 Configuration: CHEMINS ABSOLUS (Fini les galères !)\")\n",
    "if REAL_DATA_LOADED:\n",
    "    print(f\"🚀 Prêt pour la suite : Modèles et Interprétabilité ! 🎉\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11836f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 TEST INDÉPENDANT DU DATALOADER RAF\n",
      "==================================================\n",
      "📂 Répertoire de test: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "🏷️ Classes à tester: ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
      "\n",
      "🔍 TEST 1: Vérification directe des dossiers\n",
      "----------------------------------------\n",
      "📍 Chemin absolu: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "📂 Existe: True\n",
      "📁 Tous les éléments (9): ['README.md.txt', 'Viral Pneumonia', 'Viral Pneumonia.metadata.xlsx', 'Normal.metadata.xlsx', 'Lung_Opacity.metadata.xlsx', 'Normal', 'COVID.metadata.xlsx', 'Lung_Opacity', 'COVID']\n",
      "📁 Dossiers seulement (4): ['Viral Pneumonia', 'Normal', 'Lung_Opacity', 'COVID']\n",
      "\n",
      "🧪 Test de chaque classe:\n",
      "  ✅ COVID: 7232 images, 2 sous-dossiers\n",
      "     📁 Sous-dossiers: ['images', 'masks']\n",
      "  ✅ Lung_Opacity: 12024 images, 2 sous-dossiers\n",
      "     📁 Sous-dossiers: ['images', 'masks']\n",
      "  ✅ Normal: 20384 images, 2 sous-dossiers\n",
      "     📁 Sous-dossiers: ['images', 'masks']\n",
      "  ✅ Viral Pneumonia: 2690 images, 2 sous-dossiers\n",
      "     📁 Sous-dossiers: ['images', 'masks']\n",
      "\n",
      "🔍 TEST 2: Test du DataLoader RAF\n",
      "----------------------------------------\n",
      "✅ Imports DataLoader réussis\n",
      "🔧 === CONFIGURATION UNIVERSELLE RAF ===\n",
      "📍 Environnement: 💻 WSL/Linux Local\n",
      "✅ Environnement virtuel .venv détecté\n",
      "✅ Configuration chargée: /home/cepa/DST/projet_DS/DS_COVID/.env\n",
      "🔧 Configuration créée:\n",
      "  • Data dir: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "  • Classes: ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
      "\n",
      "🏗️ Création du DataLoader...\n",
      "📂 DataLoader initialisé: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "✅ DataLoader créé avec succès\n",
      "\n",
      "📊 Test de load_image_paths_and_labels()...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0a1b1883ac46ce8f7f4373eb630e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test chargement:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Chargement des chemins d'images...\n",
      "  COVID: 3616 images\n",
      "  Lung_Opacity: 6012 images\n",
      "  COVID: 3616 images\n",
      "  Lung_Opacity: 6012 images\n",
      "  Normal: 10192 images\n",
      "  Viral Pneumonia: 1345 images\n",
      "📊 Total: 21165 images\n",
      "✅ Méthode exécutée avec succès\n",
      "📊 Résultats:\n",
      "  • Images trouvées: 21165\n",
      "  • Labels: 21165\n",
      "  • Comptage par classe: {'COVID': 3616, 'Lung_Opacity': 6012, 'Normal': 10192, 'Viral Pneumonia': 1345}\n",
      "  • Premier chemin: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset/COVID/images/COVID-3039.png\n",
      "  • Premier label: COVID\n",
      "\n",
      "🖼️ Test de chargement d'images...\n",
      "🖼️ Chargement de 3 images d'exemple...\n",
      "✅ 3 images chargées avec succès\n",
      "✅ Échantillons chargés: 3 images\n",
      "  • Shape première image: (256, 256, 3)\n",
      "\n",
      "🔍 TEST 3: Recherche manuelle d'images\n",
      "----------------------------------------\n",
      "📁 COVID: 7232 images (PNG: 7232, JPG: 0, JPEG: 0)\n",
      "   📄 Premier fichier: COVID-3039.png\n",
      "📁 Lung_Opacity: 12024 images (PNG: 12024, JPG: 0, JPEG: 0)\n",
      "   📄 Premier fichier: Lung_Opacity-4819.png\n",
      "  Normal: 10192 images\n",
      "  Viral Pneumonia: 1345 images\n",
      "📊 Total: 21165 images\n",
      "✅ Méthode exécutée avec succès\n",
      "📊 Résultats:\n",
      "  • Images trouvées: 21165\n",
      "  • Labels: 21165\n",
      "  • Comptage par classe: {'COVID': 3616, 'Lung_Opacity': 6012, 'Normal': 10192, 'Viral Pneumonia': 1345}\n",
      "  • Premier chemin: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset/COVID/images/COVID-3039.png\n",
      "  • Premier label: COVID\n",
      "\n",
      "🖼️ Test de chargement d'images...\n",
      "🖼️ Chargement de 3 images d'exemple...\n",
      "✅ 3 images chargées avec succès\n",
      "✅ Échantillons chargés: 3 images\n",
      "  • Shape première image: (256, 256, 3)\n",
      "\n",
      "🔍 TEST 3: Recherche manuelle d'images\n",
      "----------------------------------------\n",
      "📁 COVID: 7232 images (PNG: 7232, JPG: 0, JPEG: 0)\n",
      "   📄 Premier fichier: COVID-3039.png\n",
      "📁 Lung_Opacity: 12024 images (PNG: 12024, JPG: 0, JPEG: 0)\n",
      "   📄 Premier fichier: Lung_Opacity-4819.png\n",
      "📁 Normal: 20384 images (PNG: 20384, JPG: 0, JPEG: 0)\n",
      "   📄 Premier fichier: Normal-6868.png\n",
      "📁 Viral Pneumonia: 2690 images (PNG: 2690, JPG: 0, JPEG: 0)\n",
      "   📄 Premier fichier: Viral Pneumonia-657.png\n",
      "\n",
      "📊 RÉSUMÉ DU TEST MANUEL:\n",
      "• Total images trouvées: 42330\n",
      "• Répartition: {'COVID': 7232, 'Lung_Opacity': 12024, 'Normal': 20384, 'Viral Pneumonia': 2690}\n",
      "\n",
      "🎯 CONCLUSION DU TEST\n",
      "==============================\n",
      "✅ Les images existent dans la structure de dossiers\n",
      "🔧 Le problème semble venir du DataLoader RAF\n",
      "💡 Suggestions:\n",
      "  1. Vérifier la méthode load_image_paths_and_labels() du DataLoader\n",
      "  2. Vérifier les patterns de recherche d'images\n",
      "  3. Vérifier les chemins relatifs vs absolus\n",
      "\n",
      "🏁 Test terminé - Vous pouvez maintenant identifier le problème !\n",
      "📁 Normal: 20384 images (PNG: 20384, JPG: 0, JPEG: 0)\n",
      "   📄 Premier fichier: Normal-6868.png\n",
      "📁 Viral Pneumonia: 2690 images (PNG: 2690, JPG: 0, JPEG: 0)\n",
      "   📄 Premier fichier: Viral Pneumonia-657.png\n",
      "\n",
      "📊 RÉSUMÉ DU TEST MANUEL:\n",
      "• Total images trouvées: 42330\n",
      "• Répartition: {'COVID': 7232, 'Lung_Opacity': 12024, 'Normal': 20384, 'Viral Pneumonia': 2690}\n",
      "\n",
      "🎯 CONCLUSION DU TEST\n",
      "==============================\n",
      "✅ Les images existent dans la structure de dossiers\n",
      "🔧 Le problème semble venir du DataLoader RAF\n",
      "💡 Suggestions:\n",
      "  1. Vérifier la méthode load_image_paths_and_labels() du DataLoader\n",
      "  2. Vérifier les patterns de recherche d'images\n",
      "  3. Vérifier les chemins relatifs vs absolus\n",
      "\n",
      "🏁 Test terminé - Vous pouvez maintenant identifier le problème !\n"
     ]
    }
   ],
   "source": [
    "# 🧪 Test indépendant du DataLoader RAF\n",
    "print(\"🧪 TEST INDÉPENDANT DU DATALOADER RAF\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Configuration du test\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Configuration de base\n",
    "DATA_DIR = os.getenv('DATA_DIR', './data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset')\n",
    "CLASS_NAMES = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
    "\n",
    "print(f\"📂 Répertoire de test: {DATA_DIR}\")\n",
    "print(f\"🏷️ Classes à tester: {CLASS_NAMES}\")\n",
    "\n",
    "# Test 1: Vérification directe des dossiers\n",
    "print(f\"\\n🔍 TEST 1: Vérification directe des dossiers\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "data_path = Path(DATA_DIR)\n",
    "print(f\"📍 Chemin absolu: {data_path.resolve()}\")\n",
    "print(f\"📂 Existe: {data_path.exists()}\")\n",
    "\n",
    "if data_path.exists():\n",
    "    all_items = list(data_path.iterdir())\n",
    "    dirs_only = [p for p in all_items if p.is_dir()]\n",
    "    \n",
    "    print(f\"📁 Tous les éléments ({len(all_items)}): {[p.name for p in all_items]}\")\n",
    "    print(f\"📁 Dossiers seulement ({len(dirs_only)}): {[p.name for p in dirs_only]}\")\n",
    "    \n",
    "    # Test de chaque classe\n",
    "    print(f\"\\n🧪 Test de chaque classe:\")\n",
    "    for class_name in CLASS_NAMES:\n",
    "        class_path = data_path / class_name\n",
    "        exists = class_path.exists()\n",
    "        is_dir = class_path.is_dir() if exists else False\n",
    "        \n",
    "        if exists and is_dir:\n",
    "            # Compter les images\n",
    "            images = list(class_path.glob('**/*.png')) + list(class_path.glob('**/*.jpg'))\n",
    "            subfolders = [p for p in class_path.iterdir() if p.is_dir()]\n",
    "            \n",
    "            print(f\"  ✅ {class_name}: {len(images)} images, {len(subfolders)} sous-dossiers\")\n",
    "            if subfolders:\n",
    "                print(f\"     📁 Sous-dossiers: {[p.name for p in subfolders]}\")\n",
    "        else:\n",
    "            print(f\"  ❌ {class_name}: {'fichier' if exists else 'inexistant'}\")\n",
    "\n",
    "# Test 2: Test du DataLoader si disponible\n",
    "print(f\"\\n🔍 TEST 2: Test du DataLoader RAF\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if DATALOADER_AVAILABLE:\n",
    "    try:\n",
    "        # Import et configuration\n",
    "        from src.features.raf.data import DataLoader\n",
    "        from src.features.raf.utils import get_config\n",
    "        \n",
    "        print(\"✅ Imports DataLoader réussis\")\n",
    "        \n",
    "        # Configuration minimale\n",
    "        config = get_config()\n",
    "        config.data_dir = data_path\n",
    "        config.classes = CLASS_NAMES\n",
    "        config.max_images_per_class = 10  # Limité pour le test\n",
    "        \n",
    "        print(f\"🔧 Configuration créée:\")\n",
    "        print(f\"  • Data dir: {config.data_dir}\")\n",
    "        print(f\"  • Classes: {config.classes}\")\n",
    "        \n",
    "        # Initialisation du DataLoader\n",
    "        print(f\"\\n🏗️ Création du DataLoader...\")\n",
    "        loader = DataLoader(data_dir=data_path, config=config)\n",
    "        print(\"✅ DataLoader créé avec succès\")\n",
    "        \n",
    "        # Test de la méthode load_image_paths_and_labels\n",
    "        print(f\"\\n📊 Test de load_image_paths_and_labels()...\")\n",
    "        with tqdm(total=1, desc=\"Test chargement\", colour='green') as pbar:\n",
    "            try:\n",
    "                image_paths, labels, class_counts = loader.load_image_paths_and_labels()\n",
    "                pbar.update(1)\n",
    "                \n",
    "                print(f\"✅ Méthode exécutée avec succès\")\n",
    "                print(f\"📊 Résultats:\")\n",
    "                print(f\"  • Images trouvées: {len(image_paths)}\")\n",
    "                print(f\"  • Labels: {len(labels)}\")\n",
    "                print(f\"  • Comptage par classe: {dict(class_counts) if class_counts else 'Vide'}\")\n",
    "                \n",
    "                if len(image_paths) > 0:\n",
    "                    print(f\"  • Premier chemin: {image_paths[0]}\")\n",
    "                    print(f\"  • Premier label: {labels[0]}\")\n",
    "                    \n",
    "                    # Test de quelques échantillons\n",
    "                    print(f\"\\n🖼️ Test de chargement d'images...\")\n",
    "                    try:\n",
    "                        sample_images, sample_labels = loader.load_sample_images(\n",
    "                            image_paths[:3], labels[:3], n_samples=3\n",
    "                        )\n",
    "                        print(f\"✅ Échantillons chargés: {len(sample_images)} images\")\n",
    "                        if len(sample_images) > 0:\n",
    "                            print(f\"  • Shape première image: {sample_images[0].shape}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Erreur chargement échantillons: {e}\")\n",
    "                        \n",
    "                else:\n",
    "                    print(f\"⚠️ Aucune image trouvée par le DataLoader\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Erreur dans load_image_paths_and_labels: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                pbar.update(1)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur lors du test DataLoader: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"❌ DataLoader non disponible pour le test\")\n",
    "\n",
    "# Test 3: Test manuel de recherche d'images\n",
    "print(f\"\\n🔍 TEST 3: Recherche manuelle d'images\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "manual_count = {}\n",
    "total_manual = 0\n",
    "\n",
    "for class_name in CLASS_NAMES:\n",
    "    class_path = data_path / class_name\n",
    "    if class_path.exists():\n",
    "        # Recherche récursive d'images\n",
    "        png_files = list(class_path.glob('**/*.png'))\n",
    "        jpg_files = list(class_path.glob('**/*.jpg'))\n",
    "        jpeg_files = list(class_path.glob('**/*.jpeg'))\n",
    "        \n",
    "        total_files = len(png_files) + len(jpg_files) + len(jpeg_files)\n",
    "        manual_count[class_name] = total_files\n",
    "        total_manual += total_files\n",
    "        \n",
    "        print(f\"📁 {class_name}: {total_files} images (PNG: {len(png_files)}, JPG: {len(jpg_files)}, JPEG: {len(jpeg_files)})\")\n",
    "        \n",
    "        if total_files > 0:\n",
    "            first_file = (png_files + jpg_files + jpeg_files)[0]\n",
    "            print(f\"   📄 Premier fichier: {first_file.name}\")\n",
    "    else:\n",
    "        manual_count[class_name] = 0\n",
    "        print(f\"📁 {class_name}: dossier inexistant\")\n",
    "\n",
    "print(f\"\\n📊 RÉSUMÉ DU TEST MANUEL:\")\n",
    "print(f\"• Total images trouvées: {total_manual}\")\n",
    "print(f\"• Répartition: {manual_count}\")\n",
    "\n",
    "# Conclusion du test\n",
    "print(f\"\\n🎯 CONCLUSION DU TEST\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if total_manual > 0:\n",
    "    print(\"✅ Les images existent dans la structure de dossiers\")\n",
    "    if DATALOADER_AVAILABLE:\n",
    "        print(\"🔧 Le problème semble venir du DataLoader RAF\")\n",
    "        print(\"💡 Suggestions:\")\n",
    "        print(\"  1. Vérifier la méthode load_image_paths_and_labels() du DataLoader\")\n",
    "        print(\"  2. Vérifier les patterns de recherche d'images\")\n",
    "        print(\"  3. Vérifier les chemins relatifs vs absolus\")\n",
    "    else:\n",
    "        print(\"⚠️ DataLoader RAF non disponible\")\n",
    "else:\n",
    "    print(\"❌ Aucune image trouvée manuellement\")\n",
    "    print(\"💡 Vérifiez la structure des dossiers et les chemins\")\n",
    "\n",
    "print(f\"\\n🏁 Test terminé - Vous pouvez maintenant identifier le problème !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8430da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 CORRECTION AUTOMATIQUE DES CHEMINS\n",
      "==================================================\n",
      "📍 Répertoire de travail actuel: /home/cepa/DST/projet_DS/DS_COVID/notebooks\n",
      "\n",
      "🔍 Test des chemins possibles...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0eb43c772e1479ba80c002b96a1e679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test chemins:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📂 Test 1: ../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "   📍 Absolu: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "   📂 Existe: True\n",
      "   ✅ COVID: True\n",
      "   ✅ Lung_Opacity: True\n",
      "   ✅ Normal: True\n",
      "   ✅ Viral Pneumonia: True\n",
      "   🎯 CHEMIN CORRECT TROUVÉ !\n",
      "\n",
      "✅ CHEMIN CORRIGÉ TROUVÉ !\n",
      "📂 Chemin correct: ../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "📍 Chemin absolu: /home/cepa/DST/projet_DS/DS_COVID/data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "\n",
      "🔄 Mise à jour de la configuration...\n",
      "\n",
      "🧪 TEST AVEC LE CHEMIN CORRIGÉ\n",
      "----------------------------------------\n",
      "📁 COVID: 7232 images\n",
      "📁 Lung_Opacity: 12024 images\n",
      "📁 Normal: 20384 images\n",
      "📁 Viral Pneumonia: 2690 images\n",
      "\n",
      "📊 RÉSUMÉ AVEC CHEMIN CORRIGÉ:\n",
      "• Total images: 42330\n",
      "• Répartition: {'COVID': 7232, 'Lung_Opacity': 12024, 'Normal': 20384, 'Viral Pneumonia': 2690}\n",
      "\n",
      "🎉 PROBLÈME RÉSOLU !\n",
      "💡 Le problème était un chemin relatif incorrect\n",
      "🔧 Solution: Utiliser le chemin '../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset'\n",
      "📝 Variable DATA_DIR_CORRECTED créée: ../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "\n",
      "🧪 TEST RAPIDE DU DATALOADER CORRIGÉ\n",
      "----------------------------------------\n",
      "📂 DataLoader initialisé: ../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "📁 COVID: 7232 images\n",
      "📁 Lung_Opacity: 12024 images\n",
      "📁 Normal: 20384 images\n",
      "📁 Viral Pneumonia: 2690 images\n",
      "\n",
      "📊 RÉSUMÉ AVEC CHEMIN CORRIGÉ:\n",
      "• Total images: 42330\n",
      "• Répartition: {'COVID': 7232, 'Lung_Opacity': 12024, 'Normal': 20384, 'Viral Pneumonia': 2690}\n",
      "\n",
      "🎉 PROBLÈME RÉSOLU !\n",
      "💡 Le problème était un chemin relatif incorrect\n",
      "🔧 Solution: Utiliser le chemin '../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset'\n",
      "📝 Variable DATA_DIR_CORRECTED créée: ../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n",
      "\n",
      "🧪 TEST RAPIDE DU DATALOADER CORRIGÉ\n",
      "----------------------------------------\n",
      "📂 DataLoader initialisé: ../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c778c7605ce495eaee4eada071718bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Test DataLoader corrigé:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Chargement des chemins d'images...\n",
      "  COVID: 3616 images\n",
      "  Lung_Opacity: 6012 images\n",
      "  Normal: 10192 images\n",
      "  Viral Pneumonia: 1345 images\n",
      "📊 Total: 21165 images\n",
      "✅ DataLoader avec chemin corrigé: 21165 images trouvées\n",
      "📊 Comptage par classe: {'COVID': 3616, 'Lung_Opacity': 6012, 'Normal': 10192, 'Viral Pneumonia': 1345}\n",
      "🎯 DATALOADER FONCTIONNEL !\n",
      "\n",
      "🏁 Diagnostic terminé !\n",
      "  Normal: 10192 images\n",
      "  Viral Pneumonia: 1345 images\n",
      "📊 Total: 21165 images\n",
      "✅ DataLoader avec chemin corrigé: 21165 images trouvées\n",
      "📊 Comptage par classe: {'COVID': 3616, 'Lung_Opacity': 6012, 'Normal': 10192, 'Viral Pneumonia': 1345}\n",
      "🎯 DATALOADER FONCTIONNEL !\n",
      "\n",
      "🏁 Diagnostic terminé !\n"
     ]
    }
   ],
   "source": [
    "# 🔧 CORRECTION AUTOMATIQUE DES CHEMINS\n",
    "print(\"🔧 CORRECTION AUTOMATIQUE DES CHEMINS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Détection du problème de chemin\n",
    "current_working_dir = Path.cwd()\n",
    "print(f\"📍 Répertoire de travail actuel: {current_working_dir}\")\n",
    "\n",
    "# Configuration des chemins possibles\n",
    "possible_paths = [\n",
    "    # Chemin depuis notebooks/ (actuel)\n",
    "    Path('../data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset'),\n",
    "    # Chemin depuis racine du projet\n",
    "    Path('./data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset'),\n",
    "    # Chemin avec un seul niveau\n",
    "    Path('../data/raw/COVID-19_Radiography_Dataset'),\n",
    "    # Chemin absolu basé sur project_root\n",
    "    current_working_dir.parent / 'data' / 'raw' / 'COVID-19_Radiography_Dataset' / 'COVID-19_Radiography_Dataset'\n",
    "]\n",
    "\n",
    "CLASS_NAMES = ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
    "\n",
    "print(f\"\\n🔍 Test des chemins possibles...\")\n",
    "correct_path = None\n",
    "\n",
    "with tqdm(total=len(possible_paths), desc=\"Test chemins\", colour='blue') as pbar:\n",
    "    for i, test_path in enumerate(possible_paths):\n",
    "        print(f\"\\n📂 Test {i+1}: {test_path}\")\n",
    "        print(f\"   📍 Absolu: {test_path.resolve()}\")\n",
    "        print(f\"   📂 Existe: {test_path.exists()}\")\n",
    "        \n",
    "        if test_path.exists():\n",
    "            # Vérifier la présence des dossiers de classes\n",
    "            class_found = 0\n",
    "            for class_name in CLASS_NAMES:\n",
    "                class_path = test_path / class_name\n",
    "                if class_path.exists():\n",
    "                    class_found += 1\n",
    "                    print(f\"   ✅ {class_name}: {class_path.exists()}\")\n",
    "                else:\n",
    "                    print(f\"   ❌ {class_name}: {class_path.exists()}\")\n",
    "            \n",
    "            if class_found == len(CLASS_NAMES):\n",
    "                print(f\"   🎯 CHEMIN CORRECT TROUVÉ !\")\n",
    "                correct_path = test_path\n",
    "                break\n",
    "            else:\n",
    "                print(f\"   ⚠️ Seulement {class_found}/{len(CLASS_NAMES)} classes trouvées\")\n",
    "        \n",
    "        pbar.update(1)\n",
    "\n",
    "# Résultat de la correction\n",
    "if correct_path:\n",
    "    print(f\"\\n✅ CHEMIN CORRIGÉ TROUVÉ !\")\n",
    "    print(f\"📂 Chemin correct: {correct_path}\")\n",
    "    print(f\"📍 Chemin absolu: {correct_path.resolve()}\")\n",
    "    \n",
    "    # Mise à jour des variables d'environnement\n",
    "    corrected_data_dir = str(correct_path)\n",
    "    print(f\"\\n🔄 Mise à jour de la configuration...\")\n",
    "    \n",
    "    # Test avec le bon chemin\n",
    "    print(f\"\\n🧪 TEST AVEC LE CHEMIN CORRIGÉ\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Compter les images par classe\n",
    "    total_images = 0\n",
    "    class_distribution = {}\n",
    "    \n",
    "    for class_name in CLASS_NAMES:\n",
    "        class_path = correct_path / class_name\n",
    "        if class_path.exists():\n",
    "            images = list(class_path.glob('**/*.png')) + list(class_path.glob('**/*.jpg'))\n",
    "            class_distribution[class_name] = len(images)\n",
    "            total_images += len(images)\n",
    "            print(f\"📁 {class_name}: {len(images)} images\")\n",
    "        else:\n",
    "            class_distribution[class_name] = 0\n",
    "            print(f\"📁 {class_name}: 0 images (dossier inexistant)\")\n",
    "    \n",
    "    print(f\"\\n📊 RÉSUMÉ AVEC CHEMIN CORRIGÉ:\")\n",
    "    print(f\"• Total images: {total_images}\")\n",
    "    print(f\"• Répartition: {class_distribution}\")\n",
    "    \n",
    "    if total_images > 0:\n",
    "        print(f\"\\n🎉 PROBLÈME RÉSOLU !\")\n",
    "        print(f\"💡 Le problème était un chemin relatif incorrect\")\n",
    "        print(f\"🔧 Solution: Utiliser le chemin '{corrected_data_dir}'\")\n",
    "        \n",
    "        # Mettre à jour la variable globale pour la suite\n",
    "        DATA_DIR_CORRECTED = corrected_data_dir\n",
    "        print(f\"📝 Variable DATA_DIR_CORRECTED créée: {DATA_DIR_CORRECTED}\")\n",
    "        \n",
    "        # Test rapide du DataLoader avec le bon chemin\n",
    "        if DATALOADER_AVAILABLE:\n",
    "            print(f\"\\n🧪 TEST RAPIDE DU DATALOADER CORRIGÉ\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            try:\n",
    "                from src.features.raf.data import DataLoader\n",
    "                from src.features.raf.utils import get_config\n",
    "                \n",
    "                # Configuration avec le bon chemin\n",
    "                config = get_config()\n",
    "                config.data_dir = correct_path\n",
    "                config.classes = CLASS_NAMES\n",
    "                config.max_images_per_class = 5  # Test rapide\n",
    "                \n",
    "                loader_corrected = DataLoader(data_dir=correct_path, config=config)\n",
    "                \n",
    "                with tqdm(total=1, desc=\"Test DataLoader corrigé\", colour='green') as pbar:\n",
    "                    image_paths, labels, class_counts = loader_corrected.load_image_paths_and_labels()\n",
    "                    pbar.update(1)\n",
    "                \n",
    "                print(f\"✅ DataLoader avec chemin corrigé: {len(image_paths)} images trouvées\")\n",
    "                print(f\"📊 Comptage par classe: {dict(class_counts)}\")\n",
    "                \n",
    "                if len(image_paths) > 0:\n",
    "                    print(f\"🎯 DATALOADER FONCTIONNEL !\")\n",
    "                else:\n",
    "                    print(f\"⚠️ DataLoader toujours ne trouve pas d'images\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Erreur test DataLoader corrigé: {e}\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n❌ AUCUN CHEMIN CORRECT TROUVÉ\")\n",
    "    print(f\"💡 Suggestions:\")\n",
    "    print(f\"  1. Vérifiez que le dataset COVID-19 est bien téléchargé\")\n",
    "    print(f\"  2. Vérifiez la structure des dossiers:\")\n",
    "    print(f\"     data/raw/COVID-19_Radiography_Dataset/COVID-19_Radiography_Dataset/\")\n",
    "    print(f\"       ├── COVID/\")\n",
    "    print(f\"       ├── Lung_Opacity/\")\n",
    "    print(f\"       ├── Normal/\")\n",
    "    print(f\"       └── Viral Pneumonia/\")\n",
    "    print(f\"  3. Relancez depuis le répertoire racine du projet\")\n",
    "\n",
    "print(f\"\\n🏁 Diagnostic terminé !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03b1022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de modèles simulés pour la démonstration\n",
    "# En pratique, vous chargerez vos modèles pré-entraînés\n",
    "\n",
    "print(\"🏗️ Création des modèles de démonstration...\")\n",
    "\n",
    "# Configuration depuis .env\n",
    "EPOCHS = int(os.getenv('EPOCHS', 2))  # Epochs rapides pour démo\n",
    "BATCH_SIZE = int(os.getenv('BATCH_SIZE', 32))\n",
    "LEARNING_RATE = float(os.getenv('LEARNING_RATE', 0.001))\n",
    "\n",
    "# Configuration Random Forest depuis .env\n",
    "RF_N_ESTIMATORS = int(os.getenv('RF_N_ESTIMATORS', 50))\n",
    "RF_MAX_DEPTH = int(os.getenv('RF_MAX_DEPTH', 10))\n",
    "\n",
    "# Modèle CNN simulé (TensorFlow/Keras)\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow import keras\n",
    "    \n",
    "    # CNN simple pour démonstration\n",
    "    cnn_model = keras.Sequential([\n",
    "        keras.layers.Conv2D(32, 3, activation='relu', input_shape=(*IMG_SIZE, 1)),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "        keras.layers.MaxPooling2D(),\n",
    "        keras.layers.Conv2D(128, 3, activation='relu'),\n",
    "        keras.layers.GlobalAveragePooling2D(),\n",
    "        keras.layers.Dense(128, activation='relu'),\n",
    "        keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    cnn_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Modèle CNN créé\")\n",
    "    print(f\"📊 Architecture: {len(cnn_model.layers)} couches\")\n",
    "    print(f\"🎯 Learning rate: {LEARNING_RATE}\")\n",
    "    \n",
    "    # Entraînement rapide pour avoir des poids\n",
    "    print(f\"🏋️ Entraînement rapide ({EPOCHS} époques)...\")\n",
    "    cnn_model.fit(X_images, y_true, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "    print(\"✅ Modèle CNN entraîné\")\n",
    "    \n",
    "    CNN_AVAILABLE = True\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"❌ TensorFlow non disponible - pas de modèle CNN\")\n",
    "    cnn_model = None\n",
    "    CNN_AVAILABLE = False\n",
    "\n",
    "# Modèle ML classique (Random Forest)\n",
    "try:\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # Création et entraînement du Random Forest avec config .env\n",
    "    ml_model = RandomForestClassifier(\n",
    "        n_estimators=RF_N_ESTIMATORS,\n",
    "        max_depth=RF_MAX_DEPTH,\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    # Entraînement\n",
    "    ml_model.fit(X_flat, y_true)\n",
    "    \n",
    "    print(\"✅ Modèle Random Forest créé et entraîné\")\n",
    "    print(f\"📊 Nombre d'arbres: {ml_model.n_estimators}\")\n",
    "    print(f\"🌳 Profondeur max: {ml_model.max_depth}\")\n",
    "    \n",
    "    ML_AVAILABLE = True\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"❌ Scikit-learn non disponible - pas de modèle ML\")\n",
    "    ml_model = None\n",
    "    ML_AVAILABLE = False\n",
    "\n",
    "print(f\"\\n📊 Résumé des modèles:\")\n",
    "print(f\"• CNN disponible: {CNN_AVAILABLE}\")\n",
    "print(f\"• ML disponible: {ML_AVAILABLE}\")\n",
    "print(f\"• Configuration depuis .env: ✅\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a42d7c9",
   "metadata": {},
   "source": [
    "## 🎯 Démonstration GradCAM\n",
    "\n",
    "GradCAM (Gradient-weighted Class Activation Mapping) permet de visualiser les régions importantes pour la prédiction d'un CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18715b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CNN_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"🎯 Démonstration GradCAM\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Initialisation de l'explainer GradCAM\n",
    "    try:\n",
    "        gradcam_explainer = GradCAMExplainer(cnn_model)\n",
    "        print(f\"✅ GradCAM explainer initialisé\")\n",
    "        print(f\"🔍 Couche analysée: {gradcam_explainer.layer_name}\")\n",
    "        \n",
    "        # Sélection d'une image pour l'analyse\n",
    "        test_image = X_images[0]  # Première image\n",
    "        true_class = y_true[0]\n",
    "        \n",
    "        print(f\"\\n🖼️ Analyse de l'image test\")\n",
    "        print(f\"• Classe réelle: {CLASS_NAMES[true_class]}\")\n",
    "        print(f\"• Shape: {test_image.shape}\")\n",
    "        \n",
    "        # Génération de la carte GradCAM avec paramètres .env\n",
    "        print(f\"\\n🔍 Génération GradCAM (alpha={GRADCAM_ALPHA}, colormap={GRADCAM_COLORMAP})...\")\n",
    "        gradcam_results = gradcam_explainer.generate_gradcam(\n",
    "            test_image, \n",
    "            alpha=GRADCAM_ALPHA, \n",
    "            colormap=GRADCAM_COLORMAP\n",
    "        )\n",
    "        \n",
    "        predicted_class = gradcam_results['predicted_class']\n",
    "        confidence = gradcam_results['prediction_confidence']\n",
    "        \n",
    "        print(f\"✅ GradCAM généré !\")\n",
    "        print(f\"• Classe prédite: {CLASS_NAMES[predicted_class]}\")\n",
    "        print(f\"• Confiance: {confidence:.2%}\")\n",
    "        \n",
    "        # Seuils de confiance depuis .env\n",
    "        confidence_high = float(os.getenv('CONFIDENCE_HIGH_THRESHOLD', 0.8))\n",
    "        confidence_medium = float(os.getenv('CONFIDENCE_MEDIUM_THRESHOLD', 0.6))\n",
    "        \n",
    "        if confidence > confidence_high:\n",
    "            print(\"🔥 Confiance élevée\")\n",
    "        elif confidence > confidence_medium:\n",
    "            print(\"⚡ Confiance moyenne\")\n",
    "        else:\n",
    "            print(\"⚠️ Confiance faible\")\n",
    "        \n",
    "        # Visualisation des résultats\n",
    "        fig = gradcam_explainer.plot_gradcam(\n",
    "            gradcam_results,\n",
    "            title=f\"Analyse GradCAM - {CLASS_NAMES[predicted_class]}\",\n",
    "            class_names=CLASS_NAMES\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        # Analyse quantitative\n",
    "        from src.features.raf.interpretability.gradcam_explainer import (\n",
    "            extract_gradcam_features,\n",
    "            analyze_gradcam_regions\n",
    "        )\n",
    "        \n",
    "        features = extract_gradcam_features(gradcam_results['heatmap'])\n",
    "        regions = analyze_gradcam_regions(gradcam_results['heatmap'])\n",
    "        \n",
    "        print(f\"\\n📊 Analyse quantitative:\")\n",
    "        print(f\"• Activation moyenne: {features['mean_activation']:.3f}\")\n",
    "        print(f\"• Activation maximale: {features['max_activation']:.3f}\")\n",
    "        print(f\"• Entropie: {features['entropy']:.3f}\")\n",
    "        print(f\"• Concentration >75%: {features['concentration_75']:.1%}\")\n",
    "        print(f\"• Région importante: {regions['importance_ratio']:.1%}\")\n",
    "        print(f\"• Configuration depuis .env: ✅\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur GradCAM: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ GradCAM non disponible (CNN ou RAF manquant)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c1d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CNN_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"🔄 Comparaison GradCAM vs GradCAM++\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Génération des deux méthodes\n",
    "        test_image = X_images[1]  # Deuxième image\n",
    "        \n",
    "        gradcam_result = gradcam_explainer.generate_gradcam(test_image)\n",
    "        gradcam_plus_result = gradcam_explainer.generate_gradcam_plus_plus(test_image)\n",
    "        \n",
    "        # Comparaison visuelle\n",
    "        from src.features.raf.interpretability.gradcam_explainer import visualize_gradcam_comparison\n",
    "        \n",
    "        comparison_results = {\n",
    "            'GradCAM': gradcam_result,\n",
    "            'GradCAM++': gradcam_plus_result\n",
    "        }\n",
    "        \n",
    "        fig = visualize_gradcam_comparison(\n",
    "            comparison_results,\n",
    "            title=\"Comparaison GradCAM vs GradCAM++\",\n",
    "            class_names=CLASS_NAMES\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        # Comparaison quantitative\n",
    "        features_gradcam = extract_gradcam_features(gradcam_result['heatmap'])\n",
    "        features_gradcam_plus = extract_gradcam_features(gradcam_plus_result['heatmap'])\n",
    "        \n",
    "        comparison_df = pd.DataFrame({\n",
    "            'Métrique': ['Activation moyenne', 'Activation max', 'Entropie', 'Concentration 75%'],\n",
    "            'GradCAM': [\n",
    "                features_gradcam['mean_activation'],\n",
    "                features_gradcam['max_activation'],\n",
    "                features_gradcam['entropy'],\n",
    "                features_gradcam['concentration_75']\n",
    "            ],\n",
    "            'GradCAM++': [\n",
    "                features_gradcam_plus['mean_activation'],\n",
    "                features_gradcam_plus['max_activation'],\n",
    "                features_gradcam_plus['entropy'],\n",
    "                features_gradcam_plus['concentration_75']\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        print(\"\\n📊 Comparaison quantitative:\")\n",
    "        print(comparison_df.to_string(index=False, float_format='%.3f'))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur comparaison: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ Comparaison GradCAM non disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d3d56a",
   "metadata": {},
   "source": [
    "## 📊 Démonstration SHAP\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) permet d'expliquer les prédictions de tout type de modèle en quantifiant l'importance de chaque feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b997e9",
   "metadata": {},
   "source": [
    "## 🍃 Démonstration LIME\n",
    "\n",
    "LIME (Local Interpretable Model-agnostic Explanations) explique les prédictions en approximant localement le modèle avec un modèle interprétable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ed6d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CNN_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"🍃 Démonstration LIME\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Vérifier que LIME est disponible\n",
    "        try:\n",
    "            import lime\n",
    "            print(\"✅ LIME disponible\")\n",
    "            LIME_AVAILABLE = True\n",
    "        except ImportError:\n",
    "            print(\"❌ LIME non disponible - installation nécessaire\")\n",
    "            print(\"!pip install lime\")\n",
    "            LIME_AVAILABLE = False\n",
    "        \n",
    "        if LIME_AVAILABLE:\n",
    "            # Initialisation de l'explainer LIME\n",
    "            def preprocess_for_lime(images):\n",
    "                \"\"\"Fonction de préprocessing pour LIME\"\"\"\n",
    "                if len(images.shape) == 3:\n",
    "                    images = np.expand_dims(images, axis=0)\n",
    "                # Normalisation pour le modèle CNN\n",
    "                return images.astype(np.float32) / 255.0\n",
    "            \n",
    "            lime_explainer = LIMEExplainer(cnn_model, preprocess_fn=preprocess_for_lime)\n",
    "            print(f\"✅ LIME explainer initialisé\")\n",
    "            \n",
    "            # Sélection d'une image pour l'analyse LIME\n",
    "            test_image = X_images[0]  # Première image\n",
    "            true_class = y_true[0]\n",
    "            \n",
    "            print(f\"\\n🖼️ Analyse LIME de l'image test\")\n",
    "            print(f\"• Classe réelle: {CLASS_NAMES[true_class]}\")\n",
    "            print(f\"• Shape: {test_image.shape}\")\n",
    "            print(f\"• Échantillons LIME: {LIME_NUM_SAMPLES}\")\n",
    "            \n",
    "            # Génération de l'explication LIME\n",
    "            print(f\"\\n🔍 Génération de l'explication LIME...\")\n",
    "            lime_results = lime_explainer.explain_image(\n",
    "                test_image.squeeze(),  # LIME attend (H, W, C)\n",
    "                top_labels=NUM_CLASSES,\n",
    "                num_samples=LIME_NUM_SAMPLES,\n",
    "                num_features=100\n",
    "            )\n",
    "            \n",
    "            predicted_class = lime_results['predicted_class']\n",
    "            confidence = lime_results['prediction_confidence']\n",
    "            \n",
    "            print(f\"✅ Explication LIME générée !\")\n",
    "            print(f\"• Classe prédite: {CLASS_NAMES[predicted_class]}\")\n",
    "            print(f\"• Confiance: {confidence:.2%}\")\n",
    "            \n",
    "            # Visualisation des résultats LIME\n",
    "            fig = lime_explainer.plot_lime_explanation(\n",
    "                lime_results,\n",
    "                title=f\"Analyse LIME - {CLASS_NAMES[predicted_class]}\",\n",
    "                class_names=CLASS_NAMES,\n",
    "                num_features=10\n",
    "            )\n",
    "            plt.show()\n",
    "            \n",
    "            # Analyse quantitative LIME\n",
    "            analysis = lime_explainer.analyze_lime_features(lime_results)\n",
    "            \n",
    "            print(f\"\\n📊 Analyse quantitative LIME:\")\n",
    "            print(f\"• Nombre total de superpixels: {analysis['num_features']}\")\n",
    "            print(f\"• Features positives: {analysis['positive_features']}\")\n",
    "            print(f\"• Features négatives: {analysis['negative_features']}\")\n",
    "            print(f\"• Ratio positif: {analysis['positive_ratio']:.1%}\")\n",
    "            print(f\"• Poids total: {analysis['total_weight']:.3f}\")\n",
    "            \n",
    "            # Top features\n",
    "            print(f\"\\n🏆 Top 5 Features Positives:\")\n",
    "            for i, (feature_id, weight) in enumerate(analysis['top_positive_features'][:5]):\n",
    "                print(f\"  {i+1}. Superpixel {feature_id}: {weight:.3f}\")\n",
    "            \n",
    "            if analysis['top_negative_features']:\n",
    "                print(f\"\\n⚠️ Top 5 Features Négatives:\")\n",
    "                for i, (feature_id, weight) in enumerate(analysis['top_negative_features'][:5]):\n",
    "                    print(f\"  {i+1}. Superpixel {feature_id}: {weight:.3f}\")\n",
    "        \n",
    "        else:\n",
    "            print(\"⚠️ LIME non disponible pour cette démonstration\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur LIME: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ LIME non disponible (CNN ou RAF manquant)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb89d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CNN_AVAILABLE and RAF_AVAILABLE and 'lime_explainer' in locals():\n",
    "    print(\"🔄 Comparaison LIME avec Multiple Images\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Sélection de plusieurs images pour comparaison\n",
    "        n_compare = min(3, len(X_images))\n",
    "        compare_images = [X_images[i].squeeze() for i in range(n_compare)]\n",
    "        compare_labels = [f\"{CLASS_NAMES[y_true[i]]} (réel)\" for i in range(n_compare)]\n",
    "        \n",
    "        print(f\"🔍 Comparaison LIME sur {n_compare} images...\")\n",
    "        \n",
    "        # Comparaison LIME\n",
    "        comparison_results = lime_explainer.compare_lime_explanations(\n",
    "            compare_images,\n",
    "            labels=compare_labels,\n",
    "            num_samples=500  # Moins d'échantillons pour accélérer\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Comparaison LIME terminée !\")\n",
    "        \n",
    "        # Visualisation de la comparaison\n",
    "        fig = visualize_lime_comparison(comparison_results, class_names=CLASS_NAMES)\n",
    "        if fig is not None:\n",
    "            plt.show()\n",
    "        \n",
    "        # Analyse comparative des résultats\n",
    "        analyses = comparison_results['analyses']\n",
    "        valid_analyses = [a for a in analyses if a is not None]\n",
    "        \n",
    "        if valid_analyses:\n",
    "            print(f\"\\n📊 Analyse Comparative LIME:\")\n",
    "            \n",
    "            # Statistiques moyennes\n",
    "            avg_positive = np.mean([a['positive_features'] for a in valid_analyses])\n",
    "            avg_negative = np.mean([a['negative_features'] for a in valid_analyses])\n",
    "            avg_ratio = np.mean([a['positive_ratio'] for a in valid_analyses])\n",
    "            \n",
    "            print(f\"• Features positives (moyenne): {avg_positive:.1f}\")\n",
    "            print(f\"• Features négatives (moyenne): {avg_negative:.1f}\")\n",
    "            print(f\"• Ratio positif (moyenne): {avg_ratio:.1%}\")\n",
    "            \n",
    "            # Comparaison par image\n",
    "            for i, (analysis, label) in enumerate(zip(analyses, compare_labels)):\n",
    "                if analysis:\n",
    "                    print(f\"\\n{label}:\")\n",
    "                    print(f\"  • Features: {analysis['positive_features']}(+) / {analysis['negative_features']}(-)\")\n",
    "                    print(f\"  • Ratio positif: {analysis['positive_ratio']:.1%}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur comparaison LIME: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ Comparaison LIME non disponible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6172182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ML_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"📊 Démonstration SHAP\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Configuration SHAP depuis .env\n",
    "        shap_model_type = os.getenv('SHAP_MODEL_TYPE', 'tree')\n",
    "        \n",
    "        # Initialisation de l'explainer SHAP\n",
    "        shap_explainer = SHAPExplainer(ml_model, model_type=shap_model_type)\n",
    "        print(f\"✅ SHAP explainer initialisé (type: {shap_model_type})\")\n",
    "        \n",
    "        # Préparation des données avec taille configurée dans .env\n",
    "        X_background = X_flat[:SHAP_BACKGROUND_SIZE]  # Échantillons d'arrière-plan\n",
    "        X_explain = X_flat[SHAP_BACKGROUND_SIZE:SHAP_BACKGROUND_SIZE+2]   # Échantillons à expliquer\n",
    "        \n",
    "        print(f\"\\n🔧 Configuration depuis .env:\")\n",
    "        print(f\"• Données arrière-plan: {X_background.shape} (size={SHAP_BACKGROUND_SIZE})\")\n",
    "        print(f\"• Données à expliquer: {X_explain.shape}\")\n",
    "        print(f\"• Max évaluations: {SHAP_MAX_EVALS}\")\n",
    "        \n",
    "        # Ajustement de l'explainer\n",
    "        print(\"\\n🔍 Ajustement de l'explainer...\")\n",
    "        shap_explainer.fit_explainer(X_background)\n",
    "        \n",
    "        # Calcul des valeurs SHAP\n",
    "        print(\"📊 Calcul des valeurs SHAP...\")\n",
    "        shap_values = shap_explainer.explain(X_explain, max_evals=SHAP_MAX_EVALS)\n",
    "        \n",
    "        print(f\"✅ Valeurs SHAP calculées !\")\n",
    "        print(f\"• Shape: {shap_values.shape if not isinstance(shap_values, list) else [v.shape for v in shap_values]}\")\n",
    "        \n",
    "        # Visualisation waterfall pour le premier échantillon\n",
    "        print(\"\\n🌊 Graphique Waterfall...\")\n",
    "        try:\n",
    "            # Sélection des features les plus importantes pour la visualisation\n",
    "            if isinstance(shap_values, list):\n",
    "                sample_shap = shap_values[0][0]  # Premier échantillon, première classe\n",
    "            else:\n",
    "                sample_shap = shap_values[0]     # Premier échantillon\n",
    "            \n",
    "            # Top 20 features par importance absolue\n",
    "            top_indices = np.argsort(np.abs(sample_shap))[-20:]\n",
    "            feature_names = [f'Pixel_{i}' for i in top_indices]\n",
    "            \n",
    "            fig = shap_explainer.plot_waterfall(\n",
    "                instance_idx=0,\n",
    "                feature_names=feature_names,\n",
    "                show=True\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Waterfall non disponible: {e}\")\n",
    "            # Graphique alternatif\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            \n",
    "            if isinstance(shap_values, list):\n",
    "                values = shap_values[0][0][:50]  # Top 50 pixels\n",
    "            else:\n",
    "                values = shap_values[0][:50]\n",
    "            \n",
    "            colors = ['red' if v > 0 else 'blue' for v in values]\n",
    "            bars = ax.bar(range(len(values)), values, color=colors, alpha=0.7)\n",
    "            ax.set_xlabel('Pixels')\n",
    "            ax.set_ylabel('Valeur SHAP')\n",
    "            ax.set_title('Contribution des Pixels (SHAP) - Top 50')\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # Importance globale des features\n",
    "        print(\"\\n📈 Importance globale des features...\")\n",
    "        importance_df = shap_explainer.get_feature_importance()\n",
    "        \n",
    "        # Visualisation de l'importance\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        top_features = importance_df.head(20)\n",
    "        \n",
    "        bars = ax.barh(range(len(top_features)), top_features['importance'], alpha=0.7)\n",
    "        ax.set_yticks(range(len(top_features)))\n",
    "        ax.set_yticklabels([f'Pixel_{i}' for i in range(len(top_features))])\n",
    "        ax.set_xlabel('Importance SHAP moyenne')\n",
    "        ax.set_title('Top 20 Pixels - Importance SHAP')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Statistiques SHAP\n",
    "        if isinstance(shap_values, list):\n",
    "            stats_values = shap_values[0]\n",
    "        else:\n",
    "            stats_values = shap_values\n",
    "            \n",
    "        print(f\"\\n📊 Statistiques SHAP:\")\n",
    "        print(f\"• Nombre d'échantillons: {stats_values.shape[0]}\")\n",
    "        print(f\"• Nombre de features: {stats_values.shape[1]}\")\n",
    "        print(f\"• Valeur moyenne: {np.mean(stats_values):.4f}\")\n",
    "        print(f\"• Valeur max: {np.max(stats_values):.4f}\")\n",
    "        print(f\"• Valeur min: {np.min(stats_values):.4f}\")\n",
    "        print(f\"• Écart-type: {np.std(stats_values):.4f}\")\n",
    "        print(f\"• Configuration depuis .env: ✅\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur SHAP: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ SHAP non disponible (ML ou RAF manquant)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f73ae6",
   "metadata": {},
   "source": [
    "## ⚖️ Analyse Comparative SHAP vs GradCAM\n",
    "\n",
    "Comparaison des explications fournies par les deux méthodes sur la même image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118f0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CNN_AVAILABLE and ML_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"⚖️ Analyse Comparative SHAP vs GradCAM\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # Initialisation de l'analyseur intégré\n",
    "        analyzer = InterpretabilityAnalyzer(\n",
    "            cnn_model=cnn_model,\n",
    "            ml_model=ml_model\n",
    "        )\n",
    "        \n",
    "        # Sélection d'une image pour l'analyse comparative\n",
    "        test_idx = 2\n",
    "        test_image_cnn = X_images[test_idx]\n",
    "        test_image_ml = X_flat[test_idx]\n",
    "        true_class = y_true[test_idx]\n",
    "        \n",
    "        print(f\"\\n🖼️ Image test sélectionnée:\")\n",
    "        print(f\"• Index: {test_idx}\")\n",
    "        print(f\"• Classe réelle: {CLASS_NAMES[true_class]}\")\n",
    "        print(f\"• Shape CNN: {test_image_cnn.shape}\")\n",
    "        print(f\"• Shape ML: {test_image_ml.shape}\")\n",
    "        \n",
    "        # Analyse comparative\n",
    "        print(\"\\n🔍 Lancement de l'analyse comparative...\")\n",
    "        comparison_results = analyzer.compare_predictions(\n",
    "            img=test_image_cnn,\n",
    "            X_flat=test_image_ml.reshape(1, -1),\n",
    "            X_background=X_flat[:3],  # Données d'arrière-plan\n",
    "            class_names=CLASS_NAMES\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Analyse comparative terminée !\")\n",
    "        \n",
    "        # Création du tableau de bord intégré\n",
    "        print(\"\\n📊 Génération du tableau de bord...\")\n",
    "        dashboard_fig = create_interpretability_dashboard(\n",
    "            analyzer=analyzer,\n",
    "            img=test_image_cnn,\n",
    "            X_flat=test_image_ml,\n",
    "            X_background=X_flat[:3],\n",
    "            class_names=CLASS_NAMES\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        # Rapport textuel de comparaison\n",
    "        if 'comparison_report' in comparison_results:\n",
    "            report = comparison_results['comparison_report']\n",
    "            print(f\"\\n📋 Rapport de Comparaison:\")\n",
    "            print(f\"• Confiance CNN: {report.get('cnn_confidence', 'N/A')}\")\n",
    "            print(f\"• Classe prédite CNN: {report.get('cnn_predicted_class', 'N/A')}\")\n",
    "            print(f\"• Résumé: {report.get('summary', 'N/A')}\")\n",
    "        \n",
    "        # Cohérence des explications\n",
    "        print(f\"\\n🎯 Analyse de Cohérence:\")\n",
    "        \n",
    "        if 'cnn' in comparison_results and 'ml' in comparison_results:\n",
    "            cnn_confidence = comparison_results['cnn']['gradcam']['prediction_confidence']\n",
    "            cnn_class = comparison_results['cnn']['gradcam']['predicted_class']\n",
    "            \n",
    "            print(f\"• GradCAM - Classe: {CLASS_NAMES[cnn_class]}, Confiance: {cnn_confidence:.2%}\")\n",
    "            print(f\"• Classe réelle: {CLASS_NAMES[true_class]}\")\n",
    "            \n",
    "            if cnn_class == true_class:\n",
    "                print(\"✅ Prédiction correcte !\")\n",
    "            else:\n",
    "                print(\"❌ Prédiction incorrecte\")\n",
    "            \n",
    "            if cnn_confidence > 0.8:\n",
    "                print(\"🔥 Confiance élevée\")\n",
    "            elif cnn_confidence > 0.6:\n",
    "                print(\"⚡ Confiance moyenne\")\n",
    "            else:\n",
    "                print(\"⚠️ Confiance faible\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur analyse comparative: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ Analyse comparative non disponible\")\n",
    "    print(f\"• CNN: {CNN_AVAILABLE}\")\n",
    "    print(f\"• ML: {ML_AVAILABLE}\")\n",
    "    print(f\"• RAF: {RAF_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b3968",
   "metadata": {},
   "source": [
    "## 📈 Analyse Batch et Rapport\n",
    "\n",
    "Génération d'un rapport d'interprétabilité sur plusieurs échantillons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581ff97",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CNN_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"📈 Génération de Rapport Batch\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    try:\n",
    "        # Sélection d'un batch d'images\n",
    "        batch_size = 5\n",
    "        batch_images = X_images[:batch_size]\n",
    "        batch_labels = y_true[:batch_size]\n",
    "        \n",
    "        print(f\"\\n📊 Configuration du batch:\")\n",
    "        print(f\"• Nombre d'images: {batch_size}\")\n",
    "        print(f\"• Classes: {[CLASS_NAMES[label] for label in batch_labels]}\")\n",
    "        \n",
    "        # Génération du rapport\n",
    "        print(\"\\n🔍 Génération du rapport...\")\n",
    "        \n",
    "        analyzer = InterpretabilityAnalyzer(cnn_model=cnn_model)\n",
    "        \n",
    "        report_df = generate_interpretability_report(\n",
    "            analyzer=analyzer,\n",
    "            images=list(batch_images),\n",
    "            X_background=X_flat[:3],\n",
    "            class_names=CLASS_NAMES,\n",
    "            sample_names=[f\"Sample_{i+1}\" for i in range(batch_size)]\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Rapport généré !\")\n",
    "        \n",
    "        # Affichage du rapport\n",
    "        print(\"\\n📋 Rapport d'Interprétabilité:\")\n",
    "        print(report_df.to_string(index=False, float_format='%.3f'))\n",
    "        \n",
    "        # Analyse statistique du batch\n",
    "        if not report_df.empty:\n",
    "            print(f\"\\n📊 Statistiques du Batch:\")\n",
    "            print(f\"• Confiance moyenne: {report_df['confidence'].mean():.2%}\")\n",
    "            print(f\"• Confiance min: {report_df['confidence'].min():.2%}\")\n",
    "            print(f\"• Confiance max: {report_df['confidence'].max():.2%}\")\n",
    "            \n",
    "            # Distribution des classes prédites\n",
    "            class_dist = report_df['predicted_class_name'].value_counts() if 'predicted_class_name' in report_df.columns else report_df['predicted_class'].value_counts()\n",
    "            print(f\"\\n🏷️ Distribution des prédictions:\")\n",
    "            for class_name, count in class_dist.items():\n",
    "                print(f\"• {class_name}: {count} ({count/len(report_df)*100:.1f}%)\")\n",
    "            \n",
    "            # Visualisation de la distribution des confiances\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "            \n",
    "            # Histogramme des confiances\n",
    "            ax1.hist(report_df['confidence'], bins=10, alpha=0.7, edgecolor='black')\n",
    "            ax1.set_xlabel('Confiance')\n",
    "            ax1.set_ylabel('Nombre d\\'images')\n",
    "            ax1.set_title('Distribution des Confiances')\n",
    "            ax1.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Graphique des activations moyennes\n",
    "            if 'gradcam_mean_activation' in report_df.columns:\n",
    "                ax2.scatter(report_df['confidence'], report_df['gradcam_mean_activation'], alpha=0.7)\n",
    "                ax2.set_xlabel('Confiance')\n",
    "                ax2.set_ylabel('Activation GradCAM Moyenne')\n",
    "                ax2.set_title('Confiance vs Activation GradCAM')\n",
    "                ax2.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        # Résumé visuel avec les meilleures prédictions\n",
    "        print(\"\\n🖼️ Résumé visuel des meilleures prédictions...\")\n",
    "        \n",
    "        # Génération des résultats GradCAM pour visualisation\n",
    "        gradcam_results = []\n",
    "        for img in batch_images:\n",
    "            try:\n",
    "                result = gradcam_explainer.generate_gradcam(img)\n",
    "                gradcam_results.append(result)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if gradcam_results:\n",
    "            from src.features.raf.interpretability.utils import plot_interpretability_summary\n",
    "            \n",
    "            summary_fig = plot_interpretability_summary(\n",
    "                gradcam_results[:4],  # Max 4 échantillons\n",
    "                class_names=CLASS_NAMES\n",
    "            )\n",
    "            plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur rapport batch: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ Rapport batch non disponible\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc115361",
   "metadata": {},
   "source": [
    "## 🏥 Application Médicale - Cas d'Usage COVID-19\n",
    "\n",
    "Démonstration d'un cas d'usage réaliste pour le diagnostic médical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58c2944",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🏥 Cas d'Usage Médical - Diagnostic COVID-19\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Simulation d'un cas médical réaliste\n",
    "print(\"\\n👨‍⚕️ Scenario: Diagnostic d'une radiographie pulmonaire\")\n",
    "print(\"\" * 50)\n",
    "\n",
    "# Informations patient (simulées)\n",
    "patient_info = {\n",
    "    'id': 'P001',\n",
    "    'age': 65,\n",
    "    'sexe': 'M',\n",
    "    'symptomes': ['Toux', 'Fièvre', 'Difficultés respiratoires'],\n",
    "    'antecedents': ['Hypertension'],\n",
    "    'date_exam': '2024-10-16'\n",
    "}\n",
    "\n",
    "print(f\"📋 Informations Patient:\")\n",
    "for key, value in patient_info.items():\n",
    "    print(f\"• {key.capitalize()}: {value}\")\n",
    "\n",
    "# Sélection d'une image \"suspecte\"\n",
    "suspect_image = X_images[0]\n",
    "print(f\"\\n🖼️ Radiographie analysée: {suspect_image.shape}\")\n",
    "\n",
    "# Affichage de l'image\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 8))\n",
    "ax.imshow(suspect_image.squeeze(), cmap='gray')\n",
    "ax.set_title(f'Radiographie Patient {patient_info[\"id\"]}', fontsize=14)\n",
    "ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "if CNN_AVAILABLE and RAF_AVAILABLE:\n",
    "    print(\"\\n🔍 Analyse IA de la radiographie...\")\n",
    "    \n",
    "    try:\n",
    "        # Analyse GradCAM\n",
    "        gradcam_result = gradcam_explainer.generate_gradcam(suspect_image)\n",
    "        \n",
    "        predicted_class = gradcam_result['predicted_class']\n",
    "        confidence = gradcam_result['prediction_confidence']\n",
    "        predicted_disease = CLASS_NAMES[predicted_class]\n",
    "        \n",
    "        print(f\"\\n🎯 Résultats de l'Analyse IA:\")\n",
    "        print(f\"• Diagnostic suggéré: {predicted_disease}\")\n",
    "        print(f\"• Confiance du modèle: {confidence:.1%}\")\n",
    "        \n",
    "        # Interprétation médicale\n",
    "        if predicted_disease == 'COVID':\n",
    "            print(f\"⚠️ ALERTE: Suspicion COVID-19 détectée\")\n",
    "            print(f\"📋 Recommandations:\")\n",
    "            print(f\"   • Test PCR recommandé\")\n",
    "            print(f\"   • Isolement préventif\")\n",
    "            print(f\"   • Surveillance des symptômes\")\n",
    "        elif predicted_disease == 'Normal':\n",
    "            print(f\"✅ Radiographie apparemment normale\")\n",
    "            print(f\"📋 Recommandations:\")\n",
    "            print(f\"   • Surveillance clinique\")\n",
    "            print(f\"   • Suivi si symptômes persistent\")\n",
    "        else:\n",
    "            print(f\"⚠️ Anomalie détectée: {predicted_disease}\")\n",
    "            print(f\"📋 Recommandations:\")\n",
    "            print(f\"   • Évaluation spécialisée recommandée\")\n",
    "            print(f\"   • Tests complémentaires\")\n",
    "        \n",
    "        # Visualisation avec zones d'intérêt\n",
    "        print(f\"\\n🔍 Zones d'attention identifiées par l'IA:\")\n",
    "        \n",
    "        fig = gradcam_explainer.plot_gradcam(\n",
    "            gradcam_result,\n",
    "            title=f\"Analyse IA - Patient {patient_info['id']} - {predicted_disease}\",\n",
    "            class_names=CLASS_NAMES\n",
    "        )\n",
    "        plt.show()\n",
    "        \n",
    "        # Analyse quantitative pour le rapport médical\n",
    "        features = extract_gradcam_features(gradcam_result['heatmap'])\n",
    "        regions = analyze_gradcam_regions(gradcam_result['heatmap'])\n",
    "        \n",
    "        print(f\"\\n📊 Analyse Quantitative (pour le dossier médical):\")\n",
    "        print(f\"• Zone d'attention: {regions['importance_ratio']:.1%} de l'image\")\n",
    "        print(f\"• Intensité moyenne des zones suspectes: {features['mean_activation']:.3f}\")\n",
    "        print(f\"• Score de confiance technique: {confidence:.3f}\")\n",
    "        \n",
    "        # Niveau de confiance pour le médecin\n",
    "        if confidence > 0.9:\n",
    "            confidence_level = \"Très élevée\"\n",
    "            recommendation = \"Diagnostic IA très fiable\"\n",
    "        elif confidence > 0.75:\n",
    "            confidence_level = \"Élevée\"\n",
    "            recommendation = \"Diagnostic IA fiable, confirmation clinique recommandée\"\n",
    "        elif confidence > 0.6:\n",
    "            confidence_level = \"Modérée\"\n",
    "            recommendation = \"Diagnostic IA incertain, expertise médicale nécessaire\"\n",
    "        else:\n",
    "            confidence_level = \"Faible\"\n",
    "            recommendation = \"Diagnostic IA peu fiable, réévaluation recommandée\"\n",
    "        \n",
    "        print(f\"\\n👨‍⚕️ Interprétation pour le Médecin:\")\n",
    "        print(f\"• Niveau de confiance: {confidence_level}\")\n",
    "        print(f\"• Recommandation: {recommendation}\")\n",
    "        \n",
    "        # Génération d'un rapport médical structuré\n",
    "        medical_report = f\"\"\"\n",
    "RAPPORT D'ANALYSE IA - RADIOGRAPHIE PULMONAIRE\n",
    "=============================================\n",
    "\n",
    "Patient: {patient_info['id']}\n",
    "Date: {patient_info['date_exam']}\n",
    "Âge: {patient_info['age']} ans, Sexe: {patient_info['sexe']}\n",
    "\n",
    "RÉSULTATS DE L'ANALYSE IA:\n",
    "• Diagnostic suggéré: {predicted_disease}\n",
    "• Confiance du modèle: {confidence:.1%}\n",
    "• Niveau de confiance: {confidence_level}\n",
    "\n",
    "ANALYSE QUANTITATIVE:\n",
    "• Zone d'attention: {regions['importance_ratio']:.1%} de l'image\n",
    "• Intensité des anomalies: {features['mean_activation']:.3f}\n",
    "• Score de concentration: {features['concentration_75']:.1%}\n",
    "\n",
    "RECOMMANDATIONS CLINIQUES:\n",
    "{recommendation}\n",
    "\n",
    "NOTES:\n",
    "• Cette analyse IA est un outil d'aide au diagnostic\n",
    "• L'expertise médicale reste indispensable\n",
    "• En cas de doute, privilégier l'évaluation clinique\n",
    "\n",
    "Généré automatiquement le {patient_info['date_exam']}\n",
    "        \"\"\"\n",
    "        \n",
    "        print(medical_report)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erreur analyse médicale: {e}\")\n",
    "        print(f\"⚠️ En situation réelle, consulter un radiologue\")\n",
    "        \n",
    "else:\n",
    "    print(\"\\n⚠️ Analyse IA non disponible\")\n",
    "    print(\"En situation réelle, la radiographie serait analysée par un médecin\")\n",
    "\n",
    "print(f\"\\n🏥 Fin du cas médical - Patient {patient_info['id']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572958f7",
   "metadata": {},
   "source": [
    "## 📝 Conclusion et Bonnes Pratiques\n",
    "\n",
    "### 🎯 Résumé des Techniques\n",
    "\n",
    "1. **GradCAM** : Visualisation des zones importantes pour les CNN\n",
    "   - ✅ Intuitive et visuelle\n",
    "   - ✅ Spécifique aux réseaux convolutionnels\n",
    "   - ❌ Limitée aux modèles avec couches convolutionnelles\n",
    "\n",
    "2. **SHAP** : Quantification de l'importance des features\n",
    "   - ✅ Universel (tous types de modèles)\n",
    "   - ✅ Fondements théoriques solides\n",
    "   - ❌ Plus lent sur de grandes données\n",
    "\n",
    "3. **LIME** : Explication par approximation locale\n",
    "   - ✅ Agnostique au modèle\n",
    "   - ✅ Explications intuitives par superpixels\n",
    "   - ✅ Fonctionne bien sur les images\n",
    "   - ❌ Peut être instable selon l'échantillonnage\n",
    "\n",
    "### 🏥 Applications Médicales\n",
    "\n",
    "- **Aide au diagnostic** : Identifier les zones suspectes\n",
    "- **Formation** : Comprendre les critères du modèle\n",
    "- **Validation** : Vérifier la cohérence des prédictions\n",
    "- **Confiance** : Évaluer la fiabilité des résultats\n",
    "- **Traçabilité** : Documenter les décisions automatisées\n",
    "\n",
    "### ⚖️ Bonnes Pratiques\n",
    "\n",
    "1. **Combinaison des méthodes** : Utiliser SHAP, GradCAM ET LIME\n",
    "2. **Validation humaine** : Toujours confirmer avec un expert\n",
    "3. **Seuils de confiance** : Définir des niveaux d'alerte\n",
    "4. **Documentation** : Tracer les décisions du modèle\n",
    "5. **Données réelles** : Tester sur de vraies données médicales\n",
    "\n",
    "### 🔧 Framework RAF\n",
    "\n",
    "Le framework RAF facilite l'intégration de l'interprétabilité :\n",
    "- Modules prêts à l'emploi (SHAP, GradCAM, LIME)\n",
    "- Interface unifiée avec DataLoader intégré\n",
    "- Visualisations automatiques\n",
    "- Rapports structurés\n",
    "- Configuration via fichiers .env\n",
    "\n",
    "### 🚀 Prochaines Étapes\n",
    "\n",
    "1. Intégrer vos vrais modèles entraînés\n",
    "2. Tester sur de vraies données médicales COVID-19\n",
    "3. Valider avec des experts médicaux\n",
    "4. Déployer dans l'interface Streamlit\n",
    "5. Automatiser les rapports d'interprétabilité\n",
    "6. Comparer les résultats SHAP, GradCAM et LIME\n",
    "\n",
    "### 📊 Recommandations d'Usage\n",
    "\n",
    "- **GradCAM** : Pour visualiser rapidement les zones d'attention\n",
    "- **LIME** : Pour expliquer des cas spécifiques aux médecins\n",
    "- **SHAP** : Pour des analyses quantitatives et comparatives\n",
    "- **Combinaison** : Pour une validation croisée des explications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f147b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🎉 NOTEBOOK D'INTERPRÉTABILITÉ TERMINÉ\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "summary_stats = {\n",
    "    'Modules testés': {\n",
    "        'SHAP': 'Disponible' if RAF_AVAILABLE else 'Non disponible',\n",
    "        'GradCAM': 'Disponible' if RAF_AVAILABLE else 'Non disponible',\n",
    "        'LIME': 'Disponible' if RAF_AVAILABLE else 'Non disponible',\n",
    "        'Framework RAF': 'Disponible' if RAF_AVAILABLE else 'Non disponible'\n",
    "    },\n",
    "    'Données': {\n",
    "        'DataLoader RAF': 'Disponible' if DATALOADER_AVAILABLE else 'Non disponible',\n",
    "        'Données réelles': 'Chargées' if 'REAL_DATA_LOADED' in locals() and REAL_DATA_LOADED else 'Simulées',\n",
    "        'Dataset COVID-19': 'Utilisé' if 'REAL_DATA_LOADED' in locals() and REAL_DATA_LOADED else 'Non utilisé'\n",
    "    },\n",
    "    'Modèles utilisés': {\n",
    "        'CNN (TensorFlow)': 'Créé' if CNN_AVAILABLE else 'Non disponible',\n",
    "        'ML (Random Forest)': 'Créé' if ML_AVAILABLE else 'Non disponible'\n",
    "    },\n",
    "    'Analyses réalisées': {\n",
    "        'GradCAM simple': '✅' if CNN_AVAILABLE and RAF_AVAILABLE else '❌',\n",
    "        'GradCAM++': '✅' if CNN_AVAILABLE and RAF_AVAILABLE else '❌',\n",
    "        'LIME Image': '✅' if CNN_AVAILABLE and RAF_AVAILABLE else '❌',\n",
    "        'LIME Comparaison': '✅' if CNN_AVAILABLE and RAF_AVAILABLE else '❌',\n",
    "        'SHAP Tree': '✅' if ML_AVAILABLE and RAF_AVAILABLE else '❌',\n",
    "        'Analyse comparative': '✅' if CNN_AVAILABLE and ML_AVAILABLE and RAF_AVAILABLE else '❌',\n",
    "        'Rapport batch': '✅' if CNN_AVAILABLE and RAF_AVAILABLE else '❌',\n",
    "        'Cas médical': '✅' if CNN_AVAILABLE and RAF_AVAILABLE else '❌'\n",
    "    }\n",
    "}\n",
    "\n",
    "for category, items in summary_stats.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    for item, status in items.items():\n",
    "        print(f\"  • {item}: {status}\")\n",
    "\n",
    "print(f\"\\n📚 Ressources:\")\n",
    "print(f\"  • Framework RAF: src/features/raf/interpretability/\")\n",
    "print(f\"  • DataLoader RAF: src/features/raf/data/\")\n",
    "print(f\"  • Interface Streamlit: src/streamlit/pages/03_Interpretability.py\")\n",
    "print(f\"  • Documentation SHAP: https://shap.readthedocs.io/\")\n",
    "print(f\"  • Paper GradCAM: https://arxiv.org/abs/1610.02391\")\n",
    "print(f\"  • Paper LIME: https://arxiv.org/abs/1602.04938\")\n",
    "\n",
    "print(f\"\\n🚀 Prochaines étapes:\")\n",
    "print(f\"  1. Installer LIME si nécessaire: pip install lime\")\n",
    "print(f\"  2. Charger vos modèles réels entraînés\")\n",
    "print(f\"  3. Tester sur vraies données COVID-19\")\n",
    "print(f\"  4. Valider avec experts médicaux\")\n",
    "print(f\"  5. Comparer SHAP, GradCAM et LIME\")\n",
    "print(f\"  6. Intégrer dans pipeline de production\")\n",
    "\n",
    "print(f\"\\n✨ L'interprétabilité est essentielle pour l'IA médicale !\")\n",
    "print(f\"🔍 SHAP + GradCAM + LIME = Triangle d'or de l'explicabilité\")\n",
    "print(f\"🏥 Continuez à explorer et à valider vos modèles.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
